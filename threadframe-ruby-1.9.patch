Index: include/ruby/ruby.h
===================================================================
--- include/ruby/ruby.h	(revision 27984)
+++ include/ruby/ruby.h	(working copy)
@@ -1345,7 +1345,9 @@
 #define RUBY_EVENT_C_CALL    0x0020
 #define RUBY_EVENT_C_RETURN  0x0040
 #define RUBY_EVENT_RAISE     0x0080
-#define RUBY_EVENT_ALL       0xffff
+#define RUBY_EVENT_INSN      0x0100
+#define RUBY_EVENT_BRKPT     0x0200
+#define RUBY_EVENT_ALL       (0xffff & ~RUBY_EVENT_INSN)
 #define RUBY_EVENT_VM       0x10000
 #define RUBY_EVENT_SWITCH   0x20000
 #define RUBY_EVENT_COVERAGE 0x40000
Index: insns.def
===================================================================
--- insns.def	(revision 27984)
+++ insns.def	(working copy)
@@ -15,7 +15,7 @@
 
   instruction form:
     DEFINE_INSN
-    instrunction_name
+    instruction_name
     (instruction_operands, ..)
     (pop_values, ..)
     (return value)
Index: vm_core.h
===================================================================
--- vm_core.h	(revision 27984)
+++ vm_core.h	(working copy)
@@ -34,7 +34,7 @@
 #ifndef ENABLE_VM_OBJSPACE
 #ifdef _WIN32
 /*
- * TODO: object space indenpendent st_table.
+ * TODO: object space independent st_table.
  * socklist needs st_table in rb_w32_sysinit(), before object space
  * initialization.
  * It is too early now to change st_hash_type, since it breaks binary
@@ -166,7 +166,7 @@
     VALUE name;	         /* String: iseq name */
     VALUE filename;      /* file information where this sequence from */
     VALUE filepath;      /* real file path or nil */
-    VALUE *iseq;         /* iseq (insn number and openrads) */
+    VALUE *iseq;         /* iseq (insn number and operands) */
     VALUE *iseq_encoded; /* encoded iseq */
     unsigned long iseq_size;
     VALUE mark_ary;	/* Array: includes operands which should be GC marked */
@@ -190,7 +190,7 @@
      * argument information
      *
      *  def m(a1, a2, ..., aM,                    # mandatory
-     *        b1=(...), b2=(...), ..., bN=(...),  # optinal
+     *        b1=(...), b2=(...), ..., bN=(...),  # optional
      *        *c,                                 # rest
      *        d1, d2, ..., dO,                    # post
      *        &e)                                 # block
@@ -253,6 +253,8 @@
 
     /* used at compile time */
     struct iseq_compile_data *compile_data;
+    /* Used to set a breakpoint at a VM instruction */
+    unsigned char *breakpoints; 
 };
 
 enum ruby_special_exceptions {
@@ -330,6 +332,9 @@
     rb_iseq_t *block_iseq;	/* cfp[8] / block[3] */
     VALUE proc;			/* cfp[9] / block[4] */
     const rb_method_entry_t *me;/* cfp[10] */
+    short int tracing;          /* Bits to control per-frame event tracing. 
+				   See VM_FRAME_TRACE_xxx defines.
+				 */
 } rb_control_frame_t;
 
 typedef struct rb_block_struct {
@@ -390,6 +395,18 @@
     /* passing state */
     int state;
 
+    /* tracer */
+    rb_event_hook_t *event_hooks;
+    rb_event_flag_t event_flags;
+    int tracing;  /* 0 if not tracing. If less than 0, skip that many
+		     C call/return pairs */
+    int exec_event_tracing;  /* 0 if not in rb_threadptr_evec_event_hooks. */
+    int trace_skip_insn_count; /* # of VM instructions to skip */
+
+    /* misc */
+    int method_missing_reason;
+    int abort_on_exception;
+
     /* for rb_iterate */
     const rb_block_t *passed_block;
 
@@ -412,6 +429,14 @@
     int priority;
     int slice;
 
+    /* statistics data for profiler */
+    VALUE stat_insn_usage;
+
+    /* fiber */
+    VALUE fiber;
+    VALUE root_fiber;
+    rb_jmpbuf_t root_jmpbuf;
+
     native_thread_data_t native_thread_data;
     void *blocking_region_buffer;
 
@@ -461,22 +486,7 @@
     jmp_buf machine_regs;
     int mark_stack_len;
 
-    /* statistics data for profiler */
-    VALUE stat_insn_usage;
-
-    /* tracer */
-    rb_event_hook_t *event_hooks;
-    rb_event_flag_t event_flags;
-    int tracing;
-
-    /* fiber */
-    VALUE fiber;
-    VALUE root_fiber;
-    rb_jmpbuf_t root_jmpbuf;
-
     /* misc */
-    int method_missing_reason;
-    int abort_on_exception;
 #ifdef USE_SIGALTSTACK
     void *altstack;
 #endif
@@ -490,6 +500,7 @@
 VALUE rb_iseq_new_with_opt(NODE*, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, const rb_compile_option_t*);
 VALUE rb_iseq_compile(VALUE src, VALUE file, VALUE line);
 VALUE rb_iseq_disasm(VALUE self);
+VALUE rb_iseq_disasm_no_children(VALUE self);
 int rb_iseq_disasm_insn(VALUE str, VALUE *iseqval, size_t pos, rb_iseq_t *iseq, VALUE child);
 const char *ruby_node_name(int node);
 int rb_iseq_first_lineno(rb_iseq_t *iseq);
@@ -564,6 +575,10 @@
 
 #define VM_FRAME_TYPE(cfp) ((cfp)->flag & VM_FRAME_MAGIC_MASK)
 
+#define VM_FRAME_TRACE_RETURN 0x01  /* Call trace hook on return. */
+#define VM_FRAME_TRACE_OFF    0x02  /* Turn of event hook tracing in this frame
+				       and any frames created from this one. */
+
 /* other frame flag */
 #define VM_FRAME_FLAG_PASSED 0x0100
 
@@ -691,13 +706,29 @@
 void
 rb_threadptr_exec_event_hooks(rb_thread_t *th, rb_event_flag_t flag, VALUE self, ID id, VALUE klass);
 
-#define EXEC_EVENT_HOOK(th, flag, self, id, klass) do { \
-    rb_event_flag_t wait_event__ = th->event_flags; \
-    if (UNLIKELY(wait_event__)) { \
-	if (wait_event__ & (flag | RUBY_EVENT_VM)) { \
-	    rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
-	} \
-    } \
-} while (0)
+#define EXEC_EVENT_HOOK(th, flag, self, id, klass)			\
+  if (LIKELY(0 == th->tracing)) {					\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+	    }								\
+	}								\
+    }
 
+/* Customized version of EXEC_EVENT_HOOK for RUBY_EVENT_RETURN events */
+#define EXEC_EVENT_RETURN_HOOK(th, flag, self, id, klass)		\
+    if (LIKELY(0 == th->tracing &&					\
+	       (!(th->cfp->tracing & VM_FRAME_TRACE_OFF)		\
+		|| (th->cfp->tracing & VM_FRAME_TRACE_RETURN)))) {	\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+	        th->tracing = 1;					\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+		th->tracing = 0;					\
+	    }								\
+	}								\
+    }
+
 #endif /* RUBY_VM_CORE_H */
Index: iseq.c
===================================================================
--- iseq.c	(revision 27984)
+++ iseq.c	(working copy)
@@ -23,6 +23,38 @@
 
 #define hidden_obj_p(obj) (!SPECIAL_CONST_P(obj) && !RBASIC(obj)->klass)
 
+/* some utilities */
+
+int
+insn_len(VALUE insn)
+{
+  return insn_len_info[(int)insn];
+}
+
+const char *
+insn_name(VALUE insn)
+{
+  return insn_name_info[(int)insn];
+}
+
+const char *
+insn_op_types(VALUE insn)
+{
+  return insn_operand_info[(int)insn];
+}
+
+int
+insn_op_type(VALUE insn, long pos)
+{
+  int len = insn_len(insn) - 1;
+  if(pos < len){
+    return insn_operand_info[(int)insn][pos];
+  }
+  else{
+    return 0;
+  }
+}
+
 static inline VALUE
 obj_resurrect(VALUE obj)
 {
@@ -118,6 +150,17 @@
     RUBY_MARK_LEAVE("iseq");
 }
 
+VALUE
+iseq_alloc_shared(VALUE klass)
+{
+    VALUE volatile obj;
+    rb_iseq_t *iseq;
+
+    obj = Data_Make_Struct(klass, rb_iseq_t, iseq_mark, NULL, iseq);
+    MEMZERO(iseq, rb_iseq_t, 1);
+    return obj;
+}
+
 static size_t
 iseq_memsize(const void *ptr)
 {
@@ -395,6 +438,35 @@
 				parent, ISEQ_TYPE_MAIN, &COMPILE_OPTION_DEFAULT);
 }
 
+static void
+update_file_iseq(VALUE filename, VALUE iseq_name, VALUE iseq)
+{
+    ID hash_id;
+    CONST_ID(hash_id, "SCRIPT_ISEQS__");
+    if (rb_const_defined_at(rb_cObject, hash_id)) {
+	VALUE hash = rb_const_get_at(rb_cObject, hash_id);
+	if (TYPE(hash) == T_HASH) {
+	    VALUE iseqs = rb_hash_aref(hash, filename);
+	    if (TYPE(iseqs) == T_ARRAY)
+		rb_ary_push(iseqs, iseq);
+	    else
+		rb_hash_aset(hash, filename, rb_ary_new3(1, iseq));
+	}
+    }
+    CONST_ID(hash_id, "ISEQS__");
+    if (rb_const_defined_at(rb_cObject, hash_id)) {
+	VALUE hash = rb_const_get_at(rb_cObject, hash_id);
+	if (TYPE(hash) == T_HASH) {
+	    VALUE iseqs = rb_hash_aref(hash, iseq_name);
+	    if (TYPE(iseqs) == T_ARRAY)
+		rb_ary_push(iseqs, iseq);
+	    else
+		rb_hash_aset(hash, iseq_name, rb_ary_new3(1, iseq));
+	}
+    }
+}
+
+
 static VALUE
 rb_iseq_new_with_bopt_and_opt(NODE *node, VALUE name, VALUE filename, VALUE filepath, VALUE line_no,
 				VALUE parent, VALUE type, VALUE bopt,
@@ -409,6 +481,7 @@
     prepare_iseq_build(iseq, name, filename, filepath, line_no, parent, type, bopt, option);
     rb_iseq_compile_node(self, node);
     cleanup_iseq_build(iseq);
+    update_file_iseq(filename, name, self);
     return self;
 }
 
@@ -653,9 +726,13 @@
         return rb_sprintf("#<%s: uninitialized>", rb_obj_classname(self));
     }
 
-    return rb_sprintf("<%s:%s@%s>",
-                      rb_obj_classname(self),
-		      RSTRING_PTR(iseq->name), RSTRING_PTR(iseq->filename));
+    if (ISEQ_TYPE_TOP == iseq->type)
+	return rb_sprintf("<%s:%s>",
+			  rb_obj_classname(self), RSTRING_PTR(iseq->name));
+    else
+	return rb_sprintf("<%s:%s@%s>",
+			  rb_obj_classname(self),
+			  RSTRING_PTR(iseq->name), RSTRING_PTR(iseq->filename));
 }
 
 static
@@ -725,6 +802,117 @@
     return 0;
 }
 
+static void
+insn_operand_add_child(rb_iseq_t *iseq,
+		       VALUE insn, int op_no, VALUE op,
+		       VALUE child)
+{
+    const char *types = insn_op_types(insn);
+    char type = types[op_no];
+
+    switch (type) {
+      case TS_OFFSET:		/* LONG */
+	break;
+
+      case TS_NUM:		/* ULONG */
+	break;
+
+      case TS_LINDEX:
+	break;
+
+      case TS_DINDEX:
+	break;
+
+      case TS_ID:		/* ID (symbol) */
+	op = ID2SYM(op);
+
+      case TS_VALUE:		/* VALUE */
+	op = obj_resurrect(op);
+	if (CLASS_OF(op) == rb_cISeq) {
+	    rb_ary_push(child, op);
+	}
+	break;
+
+      case TS_ISEQ:		/* iseq */
+	{
+	    rb_iseq_t *iseq = (rb_iseq_t *)op;
+	    if (iseq) {
+		if (child) {
+		    rb_ary_push(child, iseq->self);
+		}
+	    }
+	    break;
+	}
+      case TS_GENTRY:
+	break;
+
+      case TS_IC:
+	break;
+
+      case TS_CDHASH:
+	break;
+
+      case TS_FUNCPTR:
+	break;
+
+      default:
+	rb_bug("rb_iseq_disasm: unknown operand type: %c", type);
+    }
+}
+
+/**
+ * Add to child array all instruction sequences fond in an instruction.
+ */
+static int
+rb_iseq_insn_add_child(VALUE *iseq, size_t pos,
+		       rb_iseq_t *iseqdat, VALUE child)
+{
+    VALUE insn = iseq[pos];
+    int len = insn_len(insn);
+    int j;
+    const char *types = insn_op_types(insn);
+
+    for (j = 0; types[j]; j++) {
+	insn_operand_add_child(iseqdat, insn, j, iseq[pos + j + 1],
+			       child);
+    }
+    return len;
+}
+
+/* Return an ARRAY of iseq's which can be found off of this one. */
+VALUE
+rb_iseq_child_iseqs(VALUE self)
+{
+    VALUE *iseq;
+    rb_iseq_t *iseqdat;
+    VALUE child = rb_ary_new();
+    unsigned long size;
+    int i;
+    size_t n;
+    enum {header_minlen = 72};
+
+    rb_secure(1);
+    iseqdat = iseq_check(self);
+
+    rb_ary_push(child, self);
+    iseq = iseqdat->iseq;
+    size = iseqdat->iseq_size;
+
+    /* First, any catch table iseq's. */
+    for (i = 0; i < iseqdat->catch_table_size; i++) {
+	struct iseq_catch_table_entry *entry = &iseqdat->catch_table[i];
+	if (entry->iseq) {
+	    rb_ary_push(child, entry->iseq);
+	}
+    }
+
+    /* Next each iseq found inside the instructions */
+    for (n = 0; n < size;) {
+	n += rb_iseq_insn_add_child(iseq, n, iseqdat, child);
+    }
+    return child;
+}
+
 static VALUE
 insn_operand_intern(rb_iseq_t *iseq,
 		    VALUE insn, int op_no, VALUE op,
@@ -914,9 +1102,8 @@
 }
 
 VALUE
-rb_iseq_disasm(VALUE self)
+rb_iseq_disasm_internal(rb_iseq_t *iseqdat, int include_child)
 {
-    rb_iseq_t *iseqdat = iseq_check(self);
     VALUE *iseq;
     VALUE str = rb_str_new(0, 0);
     VALUE child = rb_ary_new();
@@ -1008,14 +1195,44 @@
 	n += rb_iseq_disasm_insn(str, iseq, n, iseqdat, child);
     }
 
-    for (i = 0; i < RARRAY_LEN(child); i++) {
-	VALUE isv = rb_ary_entry(child, i);
-	rb_str_concat(str, rb_iseq_disasm(isv));
-    }
+    if (include_child)
+	for (i = 0; i < RARRAY_LEN(child); i++) {
+	    VALUE isv = rb_ary_entry(child, i);
+	    rb_str_concat(str, rb_iseq_disasm(isv));
+	}
 
     return str;
 }
 
+/*
+ *  call-seq:
+ *     iseq.disasm   => string
+ *
+ *  Returns a string disassembly of an instruction sequence.
+ */
+
+VALUE
+rb_iseq_disasm(VALUE self)
+{
+    return rb_iseq_disasm_internal(iseq_check(self), 1);
+}
+
+/*
+ *  call-seq:
+ *     iseq.disasm_nochildren   => string
+ *
+ *  Returns a string disassembly of an instruction sequence, and
+ *  doesn't include instruction sequences for any associated catch
+ *  table, or instruction sequences found from this instruction
+ *  sequence.
+ */
+
+VALUE
+rb_iseq_disasm_nochildren(VALUE self)
+{
+    return rb_iseq_disasm_internal(iseq_check(self), 0);
+}
+
 static VALUE
 iseq_s_disasm(VALUE klass, VALUE body)
 {
@@ -1501,9 +1718,11 @@
     rb_define_alloc_func(rb_cISeq, iseq_alloc);
     rb_define_method(rb_cISeq, "inspect", iseq_inspect, 0);
     rb_define_method(rb_cISeq, "disasm", rb_iseq_disasm, 0);
+    rb_define_method(rb_cISeq, "disasm_nochildren", rb_iseq_disasm_nochildren, 0);
     rb_define_method(rb_cISeq, "disassemble", rb_iseq_disasm, 0);
     rb_define_method(rb_cISeq, "to_a", iseq_to_a, 0);
     rb_define_method(rb_cISeq, "eval", iseq_eval, 0);
+    rb_define_method(rb_cISeq, "child_iseqs", rb_iseq_child_iseqs, 0);
 
     /* disable this feature because there is no verifier. */
     /* rb_define_singleton_method(rb_cISeq, "load", iseq_s_load, -1); */
Index: iseq.h
===================================================================
--- iseq.h	(revision 27984)
+++ iseq.h	(working copy)
@@ -101,4 +101,10 @@
 #define DEFINED_ZSUPER INT2FIX(9)
 #define DEFINED_FUNC   INT2FIX(10)
 
+/* some utilities */
+extern int insn_len(VALUE insn);
+extern const char *insn_name(VALUE insn);
+extern const char *insn_op_types(VALUE insn);
+extern int insn_op_type(VALUE insn, long pos);
+
 #endif /* RUBY_COMPILE_H */
Index: load.c
===================================================================
--- load.c	(revision 27984)
+++ load.c	(working copy)
@@ -293,11 +293,14 @@
     if (state == 0) {
 	NODE *node;
 	VALUE iseq;
+	char iseq_name[MAXPATHLEN];
 
 	th->mild_compile_error++;
 	node = (NODE *)rb_load_file(RSTRING_PTR(fname));
 	loaded = TRUE;
-	iseq = rb_iseq_new_top(node, rb_str_new2("<top (required)>"), fname, fname, Qfalse);
+	
+	snprintf(iseq_name, sizeof(iseq_name), "<top %s>", RSTRING_PTR(fname));
+	iseq = rb_iseq_new_top(node, rb_str_new2(iseq_name), fname, fname, Qfalse);
 	th->mild_compile_error--;
 	rb_iseq_eval(iseq);
     }
Index: compile.c
===================================================================
--- compile.c	(revision 27984)
+++ compile.c	(working copy)
@@ -3353,6 +3353,9 @@
 	if (iseq->compile_data->redo_label != 0) {
 	    LABEL *splabel = NEW_LABEL(0);
 	    debugs("next in while loop\n");
+	    if (!poped) {
+		ADD_INSN(ret, nd_line(node), putnil);
+	    }
 	    ADD_LABEL(ret, splabel);
 	    COMPILE(ret, "next val/valid syntax?", node->nd_stts);
 	    add_ensure_iseq(ret, iseq, 0);
Index: vm_eval.c
===================================================================
--- vm_eval.c	(revision 27984)
+++ vm_eval.c	(working copy)
@@ -67,22 +67,37 @@
 	break;
       }
       case VM_METHOD_TYPE_CFUNC: {
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, id, klass);
 	{
 	    rb_control_frame_t *reg_cfp = th->cfp;
 	    rb_control_frame_t *cfp =
 		vm_push_frame(th, 0, VM_FRAME_MAGIC_CFUNC,
 			      recv, (VALUE)blockptr, 0, reg_cfp->sp, 0, 1);
 
+	    /* Store actual argument count as the block_iseq
+	       pointer. cfunc.argc contains the prototype
+	       value. Should formalize this by making block_iseq a
+	       union in vm_core.h
+	    */
+	    cfp->block_iseq = (rb_iseq_t *) INT2FIX(argc);
+
 	    cfp->me = me;
+	    if (0 == th->tracing)
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, id, klass);
+
 	    val = call_cfunc(def->body.cfunc.func, recv, def->body.cfunc.argc, argc, argv);
 
 	    if (reg_cfp != th->cfp + 1) {
 		rb_bug("cfp consistency error - call0");
 	    }
+	    if (0 == th->tracing && 0 == th->exec_event_tracing) {
+		/* rocky: FIXME: decide what to do for sp values,
+		   especially the return value. See vm_insnhelper.c
+		   for guidance.
+		*/
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, id, klass);
+	    }
 	    vm_pop_frame(th);
 	}
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, id, klass);
 	break;
       }
       case VM_METHOD_TYPE_ATTRSET: {
@@ -868,7 +883,8 @@
 #endif
 		    if (UNLIKELY(VM_FRAME_TYPE(th->cfp) == VM_FRAME_MAGIC_CFUNC)) {
 			const rb_method_entry_t *me = th->cfp->me;
-			EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, me->called_id, me->klass);
+			EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, 
+					th->cfp->self, me->called_id, me->klass);
 		    }
 
 		    th->cfp = RUBY_VM_PREVIOUS_CONTROL_FRAME(th->cfp);
@@ -1024,7 +1040,25 @@
     if (state) {
 	if (state == TAG_RAISE) {
 	    VALUE errinfo = th->errinfo;
-	    if (strcmp(file, "(eval)") == 0) {
+	    /* The below test for eval is inadequate in several
+	       respects.  First rather than testing on a string like
+	       "(eval" or "(eval)" as was done originally, there
+	       should be a more positive indicator that "file" is not
+	       a real file but say, a string. Then there is the harder
+	       issue of what should be done to show the backtrace for
+	       this. Personally, I think part of the string should be
+	       shown. Finally because "(eval)" is used as the "file"
+	       name, it is harder to find this particular instruction
+	       sequence from the instruction sequence name over some
+	       other eval string.
+
+	       To start to deal with instruction sequence name
+	       unhelpfulness, we will prepare for the day when we have
+	       a more descriptive container such as the leading part
+	       of the string we are about to eval, e.g. (eval "x = y +
+	       ...")
+	     */
+	    if (strncmp(file, "(eval", sizeof("(eval")-1) == 0) {
 		VALUE mesg, errat, bt2;
 		extern VALUE rb_get_backtrace(VALUE info);
 		ID id_mesg;
Index: proc.c
===================================================================
--- proc.c	(revision 27984)
+++ proc.c	(working copy)
@@ -27,7 +27,7 @@
 VALUE rb_iseq_parameters(const rb_iseq_t *iseq, int is_proc);
 
 static VALUE bmcall(VALUE, VALUE);
-static int method_arity(VALUE);
+int method_arity(VALUE);
 static int rb_obj_is_method(VALUE m);
 rb_iseq_t *rb_method_get_iseq(VALUE method);
 
@@ -324,6 +324,24 @@
     return bindval;
 }
 
+VALUE
+rb_binding_frame_new(void *vth, void *vcfp)
+{
+    rb_thread_t * th = (rb_thread_t *) vth;
+    rb_control_frame_t * cfp  = (rb_control_frame_t *) vcfp;
+    VALUE bindval = binding_alloc(rb_cBinding);
+    rb_binding_t *bind;
+    
+    if (cfp == 0) {
+        rb_raise(rb_eRuntimeError, 
+		 "Can't create Binding Object on top of Fiber.");
+    }
+
+    GetBindingPtr(bindval, bind);
+    bind->env = rb_vm_make_env_object(th, cfp);
+    return bindval;
+}
+
 /*
  *  call-seq:
  *     binding -> a_binding
@@ -625,6 +643,29 @@
     return INT2FIX(arity);
 }
 
+int 
+get_iseq_arity(rb_iseq_t *iseq) 
+{
+    if (iseq) {
+	if (BUILTIN_TYPE(iseq) != T_NODE) {
+	    if (iseq->arg_rest < 0) {
+		return iseq->argc;
+	    }
+	    else {
+		return -(iseq->argc + 1 + iseq->arg_post_len);
+	    }
+	}
+	else {
+	    NODE *node = (NODE *)iseq;
+	    if (nd_type(node) == NODE_IFUNC && node->nd_cfnc == bmcall) {
+		/* method(:foo).to_proc.arity */
+		return method_arity(node->nd_tval);
+	    }
+	}
+    }
+    return -1;
+}
+
 int
 rb_proc_arity(VALUE self)
 {
@@ -1629,7 +1670,7 @@
     return INT2FIX(n);
 }
 
-static int
+int
 method_arity(VALUE method)
 {
     struct METHOD *data;
Index: thread.c
===================================================================
--- thread.c	(revision 27984)
+++ thread.c	(working copy)
@@ -94,7 +94,7 @@
 };
 
 static void set_unblock_function(rb_thread_t *th, rb_unblock_function_t *func, void *arg,
-				 struct rb_unblock_callback *old);
+                                 struct rb_unblock_callback *old);
 static void reset_unblock_function(rb_thread_t *th, const struct rb_unblock_callback *old);
 
 static inline void blocking_region_end(rb_thread_t *th, struct rb_blocking_region_buffer *region);
@@ -117,7 +117,7 @@
 
 #define BLOCKING_REGION_CORE(exec) do { \
     GVL_UNLOCK_BEGIN(); {\
-	    exec; \
+            exec; \
     } \
     GVL_UNLOCK_END(); \
 } while(0);
@@ -197,7 +197,7 @@
 #define thread_start_func_2(th, st, rst) thread_start_func_2(th, st)
 #endif
 NOINLINE(static int thread_start_func_2(rb_thread_t *th, VALUE *stack_start,
-					VALUE *register_stack_start));
+                                        VALUE *register_stack_start));
 static void timer_thread_function(void *);
 
 #if   defined(_WIN32)
@@ -239,8 +239,8 @@
     if (!rb_thread_debug_enabled) return;
 
     if (debug_mutex_initialized == 1) {
-	debug_mutex_initialized = 0;
-	native_mutex_initialize(&debug_mutex);
+        debug_mutex_initialized = 0;
+        native_mutex_initialize(&debug_mutex);
     }
 
     va_start(args, fmt);
@@ -265,19 +265,19 @@
 
 static void
 set_unblock_function(rb_thread_t *th, rb_unblock_function_t *func, void *arg,
-		     struct rb_unblock_callback *old)
+                     struct rb_unblock_callback *old)
 {
   check_ints:
     RUBY_VM_CHECK_INTS(); /* check signal or so */
     native_mutex_lock(&th->interrupt_lock);
     if (th->interrupt_flag) {
-	native_mutex_unlock(&th->interrupt_lock);
-	goto check_ints;
+        native_mutex_unlock(&th->interrupt_lock);
+        goto check_ints;
     }
     else {
-	if (old) *old = th->unblock;
-	th->unblock.func = func;
-	th->unblock.arg = arg;
+        if (old) *old = th->unblock;
+        th->unblock.func = func;
+        th->unblock.arg = arg;
     }
     native_mutex_unlock(&th->interrupt_lock);
 }
@@ -296,10 +296,10 @@
     native_mutex_lock(&th->interrupt_lock);
     RUBY_VM_SET_INTERRUPT(th);
     if (th->unblock.func) {
-	(th->unblock.func)(th->unblock.arg);
+        (th->unblock.func)(th->unblock.arg);
     }
     else {
-	/* none */
+        /* none */
     }
     native_mutex_unlock(&th->interrupt_lock);
 }
@@ -313,13 +313,13 @@
     GetThreadPtr(thval, th);
 
     if (th != main_thread) {
-	thread_debug("terminate_i: %p\n", (void *)th);
-	rb_threadptr_interrupt(th);
-	th->thrown_errinfo = eTerminateSignal;
-	th->status = THREAD_TO_KILL;
+        thread_debug("terminate_i: %p\n", (void *)th);
+        rb_threadptr_interrupt(th);
+        th->thrown_errinfo = eTerminateSignal;
+        th->status = THREAD_TO_KILL;
     }
     else {
-	thread_debug("terminate_i: main thread (%p)\n", (void *)th);
+        thread_debug("terminate_i: main thread (%p)\n", (void *)th);
     }
     return ST_CONTINUE;
 }
@@ -336,6 +336,16 @@
 static void rb_mutex_unlock_all(mutex_t *mutex, rb_thread_t *th);
 static void rb_mutex_abandon_all(mutex_t *mutexes);
 
+
+rb_control_frame_t *
+thread_context_frame(rb_thread_t *th) 
+{
+  if (th == NULL || ((VALUE) th) == Qnil)
+    th = GET_THREAD(); /* main thread */
+  return rb_vm_get_ruby_level_next_cfp(th, th->cfp);
+}
+
+
 void
 rb_thread_terminate_all(void)
 {
@@ -343,27 +353,27 @@
     rb_vm_t *vm = th->vm;
 
     if (vm->main_thread != th) {
-	rb_bug("rb_thread_terminate_all: called by child thread (%p, %p)",
-	       (void *)vm->main_thread, (void *)th);
+        rb_bug("rb_thread_terminate_all: called by child thread (%p, %p)",
+               (void *)vm->main_thread, (void *)th);
     }
 
     /* unlock all locking mutexes */
     if (th->keeping_mutexes) {
-	rb_mutex_unlock_all(th->keeping_mutexes, GET_THREAD());
+        rb_mutex_unlock_all(th->keeping_mutexes, GET_THREAD());
     }
 
     thread_debug("rb_thread_terminate_all (main thread: %p)\n", (void *)th);
     st_foreach(vm->living_threads, terminate_i, (st_data_t)th);
 
     while (!rb_thread_alone()) {
-	PUSH_TAG();
-	if (EXEC_TAG() == 0) {
-	    rb_thread_schedule();
-	}
-	else {
-	    /* ignore exception */
-	}
-	POP_TAG();
+        PUSH_TAG();
+        if (EXEC_TAG() == 0) {
+            rb_thread_schedule();
+        }
+        else {
+            /* ignore exception */
+        }
+        POP_TAG();
     }
     rb_thread_stop_timer_thread();
 }
@@ -372,8 +382,8 @@
 thread_unlock_all_locking_mutexes(rb_thread_t *th)
 {
     if (th->keeping_mutexes) {
-	rb_mutex_unlock_all(th->keeping_mutexes, th);
-	th->keeping_mutexes = NULL;
+        rb_mutex_unlock_all(th->keeping_mutexes, th);
+        th->keeping_mutexes = NULL;
     }
 }
 
@@ -433,98 +443,98 @@
 
     native_mutex_lock(&th->vm->global_vm_lock);
     {
-	thread_debug("thread start (get lock): %p\n", (void *)th);
-	rb_thread_set_current(th);
+        thread_debug("thread start (get lock): %p\n", (void *)th);
+        rb_thread_set_current(th);
 
-	TH_PUSH_TAG(th);
-	if ((state = EXEC_TAG()) == 0) {
-	    SAVE_ROOT_JMPBUF(th, {
-		if (!th->first_func) {
-		    GetProcPtr(th->first_proc, proc);
-		    th->errinfo = Qnil;
-		    th->local_lfp = proc->block.lfp;
-		    th->local_svar = Qnil;
-		    th->value = rb_vm_invoke_proc(th, proc, proc->block.self,
-						  (int)RARRAY_LEN(args), RARRAY_PTR(args), 0);
-		}
-		else {
-		    th->value = (*th->first_func)((void *)args);
-		}
-	    });
-	}
-	else {
-	    errinfo = th->errinfo;
-	    if (NIL_P(errinfo)) errinfo = rb_errinfo();
-	    if (state == TAG_FATAL) {
-		/* fatal error within this thread, need to stop whole script */
-	    }
-	    else if (rb_obj_is_kind_of(errinfo, rb_eSystemExit)) {
-		if (th->safe_level >= 4) {
-		    th->errinfo = rb_exc_new3(rb_eSecurityError,
-					      rb_sprintf("Insecure exit at level %d", th->safe_level));
-		    errinfo = Qnil;
-		}
-	    }
-	    else if (th->safe_level < 4 &&
-		     (th->vm->thread_abort_on_exception ||
-		      th->abort_on_exception || RTEST(ruby_debug))) {
-		/* exit on main_thread */
-	    }
-	    else {
-		errinfo = Qnil;
-	    }
-	    th->value = Qnil;
-	}
+        TH_PUSH_TAG(th);
+        if ((state = EXEC_TAG()) == 0) {
+            SAVE_ROOT_JMPBUF(th, {
+                if (!th->first_func) {
+                    GetProcPtr(th->first_proc, proc);
+                    th->errinfo = Qnil;
+                    th->local_lfp = proc->block.lfp;
+                    th->local_svar = Qnil;
+                    th->value = rb_vm_invoke_proc(th, proc, proc->block.self,
+                                                  (int)RARRAY_LEN(args), RARRAY_PTR(args), 0);
+                }
+                else {
+                    th->value = (*th->first_func)((void *)args);
+                }
+            });
+        }
+        else {
+            errinfo = th->errinfo;
+            if (NIL_P(errinfo)) errinfo = rb_errinfo();
+            if (state == TAG_FATAL) {
+                /* fatal error within this thread, need to stop whole script */
+            }
+            else if (rb_obj_is_kind_of(errinfo, rb_eSystemExit)) {
+                if (th->safe_level >= 4) {
+                    th->errinfo = rb_exc_new3(rb_eSecurityError,
+                                              rb_sprintf("Insecure exit at level %d", th->safe_level));
+                    errinfo = Qnil;
+                }
+            }
+            else if (th->safe_level < 4 &&
+                     (th->vm->thread_abort_on_exception ||
+                      th->abort_on_exception || RTEST(ruby_debug))) {
+                /* exit on main_thread */
+            }
+            else {
+                errinfo = Qnil;
+            }
+            th->value = Qnil;
+        }
 
-	th->status = THREAD_KILLED;
-	thread_debug("thread end: %p\n", (void *)th);
+        th->status = THREAD_KILLED;
+        thread_debug("thread end: %p\n", (void *)th);
 
-	main_th = th->vm->main_thread;
-	if (th != main_th) {
-	    if (TYPE(errinfo) == T_OBJECT) {
-		/* treat with normal error object */
-		rb_threadptr_raise(main_th, 1, &errinfo);
-	    }
-	}
-	TH_POP_TAG();
+        main_th = th->vm->main_thread;
+        if (th != main_th) {
+            if (TYPE(errinfo) == T_OBJECT) {
+                /* treat with normal error object */
+                rb_threadptr_raise(main_th, 1, &errinfo);
+            }
+        }
+        TH_POP_TAG();
 
-	/* locking_mutex must be Qfalse */
-	if (th->locking_mutex != Qfalse) {
-	    rb_bug("thread_start_func_2: locking_mutex must not be set (%p:%"PRIxVALUE")",
-		   (void *)th, th->locking_mutex);
-	}
+        /* locking_mutex must be Qfalse */
+        if (th->locking_mutex != Qfalse) {
+            rb_bug("thread_start_func_2: locking_mutex must not be set (%p:%"PRIxVALUE")",
+                   (void *)th, th->locking_mutex);
+        }
 
-	/* delete self other than main thread from living_threads */
-	if (th != main_th) {
-	    st_delete_wrap(th->vm->living_threads, th->self);
-	}
+        /* delete self other than main thread from living_threads */
+        if (th != main_th) {
+            st_delete_wrap(th->vm->living_threads, th->self);
+        }
 
-	/* wake up joining threads */
-	join_th = th->join_list_head;
-	while (join_th) {
-	    if (join_th == main_th) errinfo = Qnil;
-	    rb_threadptr_interrupt(join_th);
-	    switch (join_th->status) {
-	      case THREAD_STOPPED: case THREAD_STOPPED_FOREVER:
-		join_th->status = THREAD_RUNNABLE;
-	      default: break;
-	    }
-	    join_th = join_th->join_list_next;
-	}
+        /* wake up joining threads */
+        join_th = th->join_list_head;
+        while (join_th) {
+            if (join_th == main_th) errinfo = Qnil;
+            rb_threadptr_interrupt(join_th);
+            switch (join_th->status) {
+              case THREAD_STOPPED: case THREAD_STOPPED_FOREVER:
+                join_th->status = THREAD_RUNNABLE;
+              default: break;
+            }
+            join_th = join_th->join_list_next;
+        }
 
-	if (!th->root_fiber) {
-	    rb_thread_recycle_stack_release(th->stack);
-	    th->stack = 0;
-	}
+        if (!th->root_fiber) {
+            rb_thread_recycle_stack_release(th->stack);
+            th->stack = 0;
+        }
     }
     thread_unlock_all_locking_mutexes(th);
     if (th != main_th) rb_check_deadlock(th->vm);
     if (th->vm->main_thread == th) {
-	ruby_cleanup(state);
+        ruby_cleanup(state);
     }
     else {
-	thread_cleanup_func(th);
-	native_mutex_unlock(&th->vm->global_vm_lock);
+        thread_cleanup_func(th);
+        native_mutex_unlock(&th->vm->global_vm_lock);
     }
 
     return 0;
@@ -537,8 +547,8 @@
     int err;
 
     if (OBJ_FROZEN(GET_THREAD()->thgroup)) {
-	rb_raise(rb_eThreadError,
-		 "can't start a new thread (frozen ThreadGroup)");
+        rb_raise(rb_eThreadError,
+                 "can't start a new thread (frozen ThreadGroup)");
     }
     GetThreadPtr(thval, th);
 
@@ -552,15 +562,15 @@
 
     native_mutex_initialize(&th->interrupt_lock);
     if (GET_VM()->event_hooks != NULL)
-	th->event_flags |= RUBY_EVENT_VM;
+        th->event_flags |= RUBY_EVENT_VM;
 
     /* kick thread */
     st_insert(th->vm->living_threads, thval, (st_data_t) th->thread_id);
     err = native_thread_create(th);
     if (err) {
-	st_delete_wrap(th->vm->living_threads, th->self);
-	th->status = THREAD_KILLED;
-	rb_raise(rb_eThreadError, "can't create Thread (%d)", err);
+        st_delete_wrap(th->vm->living_threads, th->self);
+        th->status = THREAD_KILLED;
+        rb_raise(rb_eThreadError, "can't create Thread (%d)", err);
     }
     return thval;
 }
@@ -574,8 +584,8 @@
     rb_obj_call_init(thread, argc, argv);
     GetThreadPtr(thread, th);
     if (!th->first_args) {
-	rb_raise(rb_eThreadError, "uninitialized thread - check `%s#initialize'",
-		 rb_class2name(klass));
+        rb_raise(rb_eThreadError, "uninitialized thread - check `%s#initialize'",
+                 rb_class2name(klass));
     }
     return thread;
 }
@@ -602,21 +612,21 @@
 {
     rb_thread_t *th;
     if (!rb_block_given_p()) {
-	rb_raise(rb_eThreadError, "must be called with a block");
+        rb_raise(rb_eThreadError, "must be called with a block");
     }
     GetThreadPtr(thread, th);
     if (th->first_args) {
-	VALUE rb_proc_location(VALUE self);
-	VALUE proc = th->first_proc, line, loc;
-	const char *file;
+        VALUE rb_proc_location(VALUE self);
+        VALUE proc = th->first_proc, line, loc;
+        const char *file;
         if (!proc || !RTEST(loc = rb_proc_location(proc))) {
             rb_raise(rb_eThreadError, "already initialized thread");
         }
-	file = RSTRING_PTR(RARRAY_PTR(loc)[0]);
-	if (NIL_P(line = RARRAY_PTR(loc)[1])) {
-	    rb_raise(rb_eThreadError, "already initialized thread - %s",
-		     file);
-	}
+        file = RSTRING_PTR(RARRAY_PTR(loc)[0]);
+        if (NIL_P(line = RARRAY_PTR(loc)[1])) {
+            rb_raise(rb_eThreadError, "already initialized thread - %s",
+                     file);
+        }
         rb_raise(rb_eThreadError, "already initialized thread - %s:%d",
                  file, NUM2INT(line));
     }
@@ -646,15 +656,15 @@
     rb_thread_t *target_th = p->target, *th = p->waiting;
 
     if (target_th->status != THREAD_KILLED) {
-	rb_thread_t **pth = &target_th->join_list_head;
+        rb_thread_t **pth = &target_th->join_list_head;
 
-	while (*pth) {
-	    if (*pth == th) {
-		*pth = th->join_list_next;
-		break;
-	    }
-	    pth = &(*pth)->join_list_next;
-	}
+        while (*pth) {
+            if (*pth == th) {
+                *pth = th->join_list_next;
+                break;
+            }
+            pth = &(*pth)->join_list_next;
+        }
     }
 
     return Qnil;
@@ -668,20 +678,20 @@
     double now, limit = p->limit;
 
     while (target_th->status != THREAD_KILLED) {
-	if (p->forever) {
-	    sleep_forever(th, 1);
-	}
-	else {
-	    now = timeofday();
-	    if (now > limit) {
-		thread_debug("thread_join: timeout (thid: %p)\n",
-			     (void *)target_th->thread_id);
-		return Qfalse;
-	    }
-	    sleep_wait_for_interrupt(th, limit - now);
-	}
-	thread_debug("thread_join: interrupted (thid: %p)\n",
-		     (void *)target_th->thread_id);
+        if (p->forever) {
+            sleep_forever(th, 1);
+        }
+        else {
+            now = timeofday();
+            if (now > limit) {
+                thread_debug("thread_join: timeout (thid: %p)\n",
+                             (void *)target_th->thread_id);
+                return Qfalse;
+            }
+            sleep_wait_for_interrupt(th, limit - now);
+        }
+        thread_debug("thread_join: interrupted (thid: %p)\n",
+                     (void *)target_th->thread_id);
     }
     return Qtrue;
 }
@@ -700,31 +710,31 @@
     thread_debug("thread_join (thid: %p)\n", (void *)target_th->thread_id);
 
     if (target_th->status != THREAD_KILLED) {
-	th->join_list_next = target_th->join_list_head;
-	target_th->join_list_head = th;
-	if (!rb_ensure(thread_join_sleep, (VALUE)&arg,
-		       remove_from_join_list, (VALUE)&arg)) {
-	    return Qnil;
-	}
+        th->join_list_next = target_th->join_list_head;
+        target_th->join_list_head = th;
+        if (!rb_ensure(thread_join_sleep, (VALUE)&arg,
+                       remove_from_join_list, (VALUE)&arg)) {
+            return Qnil;
+        }
     }
 
     thread_debug("thread_join: success (thid: %p)\n",
-		 (void *)target_th->thread_id);
+                 (void *)target_th->thread_id);
 
     if (target_th->errinfo != Qnil) {
-	VALUE err = target_th->errinfo;
+        VALUE err = target_th->errinfo;
 
-	if (FIXNUM_P(err)) {
-	    /* */
-	}
-	else if (TYPE(target_th->errinfo) == T_NODE) {
-	    rb_exc_raise(rb_vm_make_jump_tag_but_local_jump(
-		GET_THROWOBJ_STATE(err), GET_THROWOBJ_VAL(err)));
-	}
-	else {
-	    /* normal exception */
-	    rb_exc_raise(err);
-	}
+        if (FIXNUM_P(err)) {
+            /* */
+        }
+        else if (TYPE(target_th->errinfo) == T_NODE) {
+            rb_exc_raise(rb_vm_make_jump_tag_but_local_jump(
+                GET_THROWOBJ_STATE(err), GET_THROWOBJ_VAL(err)));
+        }
+        else {
+            /* normal exception */
+            rb_exc_raise(err);
+        }
     }
     return target_th->self;
 }
@@ -780,7 +790,7 @@
 
     rb_scan_args(argc, argv, "01", &limit);
     if (!NIL_P(limit)) {
-	delay = rb_num2dbl(limit);
+        delay = rb_num2dbl(limit);
     }
 
     return thread_join(target_th, delay);
@@ -818,8 +828,8 @@
     time.tv_sec = (int)d;
     time.tv_usec = (int)((d - (int)d) * 1e6);
     if (time.tv_usec < 0) {
-	time.tv_usec += (int)1e6;
-	time.tv_sec -= 1;
+        time.tv_usec += (int)1e6;
+        time.tv_sec -= 1;
     }
     return time;
 }
@@ -831,15 +841,15 @@
 
     th->status = deadlockable ? THREAD_STOPPED_FOREVER : THREAD_STOPPED;
     do {
-	if (deadlockable) {
-	    th->vm->sleeper++;
-	    rb_check_deadlock(th->vm);
-	}
-	native_sleep(th, 0);
-	if (deadlockable) {
-	    th->vm->sleeper--;
-	}
-	RUBY_VM_CHECK_INTS();
+        if (deadlockable) {
+            th->vm->sleeper++;
+            rb_check_deadlock(th->vm);
+        }
+        native_sleep(th, 0);
+        if (deadlockable) {
+            th->vm->sleeper--;
+        }
+        RUBY_VM_CHECK_INTS();
     } while (th->status == THREAD_STOPPED_FOREVER);
     th->status = prev_status;
 }
@@ -851,8 +861,8 @@
     struct timespec ts;
 
     if (clock_gettime(CLOCK_MONOTONIC, &ts) == 0) {
-	tp->tv_sec = ts.tv_sec;
-	tp->tv_usec = ts.tv_nsec / 1000;
+        tp->tv_sec = ts.tv_sec;
+        tp->tv_usec = ts.tv_nsec / 1000;
     } else
 #endif
     {
@@ -869,25 +879,25 @@
     getclockofday(&to);
     to.tv_sec += tv.tv_sec;
     if ((to.tv_usec += tv.tv_usec) >= 1000000) {
-	to.tv_sec++;
-	to.tv_usec -= 1000000;
+        to.tv_sec++;
+        to.tv_usec -= 1000000;
     }
 
     th->status = THREAD_STOPPED;
     do {
-	native_sleep(th, &tv);
-	RUBY_VM_CHECK_INTS();
-	getclockofday(&tvn);
-	if (to.tv_sec < tvn.tv_sec) break;
-	if (to.tv_sec == tvn.tv_sec && to.tv_usec <= tvn.tv_usec) break;
-	thread_debug("sleep_timeval: %ld.%.6ld > %ld.%.6ld\n",
-		     (long)to.tv_sec, (long)to.tv_usec,
-		     (long)tvn.tv_sec, (long)tvn.tv_usec);
-	tv.tv_sec = to.tv_sec - tvn.tv_sec;
-	if ((tv.tv_usec = to.tv_usec - tvn.tv_usec) < 0) {
-	    --tv.tv_sec;
-	    tv.tv_usec += 1000000;
-	}
+        native_sleep(th, &tv);
+        RUBY_VM_CHECK_INTS();
+        getclockofday(&tvn);
+        if (to.tv_sec < tvn.tv_sec) break;
+        if (to.tv_sec == tvn.tv_sec && to.tv_usec <= tvn.tv_usec) break;
+        thread_debug("sleep_timeval: %ld.%.6ld > %ld.%.6ld\n",
+                     (long)to.tv_sec, (long)to.tv_usec,
+                     (long)tvn.tv_sec, (long)tvn.tv_usec);
+        tv.tv_sec = to.tv_sec - tvn.tv_sec;
+        if ((tv.tv_usec = to.tv_usec - tvn.tv_usec) < 0) {
+            --tv.tv_sec;
+            tv.tv_usec += 1000000;
+        }
     } while (th->status == THREAD_STOPPED);
     th->status = prev_status;
 }
@@ -934,7 +944,7 @@
 {
     struct timeval time;
     time.tv_sec = 0;
-    time.tv_usec = 100 * 1000;	/* 0.1 sec */
+    time.tv_usec = 100 * 1000;  /* 0.1 sec */
     sleep_timeval(th, time);
 }
 
@@ -950,8 +960,8 @@
 {
     RUBY_VM_CHECK_INTS();
     if (!rb_thread_alone()) {
-	rb_thread_t *th = GET_THREAD();
-	sleep_for_polling(th);
+        rb_thread_t *th = GET_THREAD();
+        sleep_for_polling(th);
     }
 }
 
@@ -1002,19 +1012,19 @@
 {
     thread_debug("rb_thread_schedule\n");
     if (!rb_thread_alone()) {
-	rb_thread_t *th = GET_THREAD();
+        rb_thread_t *th = GET_THREAD();
 
-	thread_debug("rb_thread_schedule/switch start\n");
+        thread_debug("rb_thread_schedule/switch start\n");
 
-	RB_GC_SAVE_MACHINE_CONTEXT(th);
-	native_mutex_unlock(&th->vm->global_vm_lock);
-	{
-	    native_thread_yield();
-	}
-	native_mutex_lock(&th->vm->global_vm_lock);
+        RB_GC_SAVE_MACHINE_CONTEXT(th);
+        native_mutex_unlock(&th->vm->global_vm_lock);
+        {
+            native_thread_yield();
+        }
+        native_mutex_lock(&th->vm->global_vm_lock);
 
-	rb_thread_set_current(th);
-	thread_debug("rb_thread_schedule/switch done\n");
+        rb_thread_set_current(th);
+        thread_debug("rb_thread_schedule/switch done\n");
 
         if (!sched_depth && UNLIKELY(GET_THREAD()->interrupt_flag)) {
             rb_threadptr_execute_interrupts_rec(GET_THREAD(), sched_depth+1);
@@ -1040,7 +1050,7 @@
     th->blocking_region_buffer = 0;
     reset_unblock_function(th, &region->oldubf);
     if (th->status == THREAD_STOPPED) {
-	th->status = region->prev_status;
+        th->status = region->prev_status;
     }
 }
 
@@ -1110,13 +1120,13 @@
     int saved_errno = 0;
 
     if (ubf == RUBY_UBF_IO || ubf == RUBY_UBF_PROCESS) {
-	ubf = ubf_select;
-	data2 = th;
+        ubf = ubf_select;
+        data2 = th;
     }
 
     BLOCKING_REGION({
-	val = func(data1);
-	saved_errno = errno;
+        val = func(data1);
+        saved_errno = errno;
     }, ubf, data2);
     errno = saved_errno;
 
@@ -1174,20 +1184,20 @@
     void *r;
 
     if (th == 0) {
-	/* Error is occurred, but we can't use rb_bug()
-	 * because this thread is not Ruby's thread.
+        /* Error is occurred, but we can't use rb_bug()
+         * because this thread is not Ruby's thread.
          * What should we do?
-	 */
+         */
 
-	fprintf(stderr, "[BUG] rb_thread_call_with_gvl() is called by non-ruby thread\n");
-	exit(1);
+        fprintf(stderr, "[BUG] rb_thread_call_with_gvl() is called by non-ruby thread\n");
+        exit(1);
     }
 
     brb = (struct rb_blocking_region_buffer *)th->blocking_region_buffer;
     prev_unblock = th->unblock;
 
     if (brb == 0) {
-	rb_bug("rb_thread_call_with_gvl: called by a thread which has GVL.");
+        rb_bug("rb_thread_call_with_gvl: called by a thread which has GVL.");
     }
 
     blocking_region_end(th, brb);
@@ -1213,10 +1223,10 @@
     rb_thread_t *th = ruby_thread_from_native();
 
     if (th && th->blocking_region_buffer == 0) {
-	return 1;
+        return 1;
     }
     else {
-	return 0;
+        return 0;
     }
 }
 
@@ -1255,65 +1265,65 @@
 rb_threadptr_execute_interrupts_rec(rb_thread_t *th, int sched_depth)
 {
     if (GET_VM()->main_thread == th) {
-	while (rb_signal_buff_size() && !th->exec_signal) native_thread_yield();
+        while (rb_signal_buff_size() && !th->exec_signal) native_thread_yield();
     }
 
     if (th->raised_flag) return;
 
     while (th->interrupt_flag) {
-	enum rb_thread_status status = th->status;
-	int timer_interrupt = th->interrupt_flag & 0x01;
-	int finalizer_interrupt = th->interrupt_flag & 0x04;
+        enum rb_thread_status status = th->status;
+        int timer_interrupt = th->interrupt_flag & 0x01;
+        int finalizer_interrupt = th->interrupt_flag & 0x04;
 
-	th->status = THREAD_RUNNABLE;
-	th->interrupt_flag = 0;
+        th->status = THREAD_RUNNABLE;
+        th->interrupt_flag = 0;
 
-	/* signal handling */
-	if (th->exec_signal) {
-	    int sig = th->exec_signal;
-	    th->exec_signal = 0;
-	    rb_signal_exec(th, sig);
-	}
+        /* signal handling */
+        if (th->exec_signal) {
+            int sig = th->exec_signal;
+            th->exec_signal = 0;
+            rb_signal_exec(th, sig);
+        }
 
-	/* exception from another thread */
-	if (th->thrown_errinfo) {
-	    VALUE err = th->thrown_errinfo;
-	    th->thrown_errinfo = 0;
-	    thread_debug("rb_thread_execute_interrupts: %ld\n", err);
+        /* exception from another thread */
+        if (th->thrown_errinfo) {
+            VALUE err = th->thrown_errinfo;
+            th->thrown_errinfo = 0;
+            thread_debug("rb_thread_execute_interrupts: %ld\n", err);
 
-	    if (err == eKillSignal || err == eTerminateSignal) {
-		th->errinfo = INT2FIX(TAG_FATAL);
-		TH_JUMP_TAG(th, TAG_FATAL);
-	    }
-	    else {
-		rb_exc_raise(err);
-	    }
-	}
-	th->status = status;
+            if (err == eKillSignal || err == eTerminateSignal) {
+                th->errinfo = INT2FIX(TAG_FATAL);
+                TH_JUMP_TAG(th, TAG_FATAL);
+            }
+            else {
+                rb_exc_raise(err);
+            }
+        }
+        th->status = status;
 
-	if (finalizer_interrupt) {
-	    rb_gc_finalize_deferred();
-	}
+        if (finalizer_interrupt) {
+            rb_gc_finalize_deferred();
+        }
 
-	if (!sched_depth && timer_interrupt) {
+        if (!sched_depth && timer_interrupt) {
             sched_depth++;
-	    EXEC_EVENT_HOOK(th, RUBY_EVENT_SWITCH, th->cfp->self, 0, 0);
+            EXEC_EVENT_HOOK(th, RUBY_EVENT_SWITCH, th->cfp->self, 0, 0);
 
-	    if (th->slice > 0) {
-		th->slice--;
-	    }
-	    else {
-	      reschedule:
-		rb_thread_schedule_rec(sched_depth+1);
-		if (th->slice < 0) {
-		    th->slice++;
-		    goto reschedule;
-		}
-		else {
-		    th->slice = th->priority;
-		}
-	    }
-	}
+            if (th->slice > 0) {
+                th->slice--;
+            }
+            else {
+              reschedule:
+                rb_thread_schedule_rec(sched_depth+1);
+                if (th->slice < 0) {
+                    th->slice++;
+                    goto reschedule;
+                }
+                else {
+                    th->slice = th->priority;
+                }
+            }
+        }
     }
 }
 
@@ -1344,12 +1354,12 @@
 
   again:
     if (rb_threadptr_dead(th)) {
-	return Qnil;
+        return Qnil;
     }
 
     if (th->thrown_errinfo != 0 || th->raised_flag) {
-	rb_thread_schedule();
-	goto again;
+        rb_thread_schedule();
+        goto again;
     }
 
     exc = rb_make_exception(argc, argv);
@@ -1399,7 +1409,7 @@
 rb_threadptr_set_raised(rb_thread_t *th)
 {
     if (th->raised_flag & RAISED_EXCEPTION) {
-	return 1;
+        return 1;
     }
     th->raised_flag |= RAISED_EXCEPTION;
     return 0;
@@ -1409,7 +1419,7 @@
 rb_threadptr_reset_raised(rb_thread_t *th)
 {
     if (!(th->raised_flag & RAISED_EXCEPTION)) {
-	return 0;
+        return 0;
     }
     th->raised_flag &= ~RAISED_EXCEPTION;
     return 1;
@@ -1437,9 +1447,9 @@
  *  <em>produces:</em>
  *
  *     prog.rb:3: Gotcha (RuntimeError)
- *     	from prog.rb:2:in `initialize'
- *     	from prog.rb:2:in `new'
- *     	from prog.rb:2
+ *      from prog.rb:2:in `initialize'
+ *      from prog.rb:2:in `new'
+ *      from prog.rb:2
  */
 
 static VALUE
@@ -1472,13 +1482,13 @@
     GetThreadPtr(thread, th);
 
     if (th != GET_THREAD() && th->safe_level < 4) {
-	rb_secure(4);
+        rb_secure(4);
     }
     if (th->status == THREAD_TO_KILL || th->status == THREAD_KILLED) {
-	return thread;
+        return thread;
     }
     if (th == th->vm->main_thread) {
-	rb_exit(EXIT_SUCCESS);
+        rb_exit(EXIT_SUCCESS);
     }
 
     thread_debug("rb_thread_kill: %p (%p)\n", (void *)th, (void *)th->thread_id);
@@ -1551,11 +1561,11 @@
     GetThreadPtr(thread, th);
 
     if (th->status == THREAD_KILLED) {
-	rb_raise(rb_eThreadError, "killed thread");
+        rb_raise(rb_eThreadError, "killed thread");
     }
     rb_threadptr_ready(th);
     if (th->status != THREAD_TO_KILL) {
-	th->status = THREAD_RUNNABLE;
+        th->status = THREAD_RUNNABLE;
     }
     return thread;
 }
@@ -1611,8 +1621,8 @@
 rb_thread_stop(void)
 {
     if (rb_thread_alone()) {
-	rb_raise(rb_eThreadError,
-		 "stopping only thread\n\tnote: use sleep to stop forever");
+        rb_raise(rb_eThreadError,
+                 "stopping only thread\n\tnote: use sleep to stop forever");
     }
     rb_thread_sleep_deadly();
     return Qnil;
@@ -1630,9 +1640,9 @@
       case THREAD_STOPPED:
       case THREAD_STOPPED_FOREVER:
       case THREAD_TO_KILL:
-	rb_ary_push(ary, th->self);
+        rb_ary_push(ary, th->self);
       default:
-	break;
+        break;
     }
     return ST_CONTINUE;
 }
@@ -1746,9 +1756,9 @@
  *
  *     In new thread
  *     prog.rb:4: Exception from thread (RuntimeError)
- *     	from prog.rb:2:in `initialize'
- *     	from prog.rb:2:in `new'
- *     	from prog.rb:2
+ *      from prog.rb:2:in `initialize'
+ *      from prog.rb:2:in `new'
+ *      from prog.rb:2
  */
 
 static VALUE
@@ -1818,7 +1828,7 @@
     group = th->thgroup;
 
     if (!group) {
-	group = Qnil;
+        group = Qnil;
     }
     return group;
 }
@@ -1828,16 +1838,16 @@
 {
     switch (status) {
       case THREAD_RUNNABLE:
-	return "run";
+        return "run";
       case THREAD_STOPPED:
       case THREAD_STOPPED_FOREVER:
-	return "sleep";
+        return "sleep";
       case THREAD_TO_KILL:
-	return "aborting";
+        return "aborting";
       case THREAD_KILLED:
-	return "dead";
+        return "dead";
       default:
-	return "unknown";
+        return "unknown";
     }
 }
 
@@ -1877,11 +1887,11 @@
     GetThreadPtr(thread, th);
 
     if (rb_threadptr_dead(th)) {
-	if (!NIL_P(th->errinfo) && !FIXNUM_P(th->errinfo)
-	    /* TODO */ ) {
-	    return Qnil;
-	}
-	return Qfalse;
+        if (!NIL_P(th->errinfo) && !FIXNUM_P(th->errinfo)
+            /* TODO */ ) {
+            return Qnil;
+        }
+        return Qfalse;
     }
     return rb_str_new2(thread_status_name(th->status));
 }
@@ -1906,7 +1916,7 @@
     GetThreadPtr(thread, th);
 
     if (rb_threadptr_dead(th))
-	return Qfalse;
+        return Qfalse;
     return Qtrue;
 }
 
@@ -1929,9 +1939,9 @@
     GetThreadPtr(thread, th);
 
     if (rb_threadptr_dead(th))
-	return Qtrue;
+        return Qtrue;
     if (th->status == THREAD_STOPPED || th->status == THREAD_STOPPED_FOREVER)
-	return Qtrue;
+        return Qtrue;
     return Qfalse;
 }
 
@@ -1987,13 +1997,13 @@
 
     GetThreadPtr(thread, th);
     if (rb_safe_level() >= 4 && th != GET_THREAD()) {
-	rb_raise(rb_eSecurityError, "Insecure: thread locals");
+        rb_raise(rb_eSecurityError, "Insecure: thread locals");
     }
     if (!th->local_storage) {
-	return Qnil;
+        return Qnil;
     }
     if (st_lookup(th->local_storage, id, &val)) {
-	return val;
+        return val;
     }
     return Qnil;
 }
@@ -2032,17 +2042,17 @@
     GetThreadPtr(thread, th);
 
     if (rb_safe_level() >= 4 && th != GET_THREAD()) {
-	rb_raise(rb_eSecurityError, "Insecure: can't modify thread locals");
+        rb_raise(rb_eSecurityError, "Insecure: can't modify thread locals");
     }
     if (OBJ_FROZEN(thread)) {
-	rb_error_frozen("thread locals");
+        rb_error_frozen("thread locals");
     }
     if (!th->local_storage) {
-	th->local_storage = st_init_numtable();
+        th->local_storage = st_init_numtable();
     }
     if (NIL_P(val)) {
-	st_delete_wrap(th->local_storage, id);
-	return Qnil;
+        st_delete_wrap(th->local_storage, id);
+        return Qnil;
     }
     st_insert(th->local_storage, id, val);
     return val;
@@ -2084,10 +2094,10 @@
     GetThreadPtr(self, th);
 
     if (!th->local_storage) {
-	return Qfalse;
+        return Qfalse;
     }
     if (st_lookup(th->local_storage, id, 0)) {
-	return Qtrue;
+        return Qtrue;
     }
     return Qfalse;
 }
@@ -2110,8 +2120,8 @@
 {
     int num = 1;
     if (GET_THREAD()->vm->living_threads) {
-	num = vm_living_thread_num(GET_THREAD()->vm);
-	thread_debug("rb_thread_alone: %d\n", num);
+        num = vm_living_thread_num(GET_THREAD()->vm);
+        thread_debug("rb_thread_alone: %d\n", num);
     }
     return num == 1;
 }
@@ -2138,7 +2148,7 @@
     GetThreadPtr(self, th);
 
     if (th->local_storage) {
-	st_foreach(th->local_storage, thread_keys_i, ary);
+        st_foreach(th->local_storage, thread_keys_i, ary);
     }
     return ary;
 }
@@ -2208,10 +2218,10 @@
 #else
     priority = NUM2INT(prio);
     if (priority > RUBY_THREAD_PRIORITY_MAX) {
-	priority = RUBY_THREAD_PRIORITY_MAX;
+        priority = RUBY_THREAD_PRIORITY_MAX;
     }
     else if (priority < RUBY_THREAD_PRIORITY_MIN) {
-	priority = RUBY_THREAD_PRIORITY_MIN;
+        priority = RUBY_THREAD_PRIORITY_MIN;
     }
     th->priority = priority;
     th->slice = priority;
@@ -2270,8 +2280,8 @@
 rb_fd_zero(rb_fdset_t *fds)
 {
     if (fds->fdset) {
-	MEMZERO(fds->fdset, fd_mask, howmany(fds->maxfd, NFDBITS));
-	FD_ZERO(fds->fdset);
+        MEMZERO(fds->fdset, fd_mask, howmany(fds->maxfd, NFDBITS));
+        FD_ZERO(fds->fdset);
     }
 }
 
@@ -2285,8 +2295,8 @@
     if (o < sizeof(fd_set)) o = sizeof(fd_set);
 
     if (m > o) {
-	fds->fdset = realloc(fds->fdset, m);
-	memset((char *)fds->fdset + o, 0, m - o);
+        fds->fdset = realloc(fds->fdset, m);
+        memset((char *)fds->fdset + o, 0, m - o);
     }
     if (n >= fds->maxfd) fds->maxfd = n + 1;
 }
@@ -2347,10 +2357,10 @@
 #undef FD_CLR
 #undef FD_ISSET
 
-#define FD_ZERO(f)	rb_fd_zero(f)
-#define FD_SET(i, f)	rb_fd_set(i, f)
-#define FD_CLR(i, f)	rb_fd_clr(i, f)
-#define FD_ISSET(i, f)	rb_fd_isset(i, f)
+#define FD_ZERO(f)      rb_fd_zero(f)
+#define FD_SET(i, f)    rb_fd_set(i, f)
+#define FD_CLR(i, f)    rb_fd_clr(i, f)
+#define FD_ISSET(i, f)  rb_fd_isset(i, f)
 
 #elif defined(_WIN32)
 
@@ -2382,8 +2392,8 @@
         }
     }
     if (set->fdset->fd_count >= (unsigned)set->capa) {
-	set->capa = (set->fdset->fd_count / FD_SETSIZE + 1) * FD_SETSIZE;
-	set->fdset = xrealloc(set->fdset, sizeof(unsigned int) + sizeof(SOCKET) * set->capa);
+        set->capa = (set->fdset->fd_count / FD_SETSIZE + 1) * FD_SETSIZE;
+        set->fdset = xrealloc(set->fdset, sizeof(unsigned int) + sizeof(SOCKET) * set->capa);
     }
     set->fdset->fd_array[set->fdset->fd_count++] = s;
 }
@@ -2393,10 +2403,10 @@
 #undef FD_CLR
 #undef FD_ISSET
 
-#define FD_ZERO(f)	rb_fd_zero(f)
-#define FD_SET(i, f)	rb_fd_set(i, f)
-#define FD_CLR(i, f)	rb_fd_clr(i, f)
-#define FD_ISSET(i, f)	rb_fd_isset(i, f)
+#define FD_ZERO(f)      rb_fd_zero(f)
+#define FD_SET(i, f)    rb_fd_set(i, f)
+#define FD_CLR(i, f)    rb_fd_clr(i, f)
+#define FD_ISSET(i, f)  rb_fd_isset(i, f)
 
 #endif
 
@@ -2415,11 +2425,11 @@
 	return 0;
     }
     while (rest->tv_usec < wait->tv_usec) {
-	if (rest->tv_sec <= wait->tv_sec) {
-	    return 0;
-	}
-	rest->tv_sec -= 1;
-	rest->tv_usec += 1000 * 1000;
+        if (rest->tv_sec <= wait->tv_sec) {
+            return 0;
+        }
+        rest->tv_sec -= 1;
+        rest->tv_usec += 1000 * 1000;
     }
     rest->tv_sec -= wait->tv_sec;
     rest->tv_usec -= wait->tv_usec;
@@ -2429,7 +2439,7 @@
 
 static int
 do_select(int n, fd_set *read, fd_set *write, fd_set *except,
-	  struct timeval *timeout)
+          struct timeval *timeout)
 {
     int result, lerrno;
     fd_set UNINITIALIZED_VAR(orig_read);
@@ -2445,14 +2455,14 @@
 
     if (timeout) {
 # if defined(__CYGWIN__) || defined(_WIN32)
-	gettimeofday(&start_time, NULL);
-	limit = (double)start_time.tv_sec + (double)start_time.tv_usec*1e-6;
+        gettimeofday(&start_time, NULL);
+        limit = (double)start_time.tv_sec + (double)start_time.tv_usec*1e-6;
 # else
-	limit = timeofday();
+        limit = timeofday();
 # endif
-	limit += (double)timeout->tv_sec+(double)timeout->tv_usec*1e-6;
-	wait_rest = *timeout;
-	timeout = &wait_rest;
+        limit += (double)timeout->tv_sec+(double)timeout->tv_usec*1e-6;
+        wait_rest = *timeout;
+        timeout = &wait_rest;
     }
 #endif
 
@@ -2465,70 +2475,70 @@
 
 #if defined(__CYGWIN__) || defined(_WIN32)
     {
-	int finish = 0;
-	/* polling duration: 100ms */
-	struct timeval wait_100ms, *wait;
-	wait_100ms.tv_sec = 0;
-	wait_100ms.tv_usec = 100 * 1000; /* 100 ms */
+        int finish = 0;
+        /* polling duration: 100ms */
+        struct timeval wait_100ms, *wait;
+        wait_100ms.tv_sec = 0;
+        wait_100ms.tv_usec = 100 * 1000; /* 100 ms */
 
-	do {
-	    wait = (timeout == 0 || cmp_tv(&wait_100ms, timeout) < 0) ? &wait_100ms : timeout;
-	    BLOCKING_REGION({
-		do {
-		    result = select(n, read, write, except, wait);
-		    if (result < 0) lerrno = errno;
-		    if (result != 0) break;
+        do {
+            wait = (timeout == 0 || cmp_tv(&wait_100ms, timeout) < 0) ? &wait_100ms : timeout;
+            BLOCKING_REGION({
+                do {
+                    result = select(n, read, write, except, wait);
+                    if (result < 0) lerrno = errno;
+                    if (result != 0) break;
 
-		    if (read) *read = orig_read;
-		    if (write) *write = orig_write;
-		    if (except) *except = orig_except;
-		    if (timeout) {
-			struct timeval elapsed;
-			gettimeofday(&elapsed, NULL);
-			subtract_tv(&elapsed, &start_time);
-			gettimeofday(&start_time, NULL);
-			if (!subtract_tv(timeout, &elapsed)) {
-			    finish = 1;
-			    break;
-			}
-			if (cmp_tv(&wait_100ms, timeout) > 0) wait = timeout;
-		    }
-		} while (__th->interrupt_flag == 0);
-	    }, 0, 0);
-	} while (result == 0 && !finish);
+                    if (read) *read = orig_read;
+                    if (write) *write = orig_write;
+                    if (except) *except = orig_except;
+                    if (timeout) {
+                        struct timeval elapsed;
+                        gettimeofday(&elapsed, NULL);
+                        subtract_tv(&elapsed, &start_time);
+                        gettimeofday(&start_time, NULL);
+                        if (!subtract_tv(timeout, &elapsed)) {
+                            finish = 1;
+                            break;
+                        }
+                        if (cmp_tv(&wait_100ms, timeout) > 0) wait = timeout;
+                    }
+                } while (__th->interrupt_flag == 0);
+            }, 0, 0);
+        } while (result == 0 && !finish);
     }
 #else
     BLOCKING_REGION({
-	result = select(n, read, write, except, timeout);
-	if (result < 0) lerrno = errno;
+        result = select(n, read, write, except, timeout);
+        if (result < 0) lerrno = errno;
     }, ubf_select, GET_THREAD());
 #endif
 
     errno = lerrno;
 
     if (result < 0) {
-	switch (errno) {
-	  case EINTR:
+        switch (errno) {
+          case EINTR:
 #ifdef ERESTART
-	  case ERESTART:
+          case ERESTART:
 #endif
-	    if (read) *read = orig_read;
-	    if (write) *write = orig_write;
-	    if (except) *except = orig_except;
+            if (read) *read = orig_read;
+            if (write) *write = orig_write;
+            if (except) *except = orig_except;
 #ifndef linux
-	    if (timeout) {
-		double d = limit - timeofday();
+            if (timeout) {
+                double d = limit - timeofday();
 
-		wait_rest.tv_sec = (unsigned int)d;
-		wait_rest.tv_usec = (int)((d-(double)wait_rest.tv_sec)*1e6);
-		if (wait_rest.tv_sec < 0)  wait_rest.tv_sec = 0;
-		if (wait_rest.tv_usec < 0) wait_rest.tv_usec = 0;
-	    }
+                wait_rest.tv_sec = (unsigned int)d;
+                wait_rest.tv_usec = (int)((d-(double)wait_rest.tv_sec)*1e6);
+                if (wait_rest.tv_sec < 0)  wait_rest.tv_sec = 0;
+                if (wait_rest.tv_usec < 0) wait_rest.tv_usec = 0;
+            }
 #endif
-	    goto retry;
-	  default:
-	    break;
-	}
+            goto retry;
+          default:
+            break;
+        }
     }
     return result;
 }
@@ -2540,26 +2550,26 @@
     thread_debug("rb_thread_wait_fd_rw(%d, %s)\n", fd, read ? "read" : "write");
 
     if (fd < 0) {
-	rb_raise(rb_eIOError, "closed stream");
+        rb_raise(rb_eIOError, "closed stream");
     }
     if (rb_thread_alone()) return;
     while (result <= 0) {
-	rb_fdset_t set;
-	rb_fd_init(&set);
-	FD_SET(fd, &set);
+        rb_fdset_t set;
+        rb_fd_init(&set);
+        FD_SET(fd, &set);
 
-	if (read) {
-	    result = do_select(fd + 1, rb_fd_ptr(&set), 0, 0, 0);
-	}
-	else {
-	    result = do_select(fd + 1, 0, rb_fd_ptr(&set), 0, 0);
-	}
+        if (read) {
+            result = do_select(fd + 1, rb_fd_ptr(&set), 0, 0, 0);
+        }
+        else {
+            result = do_select(fd + 1, 0, rb_fd_ptr(&set), 0, 0);
+        }
 
-	rb_fd_term(&set);
+        rb_fd_term(&set);
 
-	if (result < 0) {
-	    rb_sys_fail(0);
-	}
+        if (result < 0) {
+            rb_sys_fail(0);
+        }
     }
 
     thread_debug("rb_thread_wait_fd_rw(%d, %s): done\n", fd, read ? "read" : "write");
@@ -2580,35 +2590,35 @@
 
 int
 rb_thread_select(int max, fd_set * read, fd_set * write, fd_set * except,
-		 struct timeval *timeout)
+                 struct timeval *timeout)
 {
     if (!read && !write && !except) {
-	if (!timeout) {
-	    rb_thread_sleep_forever();
-	    return 0;
-	}
-	rb_thread_wait_for(*timeout);
-	return 0;
+        if (!timeout) {
+            rb_thread_sleep_forever();
+            return 0;
+        }
+        rb_thread_wait_for(*timeout);
+        return 0;
     }
     else {
-	return do_select(max, read, write, except, timeout);
+        return do_select(max, read, write, except, timeout);
     }
 }
 
 
 int
 rb_thread_fd_select(int max, rb_fdset_t * read, rb_fdset_t * write, rb_fdset_t * except,
-		    struct timeval *timeout)
+                    struct timeval *timeout)
 {
     fd_set *r = NULL, *w = NULL, *e = NULL;
 
     if (!read && !write && !except) {
-	if (!timeout) {
-	    rb_thread_sleep_forever();
-	    return 0;
-	}
-	rb_thread_wait_for(*timeout);
-	return 0;
+        if (!timeout) {
+            rb_thread_sleep_forever();
+            return 0;
+        }
+        rb_thread_wait_for(*timeout);
+        return 0;
     }
 
     if (read) {
@@ -2664,13 +2674,13 @@
     /* mth must be main_thread */
 
     if (!mth->exec_signal && (sig = rb_get_next_signal()) > 0) {
-	enum rb_thread_status prev_status = mth->status;
-	thread_debug("main_thread: %s, sig: %d\n",
-		     thread_status_name(prev_status), sig);
-	mth->exec_signal = sig;
-	if (mth->status != THREAD_KILLED) mth->status = THREAD_RUNNABLE;
-	rb_threadptr_interrupt(mth);
-	mth->status = prev_status;
+        enum rb_thread_status prev_status = mth->status;
+        thread_debug("main_thread: %s, sig: %d\n",
+                     thread_status_name(prev_status), sig);
+        mth->exec_signal = sig;
+        if (mth->status != THREAD_KILLED) mth->status = THREAD_RUNNABLE;
+        rb_threadptr_interrupt(mth);
+        mth->status = prev_status;
     }
 }
 
@@ -2688,11 +2698,11 @@
 #if 0
     /* prove profiler */
     if (vm->prove_profile.enable) {
-	rb_thread_t *th = vm->running_thread;
+        rb_thread_t *th = vm->running_thread;
 
-	if (vm->during_gc) {
-	    /* GC prove profiling */
-	}
+        if (vm->during_gc) {
+            /* GC prove profiling */
+        }
     }
 #endif
 }
@@ -2701,7 +2711,7 @@
 rb_thread_stop_timer_thread(void)
 {
     if (timer_thread_id && native_stop_timer_thread()) {
-	native_reset_timer_thread();
+        native_reset_timer_thread();
     }
 }
 
@@ -2725,9 +2735,9 @@
     VALUE lines = (VALUE)val;
 
     for (i = 0; i < RARRAY_LEN(lines); i++) {
-	if (RARRAY_PTR(lines)[i] != Qnil) {
-	    RARRAY_PTR(lines)[i] = INT2FIX(0);
-	}
+        if (RARRAY_PTR(lines)[i] != Qnil) {
+            RARRAY_PTR(lines)[i] = INT2FIX(0);
+        }
     }
     return ST_CONTINUE;
 }
@@ -2738,7 +2748,7 @@
     extern VALUE rb_get_coverages(void);
     VALUE coverages = rb_get_coverages();
     if (RTEST(coverages)) {
-	st_foreach(RHASH_TBL(coverages), clear_coverage_i, 0);
+        st_foreach(RHASH_TBL(coverages), clear_coverage_i, 0);
     }
 }
 
@@ -2766,11 +2776,11 @@
     GetThreadPtr(thval, th);
 
     if (th != (rb_thread_t *)current_th) {
-	if (th->keeping_mutexes) {
-	    rb_mutex_abandon_all(th->keeping_mutexes);
-	}
-	th->keeping_mutexes = NULL;
-	thread_cleanup_func(th);
+        if (th->keeping_mutexes) {
+            rb_mutex_abandon_all(th->keeping_mutexes);
+        }
+        th->keeping_mutexes = NULL;
+        thread_cleanup_func(th);
     }
     return ST_CONTINUE;
 }
@@ -2791,7 +2801,7 @@
     GetThreadPtr(thval, th);
 
     if (th != (rb_thread_t *)current_th) {
-	thread_cleanup_func_before_exec(th);
+        thread_cleanup_func_before_exec(th);
     }
     return ST_CONTINUE;
 }
@@ -2858,7 +2868,7 @@
     GetThreadPtr(thread, th);
 
     if (th->thgroup == group) {
-	rb_ary_push(ary, thread);
+        rb_ary_push(ary, thread);
     }
     return ST_CONTINUE;
 }
@@ -2931,7 +2941,7 @@
 
     TypedData_Get_Struct(group, struct thgroup, &thgroup_data_type, data);
     if (data->enclosed)
-	return Qtrue;
+        return Qtrue;
     return Qfalse;
 }
 
@@ -2972,24 +2982,24 @@
     GetThreadPtr(thread, th);
 
     if (OBJ_FROZEN(group)) {
-	rb_raise(rb_eThreadError, "can't move to the frozen thread group");
+        rb_raise(rb_eThreadError, "can't move to the frozen thread group");
     }
     TypedData_Get_Struct(group, struct thgroup, &thgroup_data_type, data);
     if (data->enclosed) {
-	rb_raise(rb_eThreadError, "can't move to the enclosed thread group");
+        rb_raise(rb_eThreadError, "can't move to the enclosed thread group");
     }
 
     if (!th->thgroup) {
-	return Qnil;
+        return Qnil;
     }
 
     if (OBJ_FROZEN(th->thgroup)) {
-	rb_raise(rb_eThreadError, "can't move from the frozen thread group");
+        rb_raise(rb_eThreadError, "can't move from the frozen thread group");
     }
     TypedData_Get_Struct(th->thgroup, struct thgroup, &thgroup_data_type, data);
     if (data->enclosed) {
-	rb_raise(rb_eThreadError,
-		 "can't move from the enclosed thread group");
+        rb_raise(rb_eThreadError,
+                 "can't move from the enclosed thread group");
     }
 
     th->thgroup = group;
@@ -3033,14 +3043,14 @@
 mutex_free(void *ptr)
 {
     if (ptr) {
-	mutex_t *mutex = ptr;
-	if (mutex->th) {
-	    /* rb_warn("free locked mutex"); */
-	    const char *err = mutex_unlock(mutex, mutex->th);
-	    if (err) rb_bug("%s", err);
-	}
-	native_mutex_destroy(&mutex->lock);
-	native_cond_destroy(&mutex->cond);
+        mutex_t *mutex = ptr;
+        if (mutex->th) {
+            /* rb_warn("free locked mutex"); */
+            const char *err = mutex_unlock(mutex, mutex->th);
+            if (err) rb_bug("%s", err);
+        }
+        native_mutex_destroy(&mutex->lock);
+        native_cond_destroy(&mutex->cond);
     }
     ruby_xfree(ptr);
 }
@@ -3107,7 +3117,7 @@
     GetMutexPtr(self, mutex);
 
     if (th->keeping_mutexes) {
-	mutex->next_mutex = th->keeping_mutexes;
+        mutex->next_mutex = th->keeping_mutexes;
     }
     th->keeping_mutexes = mutex;
 }
@@ -3128,10 +3138,10 @@
 
     native_mutex_lock(&mutex->lock);
     if (mutex->th == 0) {
-	mutex->th = GET_THREAD();
-	locked = Qtrue;
+        mutex->th = GET_THREAD();
+        locked = Qtrue;
 
-	mutex_locked(GET_THREAD(), self);
+        mutex_locked(GET_THREAD(), self);
     }
     native_mutex_unlock(&mutex->lock);
 
@@ -3149,19 +3159,19 @@
     native_mutex_lock(&mutex->lock);
     th->transition_for_lock = 0;
     while (mutex->th || (mutex->th = th, 0)) {
-	if (last_thread) {
-	    interrupted = 2;
-	    break;
-	}
+        if (last_thread) {
+            interrupted = 2;
+            break;
+        }
 
-	mutex->cond_waiting++;
-	native_cond_wait(&mutex->cond, &mutex->lock);
-	mutex->cond_notified--;
+        mutex->cond_waiting++;
+        native_cond_wait(&mutex->cond, &mutex->lock);
+        mutex->cond_notified--;
 
-	if (RUBY_VM_INTERRUPTED(th)) {
-	    interrupted = 1;
-	    break;
-	}
+        if (RUBY_VM_INTERRUPTED(th)) {
+            interrupted = 1;
+            break;
+        }
     }
     th->transition_for_lock = 1;
     native_mutex_unlock(&mutex->lock);
@@ -3180,9 +3190,9 @@
     mutex_t *mutex = (mutex_t *)ptr;
     native_mutex_lock(&mutex->lock);
     if (mutex->cond_waiting > 0) {
-	native_cond_broadcast(&mutex->cond);
-	mutex->cond_notified = mutex->cond_waiting;
-	mutex->cond_waiting = 0;
+        native_cond_broadcast(&mutex->cond);
+        mutex->cond_notified = mutex->cond_waiting;
+        mutex->cond_waiting = 0;
     }
     native_mutex_unlock(&mutex->lock);
 }
@@ -3199,51 +3209,51 @@
 {
 
     if (rb_mutex_trylock(self) == Qfalse) {
-	mutex_t *mutex;
-	rb_thread_t *th = GET_THREAD();
-	GetMutexPtr(self, mutex);
+        mutex_t *mutex;
+        rb_thread_t *th = GET_THREAD();
+        GetMutexPtr(self, mutex);
 
-	if (mutex->th == GET_THREAD()) {
-	    rb_raise(rb_eThreadError, "deadlock; recursive locking");
-	}
+        if (mutex->th == GET_THREAD()) {
+            rb_raise(rb_eThreadError, "deadlock; recursive locking");
+        }
 
-	while (mutex->th != th) {
-	    int interrupted;
-	    enum rb_thread_status prev_status = th->status;
-	    int last_thread = 0;
-	    struct rb_unblock_callback oldubf;
+        while (mutex->th != th) {
+            int interrupted;
+            enum rb_thread_status prev_status = th->status;
+            int last_thread = 0;
+            struct rb_unblock_callback oldubf;
 
-	    set_unblock_function(th, lock_interrupt, mutex, &oldubf);
-	    th->status = THREAD_STOPPED_FOREVER;
-	    th->vm->sleeper++;
-	    th->locking_mutex = self;
-	    if (vm_living_thread_num(th->vm) == th->vm->sleeper) {
-		last_thread = 1;
-	    }
+            set_unblock_function(th, lock_interrupt, mutex, &oldubf);
+            th->status = THREAD_STOPPED_FOREVER;
+            th->vm->sleeper++;
+            th->locking_mutex = self;
+            if (vm_living_thread_num(th->vm) == th->vm->sleeper) {
+                last_thread = 1;
+            }
 
-	    th->transition_for_lock = 1;
-	    BLOCKING_REGION_CORE({
-		interrupted = lock_func(th, mutex, last_thread);
-	    });
-	    th->transition_for_lock = 0;
-	    remove_signal_thread_list(th);
-	    reset_unblock_function(th, &oldubf);
+            th->transition_for_lock = 1;
+            BLOCKING_REGION_CORE({
+                interrupted = lock_func(th, mutex, last_thread);
+            });
+            th->transition_for_lock = 0;
+            remove_signal_thread_list(th);
+            reset_unblock_function(th, &oldubf);
 
-	    th->locking_mutex = Qfalse;
-	    if (mutex->th && interrupted == 2) {
-		rb_check_deadlock(th->vm);
-	    }
-	    if (th->status == THREAD_STOPPED_FOREVER) {
-		th->status = prev_status;
-	    }
-	    th->vm->sleeper--;
+            th->locking_mutex = Qfalse;
+            if (mutex->th && interrupted == 2) {
+                rb_check_deadlock(th->vm);
+            }
+            if (th->status == THREAD_STOPPED_FOREVER) {
+                th->status = prev_status;
+            }
+            th->vm->sleeper--;
 
-	    if (mutex->th == th) mutex_locked(th, self);
+            if (mutex->th == th) mutex_locked(th, self);
 
-	    if (interrupted) {
-		RUBY_VM_CHECK_INTS();
-	    }
-	}
+            if (interrupted) {
+                RUBY_VM_CHECK_INTS();
+            }
+        }
     }
     return self;
 }
@@ -3257,40 +3267,40 @@
     native_mutex_lock(&mutex->lock);
 
     if (mutex->th == 0) {
-	err = "Attempt to unlock a mutex which is not locked";
+        err = "Attempt to unlock a mutex which is not locked";
     }
     else if (mutex->th != th) {
-	err = "Attempt to unlock a mutex which is locked by another thread";
+        err = "Attempt to unlock a mutex which is locked by another thread";
     }
     else {
-	mutex->th = 0;
-	if (mutex->cond_waiting > 0) {
-	    /* waiting thread */
-	    native_cond_signal(&mutex->cond);
-	    mutex->cond_waiting--;
-	    mutex->cond_notified++;
-	}
+        mutex->th = 0;
+        if (mutex->cond_waiting > 0) {
+            /* waiting thread */
+            native_cond_signal(&mutex->cond);
+            mutex->cond_waiting--;
+            mutex->cond_notified++;
+        }
     }
 
     native_mutex_unlock(&mutex->lock);
 
     if (!err) {
-	th_mutex = th->keeping_mutexes;
-	if (th_mutex == mutex) {
-	    th->keeping_mutexes = mutex->next_mutex;
-	}
-	else {
-	    while (1) {
-		mutex_t *tmp_mutex;
-		tmp_mutex = th_mutex->next_mutex;
-		if (tmp_mutex == mutex) {
-		    th_mutex->next_mutex = tmp_mutex->next_mutex;
-		    break;
-		}
-		th_mutex = tmp_mutex;
-	    }
-	}
-	mutex->next_mutex = NULL;
+        th_mutex = th->keeping_mutexes;
+        if (th_mutex == mutex) {
+            th->keeping_mutexes = mutex->next_mutex;
+        }
+        else {
+            while (1) {
+                mutex_t *tmp_mutex;
+                tmp_mutex = th_mutex->next_mutex;
+                if (tmp_mutex == mutex) {
+                    th_mutex->next_mutex = tmp_mutex->next_mutex;
+                    break;
+                }
+                th_mutex = tmp_mutex;
+            }
+        }
+        mutex->next_mutex = NULL;
     }
 
     return err;
@@ -3323,12 +3333,12 @@
     mutex_t *mutex;
 
     while (mutexes) {
-	mutex = mutexes;
-	/* rb_warn("mutex #<%p> remains to be locked by terminated thread",
-		mutexes); */
-	mutexes = mutex->next_mutex;
-	err = mutex_unlock(mutex, th);
-	if (err) rb_bug("invalid keeping_mutexes: %s", err);
+        mutex = mutexes;
+        /* rb_warn("mutex #<%p> remains to be locked by terminated thread",
+                mutexes); */
+        mutexes = mutex->next_mutex;
+        err = mutex_unlock(mutex, th);
+        if (err) rb_bug("invalid keeping_mutexes: %s", err);
     }
 }
 
@@ -3338,10 +3348,10 @@
     mutex_t *mutex;
 
     while (mutexes) {
-	mutex = mutexes;
-	mutexes = mutex->next_mutex;
-	mutex->th = 0;
-	mutex->next_mutex = 0;
+        mutex = mutexes;
+        mutexes = mutex->next_mutex;
+        mutex->th = 0;
+        mutex->next_mutex = 0;
     }
 }
 
@@ -3372,10 +3382,10 @@
     rb_mutex_unlock(self);
     beg = time(0);
     if (NIL_P(timeout)) {
-	rb_ensure(rb_mutex_sleep_forever, Qnil, rb_mutex_lock, self);
+        rb_ensure(rb_mutex_sleep_forever, Qnil, rb_mutex_lock, self);
     }
     else {
-	rb_ensure(rb_mutex_wait_for, (VALUE)&t, rb_mutex_lock, self);
+        rb_ensure(rb_mutex_wait_for, (VALUE)&t, rb_mutex_lock, self);
     }
     end = time(0) - beg;
     return INT2FIX(end);
@@ -3488,18 +3498,18 @@
     VALUE sym = ID2SYM(rb_frame_this_func());
     VALUE list;
     if (NIL_P(hash) || TYPE(hash) != T_HASH) {
-	hash = rb_hash_new();
-	OBJ_UNTRUST(hash);
-	rb_thread_local_aset(rb_thread_current(), recursive_key, hash);
-	list = Qnil;
+        hash = rb_hash_new();
+        OBJ_UNTRUST(hash);
+        rb_thread_local_aset(rb_thread_current(), recursive_key, hash);
+        list = Qnil;
     }
     else {
-	list = rb_hash_aref(hash, sym);
+        list = rb_hash_aref(hash, sym);
     }
     if (NIL_P(list) || TYPE(list) != T_HASH) {
-	list = rb_hash_new();
-	OBJ_UNTRUST(list);
-	rb_hash_aset(hash, sym, list);
+        list = rb_hash_new();
+        OBJ_UNTRUST(list);
+        rb_hash_aset(hash, sym, list);
     }
     return list;
 }
@@ -3515,16 +3525,16 @@
 {
     VALUE pair_list = rb_hash_lookup2(list, obj_id, Qundef);
     if (pair_list == Qundef)
-	return Qfalse;
+        return Qfalse;
     if (paired_obj_id) {
-	if (TYPE(pair_list) != T_HASH) {
-	if (pair_list != paired_obj_id)
-	    return Qfalse;
-	}
-	else {
-	if (NIL_P(rb_hash_lookup(pair_list, paired_obj_id)))
-	    return Qfalse;
-	}
+        if (TYPE(pair_list) != T_HASH) {
+        if (pair_list != paired_obj_id)
+            return Qfalse;
+        }
+        else {
+        if (NIL_P(rb_hash_lookup(pair_list, paired_obj_id)))
+            return Qfalse;
+        }
     }
     return Qtrue;
 }
@@ -3544,20 +3554,20 @@
     VALUE pair_list;
 
     if (!paired_obj) {
-	rb_hash_aset(list, obj, Qtrue);
+        rb_hash_aset(list, obj, Qtrue);
     }
     else if ((pair_list = rb_hash_lookup2(list, obj, Qundef)) == Qundef) {
-	rb_hash_aset(list, obj, paired_obj);
+        rb_hash_aset(list, obj, paired_obj);
     }
     else {
-	if (TYPE(pair_list) != T_HASH){
-	    VALUE other_paired_obj = pair_list;
-	    pair_list = rb_hash_new();
-	    OBJ_UNTRUST(pair_list);
-	    rb_hash_aset(pair_list, other_paired_obj, Qtrue);
-	    rb_hash_aset(list, obj, pair_list);
-	}
-	rb_hash_aset(pair_list, paired_obj, Qtrue);
+        if (TYPE(pair_list) != T_HASH){
+            VALUE other_paired_obj = pair_list;
+            pair_list = rb_hash_new();
+            OBJ_UNTRUST(pair_list);
+            rb_hash_aset(pair_list, other_paired_obj, Qtrue);
+            rb_hash_aset(list, obj, pair_list);
+        }
+        rb_hash_aset(pair_list, paired_obj, Qtrue);
     }
 }
 
@@ -3573,19 +3583,19 @@
 recursive_pop(VALUE list, VALUE obj, VALUE paired_obj)
 {
     if (paired_obj) {
-	VALUE pair_list = rb_hash_lookup2(list, obj, Qundef);
-	if (pair_list == Qundef) {
-	    VALUE symname = rb_inspect(ID2SYM(rb_frame_this_func()));
-	    VALUE thrname = rb_inspect(rb_thread_current());
-	    rb_raise(rb_eTypeError, "invalid inspect_tbl pair_list for %s in %s",
-		     StringValuePtr(symname), StringValuePtr(thrname));
-	}
-	if (TYPE(pair_list) == T_HASH) {
-	    rb_hash_delete(pair_list, paired_obj);
-	    if (!RHASH_EMPTY_P(pair_list)) {
-		return; /* keep hash until is empty */
-	    }
-	}
+        VALUE pair_list = rb_hash_lookup2(list, obj, Qundef);
+        if (pair_list == Qundef) {
+            VALUE symname = rb_inspect(ID2SYM(rb_frame_this_func()));
+            VALUE thrname = rb_inspect(rb_thread_current());
+            rb_raise(rb_eTypeError, "invalid inspect_tbl pair_list for %s in %s",
+                     StringValuePtr(symname), StringValuePtr(thrname));
+        }
+        if (TYPE(pair_list) == T_HASH) {
+            rb_hash_delete(pair_list, paired_obj);
+            if (!RHASH_EMPTY_P(pair_list)) {
+                return; /* keep hash until is empty */
+            }
+        }
     }
     rb_hash_delete(list, obj);
 }
@@ -3608,12 +3618,12 @@
     recursive_push(p->list, p->objid, p->pairid);
     PUSH_TAG();
     if ((state = EXEC_TAG()) == 0) {
-	result = (*p->func)(p->obj, p->arg, FALSE);
+        result = (*p->func)(p->obj, p->arg, FALSE);
     }
     POP_TAG();
     recursive_pop(p->list, p->objid, p->pairid);
     if (state)
-	JUMP_TAG(state);
+        JUMP_TAG(state);
     return result;
 }
 
@@ -3638,30 +3648,30 @@
     outermost = outer && !recursive_check(p.list, ID2SYM(recursive_key), 0);
 
     if (recursive_check(p.list, p.objid, pairid)) {
-	if (outer && !outermost) {
-	    rb_throw_obj(p.list, p.list);
-	}
-	return (*func)(obj, arg, TRUE);
+        if (outer && !outermost) {
+            rb_throw_obj(p.list, p.list);
+        }
+        return (*func)(obj, arg, TRUE);
     }
     else {
-	VALUE result = Qundef;
-	p.func = func;
-	p.obj = obj;
-	p.pairid = pairid;
-	p.arg = arg;
+        VALUE result = Qundef;
+        p.func = func;
+        p.obj = obj;
+        p.pairid = pairid;
+        p.arg = arg;
 
-	if (outermost) {
-	    recursive_push(p.list, ID2SYM(recursive_key), 0);
-	    result = rb_catch_obj(p.list, exec_recursive_i, (VALUE)&p);
-	    recursive_pop(p.list, ID2SYM(recursive_key), 0);
-	    if (result == p.list) {
-		result = (*func)(obj, arg, TRUE);
-	    }
-	}
-	else {
-	    result = exec_recursive_i(0, &p);
-	}
-	return result;
+        if (outermost) {
+            recursive_push(p.list, ID2SYM(recursive_key), 0);
+            result = rb_catch_obj(p.list, exec_recursive_i, (VALUE)&p);
+            recursive_pop(p.list, ID2SYM(recursive_key), 0);
+            if (result == p.list) {
+                result = (*func)(obj, arg, TRUE);
+            }
+        }
+        else {
+            result = exec_recursive_i(0, &p);
+        }
+        return result;
     }
 }
 
@@ -3718,15 +3728,15 @@
     rb_event_flag_t flag = th->event_flags & RUBY_EVENT_VM;
 
     while (hook) {
-	flag |= hook->flag;
-	hook = hook->next;
+        flag |= hook->flag;
+        hook = hook->next;
     }
     th->event_flags = flag;
 }
 
 static void
 rb_threadptr_add_event_hook(rb_thread_t *th, 
-			 rb_event_hook_func_t func, rb_event_flag_t events, VALUE data)
+                            rb_event_hook_func_t func, rb_event_flag_t events, VALUE data)
 {
     rb_event_hook_t *hook = alloc_event_hook(func, events, data);
     hook->next = th->event_hooks;
@@ -3744,7 +3754,7 @@
 
 void
 rb_thread_add_event_hook(VALUE thval,
-			 rb_event_hook_func_t func, rb_event_flag_t events, VALUE data)
+                         rb_event_hook_func_t func, rb_event_flag_t events, VALUE data)
 {
     rb_threadptr_add_event_hook(thval2thread_t(thval), func, events, data);
 }
@@ -3757,10 +3767,12 @@
     GetThreadPtr(thval, th);
 
     if (flag) {
-	th->event_flags |= RUBY_EVENT_VM;
+        /* Rocky: Probably wrong to set RUBY_EVENT_BRKPT here. And why is RUBY_EVENT_VM
+           special? */
+        th->event_flags |= (RUBY_EVENT_VM | RUBY_EVENT_BRKPT);
     }
     else {
-	th->event_flags &= (~RUBY_EVENT_VM);
+        th->event_flags &= (~RUBY_EVENT_VM);
     }
     return ST_CONTINUE;
 }
@@ -3775,9 +3787,9 @@
 exec_event_hooks(const rb_event_hook_t *hook, rb_event_flag_t flag, VALUE self, ID id, VALUE klass)
 {
     for (; hook; hook = hook->next) {
-	if (flag & hook->flag) {
-	    (*hook->func)(flag, hook->data, self, id, klass);
-	}
+        if (flag & hook->flag) {
+            (*hook->func)(flag, hook->data, self, id, klass);
+        }
     }
 }
 
@@ -3788,16 +3800,40 @@
     const rb_event_flag_t wait_event = th->event_flags;
 
     if (self == rb_mRubyVMFrozenCore) return;
-    if (wait_event & flag) {
-	exec_event_hooks(th->event_hooks, flag, self, id, klass);
+    if (wait_event & flag && th->tracing <= 0) {
+        if (!RUBY_VM_CONTROL_FRAME_STACK_OVERFLOW_P(th, th->cfp)
+              && !(th->cfp->tracing & VM_FRAME_TRACE_OFF))
+            exec_event_hooks(th->event_hooks, flag, self, id, klass);
     }
-    if (wait_event & RUBY_EVENT_VM) {
-	if (th->vm->event_hooks == NULL) {
-	    th->event_flags &= (~RUBY_EVENT_VM);
-	}
-	else {
-	    exec_event_hooks(th->vm->event_hooks, flag, self, id, klass);
-	}
+    if (wait_event & RUBY_EVENT_VM && th->tracing <= 0) {
+        if (th->vm->event_hooks == NULL) {
+            th->event_flags &= (~RUBY_EVENT_VM);
+        }
+        else {
+            if (0 == th->exec_event_tracing) {
+                /* Modified from ruby_suppress_tracing */
+                int state;
+                volatile int raised = rb_threadptr_reset_raised(th);
+                rb_block_t * base_block_save = th->base_block;
+                th->exec_event_tracing = 1;
+                
+                PUSH_TAG();
+                if ((state = EXEC_TAG()) == 0) {
+                    exec_event_hooks(th->vm->event_hooks, flag, self, id, klass);
+                }
+                
+                th->base_block = base_block_save;
+                if (raised) {
+                    rb_threadptr_set_raised(th);
+                }
+                POP_TAG();
+                
+                th->exec_event_tracing = 0;
+                if (state) {
+                    JUMP_TAG(state);
+                }
+            }
+        }
     }
     th->errinfo = errinfo;
 }
@@ -3820,20 +3856,20 @@
     rb_event_hook_t *prev = NULL, *hook = *root, *next;
 
     while (hook) {
-	next = hook->next;
-	if (func == 0 || hook->func == func) {
-	    if (prev) {
-		prev->next = hook->next;
-	    }
-	    else {
-		*root = hook->next;
-	    }
-	    xfree(hook);
-	}
-	else {
-	    prev = hook;
-	}
-	hook = next;
+        next = hook->next;
+        if (func == 0 || hook->func == func) {
+            if (prev) {
+                prev->next = hook->next;
+            }
+            else {
+                *root = hook->next;
+            }
+            xfree(hook);
+        }
+        else {
+            prev = hook;
+        }
+        hook = next;
     }
     return -1;
 }
@@ -3860,7 +3896,7 @@
     int ret = remove_event_hook(&vm->event_hooks, func);
 
     if (hook != NULL && vm->event_hooks == NULL) {
-	set_threads_event_flags(0);
+        set_threads_event_flags(0);
     }
 
     return ret;
@@ -3875,19 +3911,49 @@
     return ST_CONTINUE;
 }
 
-void
+VALUE
 rb_clear_trace_func(void)
 {
     st_foreach(GET_VM()->living_threads, clear_trace_func_i, (st_data_t) 0);
     rb_remove_event_hook(0);
+    return Qnil;
 }
 
 static void call_trace_func(rb_event_flag_t, VALUE data, VALUE self, ID id, VALUE klass);
 
+static VALUE
+add_trace_func(int argc, VALUE *argv)
+{
+    VALUE vmask;
+    VALUE trace;
+    int mask=RUBY_EVENT_ALL;
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &vmask)) {
+        mask = NUM2INT(vmask);
+    }
+
+    if (NIL_P(trace)) {
+        return Qnil;
+    }
+
+    if (!rb_obj_is_proc(trace)) {
+        rb_raise(rb_eTypeError, "trace_func needs to be Proc");
+    }
+
+    {
+        rb_thread_t *th           = GET_THREAD(); /* main thread */
+        th->trace_skip_insn_count = 2;
+        th->tracing               = -1;
+        rb_add_event_hook(call_trace_func, mask, trace);
+    }
+    
+    return trace;
+}
+
 /*
  *  call-seq:
- *     set_trace_func(proc)    -> proc
- *     set_trace_func(nil)     -> nil
+ *     set_trace_func(proc)        => proc
+ *     set_trace_func(proc, mask)  => proc
+ *     set_trace_func(nil)         => nil
  *
  *  Establishes _proc_ as the handler for tracing, or disables
  *  tracing if the parameter is +nil+. _proc_ takes up
@@ -3901,79 +3967,88 @@
  *  <code>line</code> (execute code on a new line), <code>raise</code>
  *  (raise an exception), and <code>return</code> (return from a Ruby
  *  method). Tracing is disabled within the context of _proc_.
+ *  _mask_ is an optional bitmask of events to trigger on, See ruby.h
+ *  for the integer values. If no mask is specified all events are triggered.
  *
  *      class Test
- *	def test
- *	  a = 1
- *	  b = 2
- *	end
+ *      def test
+ *        a = 1
+ *        b = 2
  *      end
+ *      end
  *
  *      set_trace_func proc { |event, file, line, id, binding, classname|
- *	   printf "%8s %s:%-2d %10s %8s\n", event, file, line, id, classname
+ *         printf "%8s %s:%-2d %10s %8s\n", event, file, line, id, classname
  *      }
  *      t = Test.new
  *      t.test
  *
- *	  line prog.rb:11               false
+ *        line prog.rb:11               false
  *      c-call prog.rb:11        new    Class
  *      c-call prog.rb:11 initialize   Object
  *    c-return prog.rb:11 initialize   Object
  *    c-return prog.rb:11        new    Class
- *	  line prog.rb:12               false
- *  	  call prog.rb:2        test     Test
- *	  line prog.rb:3        test     Test
- *	  line prog.rb:4        test     Test
+ *        line prog.rb:12               false
+ *        call prog.rb:2        test     Test
+ *        line prog.rb:3        test     Test
+ *        line prog.rb:4        test     Test
  *      return prog.rb:4        test     Test
+ *
+ *      set_trace_func(proc { |event, file, line, id, binding, classname|
+ *         printf "%8s %s:%-2d %10s %8s\n", event, file, line, id, classname
+ *      }, 0x018) # 0x018 == calls and returns only
+ *      t = Test.new
+ *      t.test
+ *
+ *        call prog.rb:2        test     Test
+ *      return prog.rb:4        test     Test
  */
 
 static VALUE
-set_trace_func(VALUE obj, VALUE trace)
+set_trace_func(int argc, VALUE *argv)
 {
     rb_remove_event_hook(call_trace_func);
-
-    if (NIL_P(trace)) {
-	return Qnil;
-    }
-
-    if (!rb_obj_is_proc(trace)) {
-	rb_raise(rb_eTypeError, "trace_func needs to be Proc");
-    }
-
-    rb_add_event_hook(call_trace_func, RUBY_EVENT_ALL, trace);
-    return trace;
+    return add_trace_func(argc, argv);
 }
 
 static void
-thread_add_trace_func(rb_thread_t *th, VALUE trace)
+thread_add_trace_func(rb_thread_t *th, VALUE trace, rb_event_flag_t events)
 {
     if (!rb_obj_is_proc(trace)) {
-	rb_raise(rb_eTypeError, "trace_func needs to be Proc");
+        rb_raise(rb_eTypeError, "trace_func needs to be Proc");
     }
 
-    rb_threadptr_add_event_hook(th, call_trace_func, RUBY_EVENT_ALL, trace);
+    rb_threadptr_add_event_hook(th, call_trace_func, events, trace);
 }
 
 /*
  *  call-seq:
- *     thr.add_trace_func(proc)    -> proc
+ *     thr.add_trace_func(proc, events=RUBY_EVENT_ALL)    => proc
  *
  *  Adds _proc_ as a handler for tracing.
  *  See <code>Thread#set_trace_func</code> and +set_trace_func+.
  */
 
 static VALUE
-thread_add_trace_func_m(VALUE obj, VALUE trace)
+thread_add_trace_func_m(int argc, VALUE *argv, VALUE obj)
 {
+    VALUE trace;
+    VALUE event_maskval;
+    rb_event_flag_t events=RUBY_EVENT_ALL;
     rb_thread_t *th;
+
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &event_maskval)) {
+        events = NUM2INT(event_maskval);
+    }
+
     GetThreadPtr(obj, th);
-    thread_add_trace_func(th, trace);
+    thread_add_trace_func(th, trace, events);
     return trace;
 }
 
 /*
  *  call-seq:
- *     thr.set_trace_func(proc)    -> proc
+ *     thr.set_trace_func(proc, events=RB_EVENT_ALL)    => proc
  *     thr.set_trace_func(nil)     -> nil
  *
  *  Establishes _proc_ on _thr_ as the handler for tracing, or
@@ -3982,16 +4057,24 @@
  */
 
 static VALUE
-thread_set_trace_func_m(VALUE obj, VALUE trace)
+thread_set_trace_func_m(int argc, VALUE *argv, VALUE obj)   /* (VALUE obj, VALUE trace, events) */
 {
+    VALUE trace;
+    VALUE event_maskval;
+    rb_event_flag_t events=RUBY_EVENT_ALL;
     rb_thread_t *th;
+
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &event_maskval)) {
+        events = NUM2INT(event_maskval);
+    }
+
     GetThreadPtr(obj, th);
     rb_threadptr_revmove_event_hook(th, call_trace_func);
 
     if (NIL_P(trace)) {
-	return Qnil;
+        return Qnil;
     }
-    thread_add_trace_func(th, trace);
+    thread_add_trace_func(th, trace, events);
     return trace;
 }
 
@@ -4000,23 +4083,33 @@
 {
     switch (event) {
       case RUBY_EVENT_LINE:
-	return "line";
+        return "line";
       case RUBY_EVENT_CLASS:
-	return "class";
+        return "class";
       case RUBY_EVENT_END:
-	return "end";
+        return "end";
+      case RUBY_EVENT_BRKPT:
+        return "brkpt";
       case RUBY_EVENT_CALL:
-	return "call";
+        return "call";
       case RUBY_EVENT_RETURN:
-	return "return";
+        return "return";
       case RUBY_EVENT_C_CALL:
-	return "c-call";
+        return "c-call";
       case RUBY_EVENT_C_RETURN:
-	return "c-return";
+        return "c-return";
       case RUBY_EVENT_RAISE:
-	return "raise";
+        return "raise";
+      case RUBY_EVENT_INSN:
+        return "vm-insn";
+      case RUBY_EVENT_SWITCH:
+        return "switch";
+      case RUBY_EVENT_COVERAGE:
+        return "coverage";
+      case RUBY_EVENT_VM:
+        return "vm";
       default:
-	return "unknown";
+        return "unknown";
     }
 }
 
@@ -4036,6 +4129,11 @@
     struct call_trace_func_args *p = (struct call_trace_func_args *)args;
     const char *srcfile = rb_sourcefile();
     VALUE eventname = rb_str_new2(get_event_name(p->event));
+    
+    if (p->event == RUBY_EVENT_INSN &&
+        GET_THREAD()->trace_skip_insn_count-- > 0) 
+        return Qnil;
+    
     VALUE filename = srcfile ? rb_str_new2(srcfile) : Qnil;
     VALUE argv[6];
     int line = rb_sourceline();
@@ -4043,22 +4141,27 @@
     VALUE klass = 0;
 
     if (p->event == RUBY_EVENT_C_CALL ||
-	p->event == RUBY_EVENT_C_RETURN) {
-	id = p->id;
-	klass = p->klass;
+        p->event == RUBY_EVENT_C_RETURN ||
+        p->event == RUBY_EVENT_INSN) {
+        id = p->id;
+        klass = p->klass;
+    } else if (p->event == RUBY_EVENT_RAISE) {
+        /* We have arranged to store the raise message in klass here. */
+        VALUE throwaway_klass;
+        rb_thread_method_id_and_class(GET_THREAD(), &id, &throwaway_klass);
+        klass = p->klass;
+    } else {
+        rb_thread_method_id_and_class(GET_THREAD(), &id, &klass);
     }
-    else {
-	rb_thread_method_id_and_class(GET_THREAD(), &id, &klass);
-    }
     if (id == ID_ALLOCATOR)
       return Qnil;
     if (klass) {
-	if (TYPE(klass) == T_ICLASS) {
-	    klass = RBASIC(klass)->klass;
-	}
-	else if (FL_TEST(klass, FL_SINGLETON)) {
-	    klass = rb_iv_get(klass, "__attached__");
-	}
+        if (TYPE(klass) == T_ICLASS) {
+            klass = RBASIC(klass)->klass;
+        }
+        else if (FL_TEST(klass, FL_SINGLETON)) {
+            klass = rb_iv_get(klass, "__attached__");
+        }
     }
 
     argv[0] = eventname;
@@ -4093,27 +4196,27 @@
     VALUE result = Qnil;
 
     if ((tracing = th->tracing) != 0 && !always) {
-	return Qnil;
+        return Qnil;
     }
     else {
-	th->tracing = 1;
+        th->tracing = 1;
     }
 
     raised = rb_threadptr_reset_raised(th);
 
     PUSH_TAG();
     if ((state = EXEC_TAG()) == 0) {
-	result = (*func)(arg, tracing);
+        result = (*func)(arg, tracing);
     }
 
     if (raised) {
-	rb_threadptr_set_raised(th);
+        rb_threadptr_set_raised(th);
     }
     POP_TAG();
 
     th->tracing = tracing;
     if (state) {
-	JUMP_TAG(state);
+        JUMP_TAG(state);
     }
 
     return result;
@@ -4216,9 +4319,9 @@
     rb_define_method(cThGroup, "add", thgroup_add, 1);
 
     {
-	rb_thread_t *th = GET_THREAD();
-	th->thgroup = th->vm->thgroup_default = rb_obj_alloc(cThGroup);
-	rb_define_const(cThGroup, "Default", th->thgroup);
+        rb_thread_t *th = GET_THREAD();
+        th->thgroup = th->vm->thgroup_default = rb_obj_alloc(cThGroup);
+        rb_define_const(cThGroup, "Default", th->thgroup);
     }
 
     rb_cMutex = rb_define_class("Mutex", rb_cObject);
@@ -4234,21 +4337,23 @@
     rb_eThreadError = rb_define_class("ThreadError", rb_eStandardError);
 
     /* trace */
-    rb_define_global_function("set_trace_func", set_trace_func, 1);
-    rb_define_method(rb_cThread, "set_trace_func", thread_set_trace_func_m, 1);
-    rb_define_method(rb_cThread, "add_trace_func", thread_add_trace_func_m, 1);
+    rb_define_global_function("add_trace_func", add_trace_func, -1);
+    rb_define_global_function("set_trace_func", set_trace_func, -1);
+    rb_define_global_function("clear_trace_func", rb_clear_trace_func, 0);
+    rb_define_method(rb_cThread, "set_trace_func", thread_set_trace_func_m, -1);
+    rb_define_method(rb_cThread, "add_trace_func", thread_add_trace_func_m, -1);
 
     /* init thread core */
     Init_native_thread();
     {
-	/* main thread setting */
-	{
-	    /* acquire global vm lock */
-	    rb_thread_lock_t *lp = &GET_THREAD()->vm->global_vm_lock;
-	    native_mutex_initialize(lp);
-	    native_mutex_lock(lp);
-	    native_mutex_initialize(&GET_THREAD()->interrupt_lock);
-	}
+        /* main thread setting */
+        {
+            /* acquire global vm lock */
+            rb_thread_lock_t *lp = &GET_THREAD()->vm->global_vm_lock;
+            native_mutex_initialize(lp);
+            native_mutex_lock(lp);
+            native_mutex_initialize(&GET_THREAD()->interrupt_lock);
+        }
     }
 
     rb_thread_create_timer_thread();
@@ -4273,17 +4378,17 @@
     GetThreadPtr(thval, th);
 
     if (th->status != THREAD_STOPPED_FOREVER || RUBY_VM_INTERRUPTED(th) || th->transition_for_lock) {
-	*found = 1;
+        *found = 1;
     }
     else if (th->locking_mutex) {
-	mutex_t *mutex;
-	GetMutexPtr(th->locking_mutex, mutex);
+        mutex_t *mutex;
+        GetMutexPtr(th->locking_mutex, mutex);
 
-	native_mutex_lock(&mutex->lock);
-	if (mutex->th == th || (!mutex->th && mutex->cond_notified)) {
-	    *found = 1;
-	}
-	native_mutex_unlock(&mutex->lock);
+        native_mutex_lock(&mutex->lock);
+        if (mutex->th == th || (!mutex->th && mutex->cond_notified)) {
+            *found = 1;
+        }
+        native_mutex_unlock(&mutex->lock);
     }
 
     return (*found) ? ST_STOP : ST_CONTINUE;
@@ -4299,12 +4404,12 @@
 
     printf("th:%p %d %d %d", th, th->status, th->interrupt_flag, th->transition_for_lock);
     if (th->locking_mutex) {
-	mutex_t *mutex;
-	GetMutexPtr(th->locking_mutex, mutex);
+        mutex_t *mutex;
+        GetMutexPtr(th->locking_mutex, mutex);
 
-	native_mutex_lock(&mutex->lock);
-	printf(" %p %d\n", mutex->th, mutex->cond_notified);
-	native_mutex_unlock(&mutex->lock);
+        native_mutex_lock(&mutex->lock);
+        printf(" %p %d\n", mutex->th, mutex->cond_notified);
+        native_mutex_unlock(&mutex->lock);
     }
     else puts("");
 
@@ -4323,15 +4428,15 @@
     st_foreach(vm->living_threads, check_deadlock_i, (st_data_t)&found);
 
     if (!found) {
-	VALUE argv[2];
-	argv[0] = rb_eFatal;
-	argv[1] = rb_str_new2("deadlock detected");
+        VALUE argv[2];
+        argv[0] = rb_eFatal;
+        argv[1] = rb_str_new2("deadlock detected");
 #if 0 /* for debug */
-	printf("%d %d %p %p\n", vm->living_threads->num_entries, vm->sleeper, GET_THREAD(), vm->main_thread);
-	st_foreach(vm->living_threads, debug_i, (st_data_t)0);
+        printf("%d %d %p %p\n", vm->living_threads->num_entries, vm->sleeper, GET_THREAD(), vm->main_thread);
+        st_foreach(vm->living_threads, debug_i, (st_data_t)0);
 #endif
-	vm->sleeper--;
-	rb_threadptr_raise(vm->main_thread, 2, argv);
+        vm->sleeper--;
+        rb_threadptr_raise(vm->main_thread, 2, argv);
     }
 }
 
@@ -4340,15 +4445,15 @@
 {
     VALUE coverage = GET_THREAD()->cfp->iseq->coverage;
     if (coverage && RBASIC(coverage)->klass == 0) {
-	long line = rb_sourceline() - 1;
-	long count;
-	if (RARRAY_PTR(coverage)[line] == Qnil) {
-	    rb_bug("bug");
-	}
-	count = FIX2LONG(RARRAY_PTR(coverage)[line]) + 1;
-	if (POSFIXABLE(count)) {
-	    RARRAY_PTR(coverage)[line] = LONG2FIX(count);
-	}
+        long line = rb_sourceline() - 1;
+        long count;
+        if (RARRAY_PTR(coverage)[line] == Qnil) {
+            rb_bug("bug");
+        }
+        count = FIX2LONG(RARRAY_PTR(coverage)[line]) + 1;
+        if (POSFIXABLE(count)) {
+            RARRAY_PTR(coverage)[line] = LONG2FIX(count);
+        }
     }
 }
 
Index: eval.c
===================================================================
--- eval.c	(revision 27984)
+++ eval.c	(working copy)
@@ -34,7 +34,7 @@
 
 /* initialize ruby */
 
-void rb_clear_trace_func(void);
+VALUE rb_clear_trace_func(void);
 void rb_thread_stop_timer_thread(void);
 
 void rb_call_inits(void);
@@ -69,7 +69,7 @@
     GET_VM()->running = 1;
 }
 
-extern void rb_clear_trace_func(void);
+extern VALUE rb_clear_trace_func(void);
 
 void *
 ruby_options(int argc, char **argv)
@@ -440,7 +440,7 @@
     rb_trap_restore_mask();
 
     if (tag != TAG_FATAL) {
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_RAISE, th->cfp->self, 0, 0);
+	EXEC_EVENT_HOOK(th, RUBY_EVENT_RAISE, th->cfp->self, 0, mesg);
     }
 }
 
@@ -588,6 +588,9 @@
 
     setup_exception(th, TAG_RAISE, mesg);
 
+    /* rocky: FIXME: decide what to do for sp values. Do we push mesg? 
+       See vm_insnhelper.c for guidance.
+     */
     EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, self, mid, klass);
     rb_thread_raised_clear(th);
     JUMP_TAG(TAG_RAISE);
Index: vm_exec.h
===================================================================
--- vm_exec.h	(revision 27984)
+++ vm_exec.h	(working copy)
@@ -18,6 +18,40 @@
 typedef rb_num_t GENTRY;
 typedef rb_iseq_t *ISEQ;
 
+#include "insns_info.inc"
+
+#if 0
+
+#define TRACE_INSN_SET_EXTRA_INFO(insn, var) do { var = Qnil; } while (0)
+
+#else
+
+#define TRACE_INSN_SET_EXTRA_INFO(insn, var) do { \
+  var = rb_ary_new2(insn_len(BIN(insn)) - 1); \
+  int trace_i__ = 0; \
+  while (trace_i__ < insn_len(BIN(insn)) - 1) { \
+    VALUE trace_push_val__ = Qnil; \
+    switch (insn_op_type(BIN(insn), trace_i__)) { \
+      case TS_VALUE: trace_push_val__ = GET_OPERAND(trace_i__ + 1); break; \
+      case TS_NUM: trace_push_val__ = INT2NUM(GET_OPERAND(trace_i__ + 1)); break; \
+      case TS_LINDEX: trace_push_val__ = INT2NUM((lindex_t) (GET_LFP() - GET_OPERAND(trace_i__ + 1))); break; \
+      case TS_DINDEX: trace_push_val__ = INT2NUM((dindex_t) (GET_DFP() - GET_OPERAND(trace_i__ + 1))); break; \
+      case TS_ID: trace_push_val__ = ID2SYM(GET_OPERAND(trace_i__ + 1)); break; \
+    } \
+    if (!SPECIAL_CONST_P(trace_push_val__)) \
+      trace_push_val__ = rb_type(trace_push_val__) == T_STRING ? \
+        rb_str_new_cstr(RSTRING_PTR(trace_push_val__)) : Qnil; \
+    rb_ary_push(var, trace_push_val__); \
+    trace_i__++; \
+  } \
+} while (0)
+
+#endif
+
+#define TRACE_INSN(insn) do { \
+  EXEC_EVENT_HOOK(th, RUBY_EVENT_INSN, GET_SELF(), 0, 0); \
+} while (0)
+
 #ifdef  COLLECT_USAGE_ANALYSIS
 #define USAGE_ANALYSIS_INSN(insn)           vm_analysis_insn(insn)
 #define USAGE_ANALYSIS_OPERAND(insn, n, op) vm_analysis_operand(insn, n, (VALUE)op)
@@ -28,12 +62,17 @@
 #define USAGE_ANALYSIS_REGISTER(reg, s)		/* none */
 #endif
 
-#ifdef __GCC__
+/* Rocky: VM-assisted breakpoint handling. */
+#define TEST_AND_HANDLE_BREAKPOINT(cfp, pc)				\
+    if (UNLIKELY(cfp->iseq &&						\
+		 cfp->iseq->breakpoints &&				\
+		 cfp->iseq->breakpoints[pc - cfp->iseq->iseq_encoded])) \
+	EXEC_EVENT_HOOK(th, RUBY_EVENT_BRKPT, cfp->self,		\
+			0, 0)
+
 /* TODO: machine dependent prefetch instruction */
-#define PREFETCH(pc)
-#else
-#define PREFETCH(pc)
-#endif
+#define PREFETCH(pc)							\
+    TEST_AND_HANDLE_BREAKPOINT(GET_CFP(), pc)
 
 #if VMDEBUG > 0
 #define debugs printf
Index: vm.c
===================================================================
--- vm.c	(revision 27984)
+++ vm.c	(working copy)
@@ -691,6 +691,7 @@
     if (RUBY_VM_NORMAL_ISEQ_P(iseq) && iseq->insn_info_size > 0) {
 	rb_num_t i;
 	size_t pos = cfp->pc - cfp->iseq->iseq_encoded;
+	line_no = iseq->insn_info_table[0].line_no;
 
 	if (iseq->insn_info_table[0].position == pos) goto found;
 	for (i = 1; i < iseq->insn_info_size; i++) {
@@ -1158,8 +1159,20 @@
 
 	while (th->cfp->pc == 0 || th->cfp->iseq == 0) {
 	    if (UNLIKELY(VM_FRAME_TYPE(th->cfp) == VM_FRAME_MAGIC_CFUNC)) {
-		const rb_method_entry_t *me = th->cfp->me;
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, me->called_id, me->klass);
+		/* rocky: The below tests and assignments are not
+		   quite right.  The problem I am having is when a
+		   there is an exception in hook code raised from a C
+		   return event. This causes the below EXEC_EVENT_HOOK to
+		   loop indefinitely. The below has the bad effect of
+		   not reseting exec_event_tracing sometimes.
+		 */
+		if (0 == th->tracing && 0 == th->exec_event_tracing) {
+		    const rb_method_entry_t *me = th->cfp->me;
+		    th->exec_event_tracing = 1;
+		    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, 
+				    me->called_id, me->klass);
+		    th->exec_event_tracing = 0;
+		}
 	    }
 	    th->cfp = RUBY_VM_PREVIOUS_CONTROL_FRAME(th->cfp);
 	}
@@ -1327,7 +1340,7 @@
 
 	    switch (VM_FRAME_TYPE(th->cfp)) {
 	      case VM_FRAME_MAGIC_METHOD:
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
+		EXEC_EVENT_RETURN_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
 		break;
 	      case VM_FRAME_MAGIC_CLASS:
 		EXEC_EVENT_HOOK(th, RUBY_EVENT_END, th->cfp->self, 0, 0);
Index: vm_insnhelper.c
===================================================================
--- vm_insnhelper.c	(revision 27984)
+++ vm_insnhelper.c	(working copy)
@@ -26,9 +26,12 @@
 	      const VALUE *pc, VALUE *sp, VALUE *lfp,
 	      int local_size)
 {
+    short int tracing = 0;
     rb_control_frame_t * const cfp = th->cfp - 1;
     int i;
 
+    if (type != VM_FRAME_MAGIC_TOP) tracing = th->cfp->tracing;
+
     if ((void *)(sp + local_size) >= (void *)cfp) {
 	rb_exc_raise(sysstack_error);
     }
@@ -60,6 +63,7 @@
     cfp->dfp = sp;
     cfp->proc = 0;
     cfp->me = 0;
+    cfp->tracing = tracing;
 
 #define COLLECT_PROFILE 0
 #if COLLECT_PROFILE
@@ -391,11 +395,18 @@
     const rb_method_definition_t *def = me->def;
     rb_control_frame_t *cfp;
 
-    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, me->called_id, me->klass);
-
     cfp = vm_push_frame(th, 0, VM_FRAME_MAGIC_CFUNC,
 			recv, (VALUE) blockptr, 0, reg_cfp->sp, 0, 1);
+
+    /* Store actual argument count as the block_iseq pointer. cfunc.argc contains
+       the prototype value. Should formalize this by making block_iseq a union
+       in vm_core.h
+    */
+    cfp->block_iseq = (rb_iseq_t *) INT2FIX(num);
+
     cfp->me = me;
+    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, me->called_id, me->klass);
+
     reg_cfp->sp -= num + 1;
 
     val = call_cfunc(def->body.cfunc.func, recv, (int)def->body.cfunc.argc, num, reg_cfp->sp + 1);
@@ -404,10 +415,21 @@
 	rb_bug("cfp consistency error - send");
     }
 
+    if (0 == th->tracing) {
+	rb_event_flag_t wait_event__ = th->event_flags;			
+	if (UNLIKELY(wait_event__)) {
+	    reg_cfp->sp += (num + 1);
+	    PUSH(val);
+	    rb_threadptr_exec_event_hooks(th, RUBY_EVENT_C_RETURN, recv, 
+					  me->called_id, me->klass);
+	    val = reg_cfp->sp[-1];    /* Allow for hook to change value */
+	    reg_cfp->sp -= (num + 2); /* +1 for above push */
+	}
+    } else if (th->tracing < 0)
+	th->tracing++;
+
     vm_pop_frame(th);
 
-    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, me->called_id, me->klass);
-
     return val;
 }
 
@@ -477,6 +499,13 @@
 		      iseq->iseq_encoded + opt_pc, sp, 0, 0);
 
 	cfp->sp = rsp - 1 /* recv */;
+	if (LIKELY(0 == th->tracing)) {
+	    EXEC_EVENT_HOOK(th, RUBY_EVENT_INSN, cfp->self, 0, 0);
+	    if (UNLIKELY(cfp->iseq &&
+			 cfp->iseq->breakpoints &&
+			 cfp->iseq->breakpoints[opt_pc]))
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_BRKPT, cfp->self, 0, 0);
+	}
     }
     else {
 	VALUE *p_rsp;
Index: tool/instruction.rb
===================================================================
--- tool/instruction.rb	(revision 27984)
+++ tool/instruction.rb	(working copy)
@@ -854,6 +854,17 @@
       commit "INSN_ENTRY(#{insn.name}){"
       make_header_prepare_stack insn
       commit "{"
+      # rocky: for reasons that I don't understand, calling the
+      # instruction trace hook in a "leave" instruction causes a
+      # SEGV via an illegal access csuch as via vm.c line 1144: 
+      #    ep = ... cfp->iseq ...  
+      # 
+      # Since we can handle this event via RUBY_EVENT_END I don't
+      # think there is any loss in functionality.
+      # Not sure if "send" should be included.
+      unless %w(leave send).member?(insn.name)
+        commit "  TRACE_INSN(#{insn.name});"
+      end
       make_header_stack_val  insn
       make_header_default_operands insn
       make_header_operands   insn
Index: test/ruby/test_settracefunc.rb
===================================================================
--- test/ruby/test_settracefunc.rb	(revision 27984)
+++ test/ruby/test_settracefunc.rb	(working copy)
@@ -23,8 +23,6 @@
      4: x = 1 + 1
      5: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :+, Fixnum],
@@ -50,8 +48,6 @@
      7: x = add(1, 1)
      8: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -88,10 +84,8 @@
      6:   end
      7: end
      8: x = Foo.new.bar
-     9: set_trace_func(nil)
+     9: clear_trace_func()
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :inherited, Class],
@@ -124,7 +118,7 @@
                  events.shift)
     assert_equal(["line", 9, __method__, self.class],
                  events.shift)
-    assert_equal(["c-call", 9, :set_trace_func, Kernel],
+    assert_equal(["c-call", 9, :clear_trace_func, Kernel],
                  events.shift)
     assert_equal([], events)
   end
@@ -132,7 +126,7 @@
   def test_return # [ruby-dev:38701]
     events = []
     eval <<-EOF.gsub(/^.*?: /, "")
-     1: set_trace_func(Proc.new { |event, file, lineno, mid, binding, klass|
+     1: add_trace_func(Proc.new { |event, file, lineno, mid, binding, klass|
      2:   events << [event, lineno, mid, klass]
      3: })
      4: def foo(a)
@@ -143,8 +137,6 @@
      9: foo(false)
     10: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -187,8 +179,6 @@
      8: foo
      9: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -220,12 +210,10 @@
      3: })
      4: begin
      5:   raise TypeError, "error"
-     6: rescue TypeError
+     6: rescue TypeError => $e
      7: end
      8: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["line", 5, __method__, self.class],
@@ -248,7 +236,7 @@
                  events.shift)
     assert_equal(["c-return", 5, :set_backtrace, Exception],
                  events.shift)
-    assert_equal(["raise", 5, :test_raise, TestSetTraceFunc],
+    assert_equal(["raise", 5, :test_raise, $e], 
                  events.shift)
     assert_equal(["c-return", 5, :raise, Kernel],
                  events.shift)
@@ -263,6 +251,15 @@
     assert_equal([], events)
   end
 
+  def chunk(list, char)
+    sep = char * 30 + "\n"
+    sep + list.map{|e| e.join(' ')}.join("\n") + "\n"
+  end
+
+  def showit(actual, expected)
+    chunk(actual, '-') + chunk(expected, '=')
+  end
+
   def test_break # [ruby-core:27606] [Bug #2610]
     events = []
     eval <<-EOF.gsub(/^.*?: /, "")
@@ -273,17 +270,15 @@
      8: set_trace_func(nil)
     EOF
 
-    [["c-return", 3, :set_trace_func, Kernel],
-     ["line", 4, __method__, self.class],
-     ["c-call", 4, :any?, Enumerable],
-     ["c-call", 4, :each, Array],
-     ["line", 4, __method__, self.class],
-     ["c-return", 4, :each, Array],
-     ["c-return", 4, :any?, Enumerable],
-     ["line", 5, __method__, self.class],
-     ["c-call", 5, :set_trace_func, Kernel]].each{|e|
-      assert_equal(e, events.shift)
-    }
+    expected = [["line", 4, __method__, self.class],
+                ["c-call", 4, :any?, Enumerable],
+                ["c-call", 4, :each, Array],
+                ["line", 4, __method__, self.class],
+                ["c-return", 4, :any?, Enumerable],
+                ["line", 5, __method__, self.class],
+                ["c-call", 5, :set_trace_func, Kernel]]
+    events.each_with_index{|e, i|
+      assert_equal(e, events[i], showit(events, expected))}
   end
 
   def test_invalid_proc
@@ -320,10 +315,11 @@
     end
     th.join
 
-    [["c-return", 1, :set_trace_func, Thread, :set],
-     ["line", 2, __method__, self.class, :set],
-     ["c-call", 2, :add_trace_func, Thread, :set]].each do |e|
-      assert_equal(e, events[:set].shift)
+    expected = [["c-return", 1, :set_trace_func, Thread, :set],
+                ["line", 2, __method__, self.class, :set],
+                ["c-call", 2, :add_trace_func, Thread, :set]]
+    expected.each do |e|
+      assert_equal(e, events[:set].shift, showit(events, expected))
     end
 
     [["c-return", 2, :add_trace_func, Thread],
@@ -354,4 +350,25 @@
     assert_equal([], events[:set])
     assert_equal([], events[:add])
   end
+
+  def test_trace_proc_that_raises_exception_recovery
+    $first_time = true
+    $traced = []
+    s = Proc.new {|event|
+      if $first_time
+        $first_time = false
+        raise RuntimeError
+      end
+      $traced << event
+    }
+    begin
+      set_trace_func(s)
+      assert_equal(false, 'hook should have raised error')
+    rescue RuntimeError
+      x = 1
+      set_trace_func(nil)
+      assert_equal(false, $traced.empty?, $traced)
+    end
+  end
+
 end
Index: template/insns_info.inc.tmpl
===================================================================
--- template/insns_info.inc.tmpl	(revision 27984)
+++ template/insns_info.inc.tmpl	(working copy)
@@ -42,38 +42,6 @@
 }
 #endif
 
-/* some utilities */
-
-static int
-insn_len(VALUE insn)
-{
-  return insn_len_info[(int)insn];
-}
-
-static const char *
-insn_name(VALUE insn)
-{
-  return insn_name_info[(int)insn];
-}
-
-static const char *
-insn_op_types(VALUE insn)
-{
-  return insn_operand_info[(int)insn];
-}
-
-static int
-insn_op_type(VALUE insn, long pos)
-{
-  int len = insn_len(insn) - 1;
-  if(pos < len){
-    return insn_operand_info[(int)insn][pos];
-  }
-  else{
-    return 0;
-  }
-}
-
 #ifdef USE_INSN_RET_NUM
 static int
 insn_ret_num(VALUE insn)
