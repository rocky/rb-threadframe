Index: method.h
===================================================================
--- method.h	(revision 28647)
+++ method.h	(working copy)
@@ -46,7 +46,11 @@
 
 typedef struct rb_method_cfunc_struct {
     VALUE (*func)(ANYARGS);
-    int argc;
+    int argc; /* This should probably be called "arity" since it is based
+		 on the static prototype, not the supplied arguments
+		 at runtime. */
+    int actual_argc; /* This probably should be called argc. It is the
+			argument count at runtime.*/
 } rb_method_cfunc_t;
 
 typedef struct rb_method_attr_struct {
Index: include/ruby/ruby.h
===================================================================
--- include/ruby/ruby.h	(revision 28647)
+++ include/ruby/ruby.h	(working copy)
@@ -1352,7 +1362,9 @@
 #define RUBY_EVENT_C_CALL    0x0020
 #define RUBY_EVENT_C_RETURN  0x0040
 #define RUBY_EVENT_RAISE     0x0080
-#define RUBY_EVENT_ALL       0xffff
+#define RUBY_EVENT_INSN      0x0100
+#define RUBY_EVENT_BRKPT     0x0200
+#define RUBY_EVENT_ALL       (0xffff & ~RUBY_EVENT_INSN)
 #define RUBY_EVENT_VM       0x10000
 #define RUBY_EVENT_SWITCH   0x20000
 #define RUBY_EVENT_COVERAGE 0x40000
Index: insns.def
===================================================================
--- insns.def	(revision 28647)
+++ insns.def	(working copy)
@@ -15,7 +15,7 @@
 
   instruction form:
     DEFINE_INSN
-    instrunction_name
+    instruction_name
     (instruction_operands, ..)
     (pop_values, ..)
     (return value)
Index: vm_core.h
===================================================================
--- vm_core.h	(revision 28647)
+++ vm_core.h	(working copy)
@@ -34,7 +34,7 @@
 #ifndef ENABLE_VM_OBJSPACE
 #ifdef _WIN32
 /*
- * TODO: object space indenpendent st_table.
+ * TODO: object space independent st_table.
  * socklist needs st_table in rb_w32_sysinit(), before object space
  * initialization.
  * It is too early now to change st_hash_type, since it breaks binary
@@ -166,7 +166,7 @@
     VALUE name;	         /* String: iseq name */
     VALUE filename;      /* file information where this sequence from */
     VALUE filepath;      /* real file path or nil */
-    VALUE *iseq;         /* iseq (insn number and openrads) */
+    VALUE *iseq;         /* iseq (insn number and operands) */
     VALUE *iseq_encoded; /* encoded iseq */
     unsigned long iseq_size;
     VALUE mark_ary;	/* Array: includes operands which should be GC marked */
@@ -190,7 +190,7 @@
      * argument information
      *
      *  def m(a1, a2, ..., aM,                    # mandatory
-     *        b1=(...), b2=(...), ..., bN=(...),  # optinal
+     *        b1=(...), b2=(...), ..., bN=(...),  # optional
      *        *c,                                 # rest
      *        d1, d2, ..., dO,                    # post
      *        &e)                                 # block
@@ -253,6 +253,8 @@
 
     /* used at compile time */
     struct iseq_compile_data *compile_data;
+    /* Used to set a breakpoint at a VM instruction */
+    unsigned char *breakpoints; 
 };
 
 enum ruby_special_exceptions {
@@ -330,6 +332,9 @@
     rb_iseq_t *block_iseq;	/* cfp[8] / block[3] */
     VALUE proc;			/* cfp[9] / block[4] */
     const rb_method_entry_t *me;/* cfp[10] */
+    short int tracing;          /* Bits to control per-frame event tracing. 
+				   See VM_FRAME_TRACE_xxx defines.
+				 */
 } rb_control_frame_t;
 
 typedef struct rb_block_struct {
@@ -390,6 +395,17 @@
     /* passing state */
     int state;
 
+    /* tracer */
+    rb_event_hook_t *event_hooks;
+    rb_event_flag_t event_flags;
+    int tracing;  /* 0 if not tracing. If less than 0, skip that many
+		     C call/return pairs */
+    int exec_event_tracing;  /* 0 if not in rb_threadptr_evec_event_hooks. */
+
+    /* misc */
+    int method_missing_reason;
+    int abort_on_exception;
+
     /* for rb_iterate */
     const rb_block_t *passed_block;
 
@@ -412,6 +429,14 @@
     int priority;
     int slice;
 
+    /* statistics data for profiler */
+    VALUE stat_insn_usage;
+
+    /* fiber */
+    VALUE fiber;
+    VALUE root_fiber;
+    rb_jmpbuf_t root_jmpbuf;
+
     native_thread_data_t native_thread_data;
     void *blocking_region_buffer;
 
@@ -461,22 +486,7 @@
     jmp_buf machine_regs;
     int mark_stack_len;
 
-    /* statistics data for profiler */
-    VALUE stat_insn_usage;
-
-    /* tracer */
-    rb_event_hook_t *event_hooks;
-    rb_event_flag_t event_flags;
-    int tracing;
-
-    /* fiber */
-    VALUE fiber;
-    VALUE root_fiber;
-    rb_jmpbuf_t root_jmpbuf;
-
     /* misc */
-    int method_missing_reason;
-    int abort_on_exception;
 #ifdef USE_SIGALTSTACK
     void *altstack;
 #endif
@@ -490,6 +500,7 @@
 VALUE rb_iseq_new_with_opt(NODE*, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, const rb_compile_option_t*);
 VALUE rb_iseq_compile(VALUE src, VALUE file, VALUE line);
 VALUE rb_iseq_disasm(VALUE self);
+VALUE rb_iseq_disasm_nochildren(VALUE self);
 int rb_iseq_disasm_insn(VALUE str, VALUE *iseqval, size_t pos, rb_iseq_t *iseq, VALUE child);
 const char *ruby_node_name(int node);
 int rb_iseq_first_lineno(rb_iseq_t *iseq);
@@ -564,6 +575,10 @@
 
 #define VM_FRAME_TYPE(cfp) ((cfp)->flag & VM_FRAME_MAGIC_MASK)
 
+#define VM_FRAME_TRACE_RETURN 0x01  /* Call trace hook on return. */
+#define VM_FRAME_TRACE_OFF    0x02  /* Turn of event hook tracing in this frame
+				       and any frames created from this one. */
+
 /* other frame flag */
 #define VM_FRAME_FLAG_PASSED 0x0100
 
@@ -691,13 +706,29 @@
 void
 rb_threadptr_exec_event_hooks(rb_thread_t *th, rb_event_flag_t flag, VALUE self, ID id, VALUE klass);
 
-#define EXEC_EVENT_HOOK(th, flag, self, id, klass) do { \
-    rb_event_flag_t wait_event__ = th->event_flags; \
-    if (UNLIKELY(wait_event__)) { \
-	if (wait_event__ & (flag | RUBY_EVENT_VM)) { \
-	    rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
-	} \
-    } \
-} while (0)
+#define EXEC_EVENT_HOOK(th, flag, self, id, klass)			\
+  if (LIKELY(0 == th->tracing)) {					\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+	    }								\
+	}								\
+    }
 
+/* Customized version of EXEC_EVENT_HOOK for RUBY_EVENT_RETURN events */
+#define EXEC_EVENT_RETURN_HOOK(th, flag, self, id, klass)		\
+    if (LIKELY(0 == th->tracing &&					\
+	       (!(th->cfp->tracing & VM_FRAME_TRACE_OFF)		\
+		|| (th->cfp->tracing & VM_FRAME_TRACE_RETURN)))) {	\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+	        th->tracing = 1;					\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+		th->tracing = 0;					\
+	    }								\
+	}								\
+    }
+
 #endif /* RUBY_VM_CORE_H */
Index: iseq.c
===================================================================
--- iseq.c	(revision 28647)
+++ iseq.c	(working copy)
@@ -23,6 +23,38 @@
 
 #define hidden_obj_p(obj) (!SPECIAL_CONST_P(obj) && !RBASIC(obj)->klass)
 
+/* some utilities */
+
+int
+insn_len(VALUE insn)
+{
+  return insn_len_info[(int)insn];
+}
+
+const char *
+insn_name(VALUE insn)
+{
+  return insn_name_info[(int)insn];
+}
+
+const char *
+insn_op_types(VALUE insn)
+{
+  return insn_operand_info[(int)insn];
+}
+
+int
+insn_op_type(VALUE insn, long pos)
+{
+  int len = insn_len(insn) - 1;
+  if(pos < len){
+    return insn_operand_info[(int)insn][pos];
+  }
+  else{
+    return 0;
+  }
+}
+
 static inline VALUE
 obj_resurrect(VALUE obj)
 {
@@ -118,6 +150,23 @@
     RUBY_MARK_LEAVE("iseq");
 }
 
+/* 
+ * This routine is here to allow an external C extension to create a
+ * RubyVM::InstructionSequence object sequence from its own C pointer
+ * of type rb_iseq_t *. For example, the rb-threadframe uses this
+ * routine to implement Method#iseq and Proc#iseq.
+ */
+VALUE
+iseq_alloc_shared(VALUE klass)
+{
+    VALUE volatile obj;
+    rb_iseq_t *iseq;
+
+    obj = Data_Make_Struct(klass, rb_iseq_t, iseq_mark, NULL, iseq);
+    MEMZERO(iseq, rb_iseq_t, 1);
+    return obj;
+}
+
 static size_t
 iseq_memsize(const void *ptr)
 {
@@ -395,6 +446,48 @@
 				parent, ISEQ_TYPE_MAIN, &COMPILE_OPTION_DEFAULT);
 }
 
+/* A debugger or similar introspection tool needs to be able to find
+ * all instruction sequences and access them. We facilitate this by
+ * adding the following behavior, analogous to SCRIPT_LINES__ for
+ * capturing source-code lines.
+ * 
+ * If SCRIPT_ISEQS__ is defined and is a hash, then every time a new
+ * instruction sequence is added, it is accessible from SCRIPT_ISEQS__
+ * using the "filename" as a key.
+ * 
+ * Similarly, if ISEQS__ is defined and is a hash, then every time a
+ * new instruction sequence is added, it is accessible from ISEQS__
+ * using its iseq_name as a key.  
+ */
+static void
+update_file_iseq(VALUE filename, VALUE iseq_name, VALUE iseq)
+{
+    ID hash_id;
+    CONST_ID(hash_id, "SCRIPT_ISEQS__");
+    if (rb_const_defined_at(rb_cObject, hash_id)) {
+	VALUE hash = rb_const_get_at(rb_cObject, hash_id);
+	if (TYPE(hash) == T_HASH) {
+	    VALUE iseqs = rb_hash_aref(hash, filename);
+	    if (TYPE(iseqs) == T_ARRAY)
+		rb_ary_push(iseqs, iseq);
+	    else
+		rb_hash_aset(hash, filename, rb_ary_new3(1, iseq));
+	}
+    }
+    CONST_ID(hash_id, "ISEQS__");
+    if (rb_const_defined_at(rb_cObject, hash_id)) {
+	VALUE hash = rb_const_get_at(rb_cObject, hash_id);
+	if (TYPE(hash) == T_HASH) {
+	    VALUE iseqs = rb_hash_aref(hash, iseq_name);
+	    if (TYPE(iseqs) == T_ARRAY)
+		rb_ary_push(iseqs, iseq);
+	    else
+		rb_hash_aset(hash, iseq_name, rb_ary_new3(1, iseq));
+	}
+    }
+}
+
+
 static VALUE
 rb_iseq_new_with_bopt_and_opt(NODE *node, VALUE name, VALUE filename, VALUE filepath, VALUE line_no,
 				VALUE parent, VALUE type, VALUE bopt,
@@ -409,6 +502,7 @@
     prepare_iseq_build(iseq, name, filename, filepath, line_no, parent, type, bopt, option);
     rb_iseq_compile_node(self, node);
     cleanup_iseq_build(iseq);
+    update_file_iseq(filename, name, self);
     return self;
 }
 
@@ -654,9 +748,13 @@
         return rb_sprintf("#<%s: uninitialized>", rb_obj_classname(self));
     }
 
-    return rb_sprintf("<%s:%s@%s>",
-                      rb_obj_classname(self),
-		      RSTRING_PTR(iseq->name), RSTRING_PTR(iseq->filename));
+    if (ISEQ_TYPE_TOP == iseq->type)
+	return rb_sprintf("<%s:%s>",
+			  rb_obj_classname(self), RSTRING_PTR(iseq->name));
+    else
+	return rb_sprintf("<%s:%s@%s>",
+			  rb_obj_classname(self),
+			  RSTRING_PTR(iseq->name), RSTRING_PTR(iseq->filename));
 }
 
 static
@@ -726,6 +824,117 @@
     return 0;
 }
 
+static void
+insn_operand_add_child(rb_iseq_t *iseq,
+		       VALUE insn, int op_no, VALUE op,
+		       VALUE child)
+{
+    const char *types = insn_op_types(insn);
+    char type = types[op_no];
+
+    switch (type) {
+      case TS_OFFSET:		/* LONG */
+	break;
+
+      case TS_NUM:		/* ULONG */
+	break;
+
+      case TS_LINDEX:
+	break;
+
+      case TS_DINDEX:
+	break;
+
+      case TS_ID:		/* ID (symbol) */
+	op = ID2SYM(op);
+
+      case TS_VALUE:		/* VALUE */
+	op = obj_resurrect(op);
+	if (CLASS_OF(op) == rb_cISeq) {
+	    rb_ary_push(child, op);
+	}
+	break;
+
+      case TS_ISEQ:		/* iseq */
+	{
+	    rb_iseq_t *iseq = (rb_iseq_t *)op;
+	    if (iseq) {
+		if (child) {
+		    rb_ary_push(child, iseq->self);
+		}
+	    }
+	    break;
+	}
+      case TS_GENTRY:
+	break;
+
+      case TS_IC:
+	break;
+
+      case TS_CDHASH:
+	break;
+
+      case TS_FUNCPTR:
+	break;
+
+      default:
+	rb_bug("rb_iseq_disasm: unknown operand type: %c", type);
+    }
+}
+
+/**
+ * Add to child array all instruction sequences found in an instruction.
+ */
+static int
+rb_iseq_insn_add_child(VALUE *iseq, size_t pos,
+		       rb_iseq_t *iseqdat, VALUE child)
+{
+    VALUE insn = iseq[pos];
+    int len = insn_len(insn);
+    int j;
+    const char *types = insn_op_types(insn);
+
+    for (j = 0; types[j]; j++) {
+	insn_operand_add_child(iseqdat, insn, j, iseq[pos + j + 1],
+			       child);
+    }
+    return len;
+}
+
+/* Return an ARRAY of iseq's which can be found off of this one. */
+VALUE
+rb_iseq_child_iseqs(VALUE self)
+{
+    VALUE *iseq;
+    rb_iseq_t *iseqdat;
+    VALUE child = rb_ary_new();
+    unsigned long size;
+    int i;
+    size_t n;
+    enum {header_minlen = 72};
+
+    rb_secure(1);
+    iseqdat = iseq_check(self);
+
+    rb_ary_push(child, self);
+    iseq = iseqdat->iseq;
+    size = iseqdat->iseq_size;
+
+    /* First, any catch table iseq's. */
+    for (i = 0; i < iseqdat->catch_table_size; i++) {
+	struct iseq_catch_table_entry *entry = &iseqdat->catch_table[i];
+	if (entry->iseq) {
+	    rb_ary_push(child, entry->iseq);
+	}
+    }
+
+    /* Next each iseq found inside the instructions */
+    for (n = 0; n < size;) {
+	n += rb_iseq_insn_add_child(iseq, n, iseqdat, child);
+    }
+    return child;
+}
+
 static VALUE
 insn_operand_intern(rb_iseq_t *iseq,
 		    VALUE insn, int op_no, VALUE op,
@@ -915,9 +1124,8 @@
 }
 
 VALUE
-rb_iseq_disasm(VALUE self)
+rb_iseq_disasm_internal(rb_iseq_t *iseqdat, int include_child)
 {
-    rb_iseq_t *iseqdat = iseq_check(self);
     VALUE *iseq;
     VALUE str = rb_str_new(0, 0);
     VALUE child = rb_ary_new();
@@ -1009,14 +1217,44 @@
 	n += rb_iseq_disasm_insn(str, iseq, n, iseqdat, child);
     }
 
-    for (i = 0; i < RARRAY_LEN(child); i++) {
-	VALUE isv = rb_ary_entry(child, i);
-	rb_str_concat(str, rb_iseq_disasm(isv));
-    }
+    if (include_child)
+	for (i = 0; i < RARRAY_LEN(child); i++) {
+	    VALUE isv = rb_ary_entry(child, i);
+	    rb_str_concat(str, rb_iseq_disasm(isv));
+	}
 
     return str;
 }
 
+/*
+ *  call-seq:
+ *     iseq.disasm   -> string
+ *
+ *  Returns a string disassembly of an instruction sequence.
+ */
+
+VALUE
+rb_iseq_disasm(VALUE self)
+{
+    return rb_iseq_disasm_internal(iseq_check(self), 1);
+}
+
+/*
+ *  call-seq:
+ *     iseq.disasm_nochildren   -> string
+ *
+ *  Returns a string disassembly of an instruction sequence, and
+ *  doesn't include instruction sequences for any associated catch
+ *  table, or instruction sequences found from this instruction
+ *  sequence.
+ */
+
+VALUE
+rb_iseq_disasm_nochildren(VALUE self)
+{
+    return rb_iseq_disasm_internal(iseq_check(self), 0);
+}
+
 static VALUE
 iseq_s_disasm(VALUE klass, VALUE body)
 {
@@ -1494,6 +1732,8 @@
     return iseqval;
 }
 
+extern void Init_Brkpt(void); /* In brkpt.c */
+
 void
 Init_ISeq(void)
 {
@@ -1502,9 +1742,11 @@
     rb_define_alloc_func(rb_cISeq, iseq_alloc);
     rb_define_method(rb_cISeq, "inspect", iseq_inspect, 0);
     rb_define_method(rb_cISeq, "disasm", rb_iseq_disasm, 0);
+    rb_define_method(rb_cISeq, "disasm_nochildren", rb_iseq_disasm_nochildren, 0);
     rb_define_method(rb_cISeq, "disassemble", rb_iseq_disasm, 0);
     rb_define_method(rb_cISeq, "to_a", iseq_to_a, 0);
     rb_define_method(rb_cISeq, "eval", iseq_eval, 0);
+    rb_define_method(rb_cISeq, "child_iseqs", rb_iseq_child_iseqs, 0);
 
     /* disable this feature because there is no verifier. */
     /* rb_define_singleton_method(rb_cISeq, "load", iseq_s_load, -1); */
@@ -1517,5 +1759,7 @@
     rb_define_singleton_method(rb_cISeq, "compile_option=", iseq_s_compile_option_set, 1);
     rb_define_singleton_method(rb_cISeq, "disasm", iseq_s_disasm, 1);
     rb_define_singleton_method(rb_cISeq, "disassemble", iseq_s_disasm, 1);
+
+    Init_Brkpt();
 }
 
Index: iseq.h
===================================================================
--- iseq.h	(revision 28647)
+++ iseq.h	(working copy)
@@ -101,4 +101,10 @@
 #define DEFINED_ZSUPER INT2FIX(9)
 #define DEFINED_FUNC   INT2FIX(10)
 
+/* some utilities */
+extern int insn_len(VALUE insn);
+extern const char *insn_name(VALUE insn);
+extern const char *insn_op_types(VALUE insn);
+extern int insn_op_type(VALUE insn, long pos);
+
 #endif /* RUBY_COMPILE_H */
Index: load.c
===================================================================
--- load.c	(revision 28647)
+++ load.c	(working copy)
@@ -294,11 +294,13 @@
     if (state == 0) {
 	NODE *node;
 	VALUE iseq;
+	char iseq_name[MAXPATHLEN];
 
 	th->mild_compile_error++;
 	node = (NODE *)rb_load_file(RSTRING_PTR(fname));
 	loaded = TRUE;
-	iseq = rb_iseq_new_top(node, rb_str_new2("<top (required)>"), fname, rb_realpath_internal(Qnil, fname, 1), Qfalse);
+	snprintf(iseq_name, sizeof(iseq_name), "<top %s>", RSTRING_PTR(fname));
+	iseq = rb_iseq_new_top(node, rb_str_new2(iseq_name), fname, rb_realpath_internal(Qnil, fname, 1), Qfalse);
 	th->mild_compile_error--;
 	rb_iseq_eval(iseq);
     }
Index: vm_eval.c
===================================================================
--- vm_eval.c	(revision 28647)
+++ vm_eval.c	(working copy)
@@ -67,22 +67,30 @@
 	break;
       }
       case VM_METHOD_TYPE_CFUNC: {
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, id, klass);
 	{
 	    rb_control_frame_t *reg_cfp = th->cfp;
 	    rb_control_frame_t *cfp =
 		vm_push_frame(th, 0, VM_FRAME_MAGIC_CFUNC,
 			      recv, (VALUE)blockptr, 0, reg_cfp->sp, 0, 1);
+	    /* Store actual argument count. Note that cfunc.argc
+	       contains the prototype value.
+	    */
+	    me->def->body.cfunc.actual_argc = argc;
 
 	    cfp->me = me;
+	    if (0 == th->tracing)
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, id, klass);
+
 	    val = call_cfunc(def->body.cfunc.func, recv, def->body.cfunc.argc, argc, argv);
 
 	    if (reg_cfp != th->cfp + 1) {
 		rb_bug("cfp consistency error - call0");
 	    }
+	    if (0 == th->tracing && 0 == th->exec_event_tracing) {
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, id, klass);
+	    }
 	    vm_pop_frame(th);
 	}
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, id, klass);
 	break;
       }
       case VM_METHOD_TYPE_ATTRSET: {
@@ -1025,7 +1038,25 @@
     if (state) {
 	if (state == TAG_RAISE) {
 	    VALUE errinfo = th->errinfo;
-	    if (strcmp(file, "(eval)") == 0) {
+	    /* The below test for eval is inadequate in several
+	       respects.  First rather than testing on a string like
+	       "(eval" or "(eval)" as was done originally, there
+	       should be a more positive indicator that "file" is not
+	       a real file but say, a string. Then there is the harder
+	       issue of what should be done to show the backtrace for
+	       this. Personally, I think part of the string should be
+	       shown. Finally because "(eval)" is used as the "file"
+	       name, it is harder to find this particular instruction
+	       sequence from the instruction sequence name over some
+	       other eval string.
+
+	       To start to deal with instruction sequence name
+	       unhelpfulness, we will prepare for the day when we have
+	       a more descriptive container such as the leading part
+	       of the string we are about to eval, e.g. (eval "x = y +
+	       ...")
+	     */
+	    if (strncmp(file, "(eval", sizeof("(eval")-1) == 0) {
 		VALUE mesg, errat, bt2;
 		extern VALUE rb_get_backtrace(VALUE info);
 		ID id_mesg;
Index: proc.c
===================================================================
--- proc.c	(revision 28647)
+++ proc.c	(working copy)
@@ -27,7 +27,7 @@
 VALUE rb_iseq_parameters(const rb_iseq_t *iseq, int is_proc);
 
 static VALUE bmcall(VALUE, VALUE);
-static int method_arity(VALUE);
+int method_arity(VALUE);
 static int rb_obj_is_method(VALUE m);
 rb_iseq_t *rb_method_get_iseq(VALUE method);
 
@@ -324,6 +328,28 @@
     return bindval;
 }
 
+/*  Like rb_binding_new(), but we allow you to pass your own thread and
+ *  cfp rather than assume the current thread and current frame
+ *  pointer. 
+*/
+VALUE
+rb_binding_frame_new(void *vth, void *vcfp)
+{
+    rb_thread_t * th = (rb_thread_t *) vth;
+    rb_control_frame_t * cfp  = (rb_control_frame_t *) vcfp;
+    VALUE bindval = binding_alloc(rb_cBinding);
+    rb_binding_t *bind;
+    
+    if (cfp == 0) {
+        rb_raise(rb_eRuntimeError, 
+		 "Can't create Binding Object on top of Fiber.");
+    }
+
+    GetBindingPtr(bindval, bind);
+    bind->env = rb_vm_make_env_object(th, cfp);
+    return bindval;
+}
+
 /*
  *  call-seq:
  *     binding -> a_binding
@@ -625,6 +647,29 @@
     return INT2FIX(arity);
 }
 
+int 
+get_iseq_arity(rb_iseq_t *iseq) 
+{
+    if (iseq) {
+	if (BUILTIN_TYPE(iseq) != T_NODE) {
+	    if (iseq->arg_rest < 0) {
+		return iseq->argc;
+	    }
+	    else {
+		return -(iseq->argc + 1 + iseq->arg_post_len);
+	    }
+	}
+	else {
+	    NODE *node = (NODE *)iseq;
+	    if (nd_type(node) == NODE_IFUNC && node->nd_cfnc == bmcall) {
+		/* method(:foo).to_proc.arity */
+		return method_arity(node->nd_tval);
+	    }
+	}
+    }
+    return -1;
+}
+
 int
 rb_proc_arity(VALUE self)
 {
@@ -1629,7 +1677,7 @@
     return INT2FIX(n);
 }
 
-static int
+int
 method_arity(VALUE method)
 {
     struct METHOD *data;
Index: thread.c
===================================================================
--- thread.c	(revision 28647)
+++ thread.c	(working copy)
@@ -336,6 +336,14 @@
 static void rb_mutex_unlock_all(mutex_t *mutex, rb_thread_t *th);
 static void rb_mutex_abandon_all(mutex_t *mutexes);
 
+rb_control_frame_t *
+thread_control_frame(rb_thread_t *th) 
+{
+  if (th == NULL || ((VALUE) th) == Qnil)
+    th = GET_THREAD(); /* main thread */
+  return rb_vm_get_ruby_level_next_cfp(th, th->cfp);
+}
+
 void
 rb_thread_terminate_all(void)
 {
@@ -3757,7 +3776,7 @@
     GetThreadPtr(thval, th);
 
     if (flag) {
-	th->event_flags |= RUBY_EVENT_VM;
+        th->event_flags |= (RUBY_EVENT_VM | RUBY_EVENT_BRKPT);
     }
     else {
 	th->event_flags &= (~RUBY_EVENT_VM);
@@ -3788,15 +3809,39 @@
     const rb_event_flag_t wait_event = th->event_flags;
 
     if (self == rb_mRubyVMFrozenCore) return;
-    if (wait_event & flag) {
-	exec_event_hooks(th->event_hooks, flag, self, id, klass);
+    if (wait_event & flag && th->tracing <= 0) {
+	if (!RUBY_VM_CONTROL_FRAME_STACK_OVERFLOW_P(th, th->cfp)
+	      && !(th->cfp->tracing & VM_FRAME_TRACE_OFF))
+	    exec_event_hooks(th->event_hooks, flag, self, id, klass);
     }
-    if (wait_event & RUBY_EVENT_VM) {
+    if (wait_event & RUBY_EVENT_VM && th->tracing <= 0) {
 	if (th->vm->event_hooks == NULL) {
 	    th->event_flags &= (~RUBY_EVENT_VM);
 	}
 	else {
-	    exec_event_hooks(th->vm->event_hooks, flag, self, id, klass);
+	    if (0 == th->exec_event_tracing) {
+		/* Modified from ruby_suppress_tracing */
+		int state;
+		volatile int raised = rb_threadptr_reset_raised(th);
+		rb_block_t * base_block_save = th->base_block;
+		th->exec_event_tracing = 1;
+		
+		PUSH_TAG();
+		if ((state = EXEC_TAG()) == 0) {
+		    exec_event_hooks(th->vm->event_hooks, flag, self, id, klass);
+		}
+		
+		th->base_block = base_block_save;
+		if (raised) {
+		    rb_threadptr_set_raised(th);
+		}
+		POP_TAG();
+		
+		th->exec_event_tracing = 0;
+		if (state) {
+		    JUMP_TAG(state);
+		}
+	    }
 	}
     }
     th->errinfo = errinfo;
@@ -3875,19 +3920,48 @@
     return ST_CONTINUE;
 }
 
-void
+VALUE
 rb_clear_trace_func(void)
 {
     st_foreach(GET_VM()->living_threads, clear_trace_func_i, (st_data_t) 0);
     rb_remove_event_hook(0);
+    return Qnil;
 }
 
 static void call_trace_func(rb_event_flag_t, VALUE data, VALUE self, ID id, VALUE klass);
 
+static VALUE
+add_trace_func(int argc, VALUE *argv)
+{
+    VALUE vmask;
+    VALUE trace;
+    int mask=RUBY_EVENT_ALL;
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &vmask)) {
+        mask = NUM2INT(vmask);
+    }
+
+    if (NIL_P(trace)) {
+	return Qnil;
+    }
+
+    if (!rb_obj_is_proc(trace)) {
+	rb_raise(rb_eTypeError, "trace_func needs to be Proc");
+    }
+
+    {
+	rb_thread_t *th = GET_THREAD(); /* main thread */
+	th->tracing     = -1;
+	rb_add_event_hook(call_trace_func, mask, trace);
+    }
+    
+    return trace;
+}
+
 /*
  *  call-seq:
- *     set_trace_func(proc)    -> proc
- *     set_trace_func(nil)     -> nil
+ *     set_trace_func(proc)        -> proc
+ *     set_trace_func(proc, mask)  -> proc
+ *     set_trace_func(nil)         -> nil
  *
  *  Establishes _proc_ as the handler for tracing, or disables
  *  tracing if the parameter is +nil+. _proc_ takes up
@@ -3901,6 +3976,8 @@
  *  <code>line</code> (execute code on a new line), <code>raise</code>
  *  (raise an exception), and <code>return</code> (return from a Ruby
  *  method). Tracing is disabled within the context of _proc_.
+ *  _mask_ is an optional bitmask of events to trigger on, See ruby.h
+ *  for the integer values. If no mask is specified all events are triggered.
  *
  *      class Test
  *	def test
@@ -3925,55 +4002,62 @@
  *	  line prog.rb:3        test     Test
  *	  line prog.rb:4        test     Test
  *      return prog.rb:4        test     Test
+ *
+ *      set_trace_func(proc { |event, file, line, id, binding, classname|
+ *	   printf "%8s %s:%-2d %10s %8s\n", event, file, line, id, classname
+ *      }, 0x018) # 0x018 == calls and returns only
+ *      t = Test.new
+ *      t.test
+ *
+ *  	  call prog.rb:2        test     Test
+ *      return prog.rb:4        test     Test
  */
 
 static VALUE
-set_trace_func(VALUE obj, VALUE trace)
+set_trace_func(int argc, VALUE *argv)
 {
     rb_remove_event_hook(call_trace_func);
-
-    if (NIL_P(trace)) {
-	return Qnil;
-    }
-
-    if (!rb_obj_is_proc(trace)) {
-	rb_raise(rb_eTypeError, "trace_func needs to be Proc");
-    }
-
-    rb_add_event_hook(call_trace_func, RUBY_EVENT_ALL, trace);
-    return trace;
+    return add_trace_func(argc, argv);
 }
 
 static void
-thread_add_trace_func(rb_thread_t *th, VALUE trace)
+thread_add_trace_func(rb_thread_t *th, VALUE trace, rb_event_flag_t events)
 {
     if (!rb_obj_is_proc(trace)) {
 	rb_raise(rb_eTypeError, "trace_func needs to be Proc");
     }
 
-    rb_threadptr_add_event_hook(th, call_trace_func, RUBY_EVENT_ALL, trace);
+    rb_threadptr_add_event_hook(th, call_trace_func, events, trace);
 }
 
 /*
  *  call-seq:
- *     thr.add_trace_func(proc)    -> proc
+ *     thr.add_trace_func(proc, events=RUBY_EVENT_ALL)    -> proc
  *
  *  Adds _proc_ as a handler for tracing.
  *  See <code>Thread#set_trace_func</code> and +set_trace_func+.
  */
 
 static VALUE
-thread_add_trace_func_m(VALUE obj, VALUE trace)
+thread_add_trace_func_m(int argc, VALUE *argv, VALUE obj)
 {
+    VALUE trace;
+    VALUE event_maskval;
+    rb_event_flag_t events=RUBY_EVENT_ALL;
     rb_thread_t *th;
+
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &event_maskval)) {
+        events = NUM2INT(event_maskval);
+    }
+
     GetThreadPtr(obj, th);
-    thread_add_trace_func(th, trace);
+    thread_add_trace_func(th, trace, events);
     return trace;
 }
 
 /*
  *  call-seq:
- *     thr.set_trace_func(proc)    -> proc
+ *     thr.set_trace_func(proc, events=RB_EVENT_ALL)    -> proc
  *     thr.set_trace_func(nil)     -> nil
  *
  *  Establishes _proc_ on _thr_ as the handler for tracing, or
@@ -3982,16 +4066,24 @@
  */
 
 static VALUE
-thread_set_trace_func_m(VALUE obj, VALUE trace)
+thread_set_trace_func_m(int argc, VALUE *argv, VALUE obj)   /* (VALUE obj, VALUE trace, events) */
 {
+    VALUE trace;
+    VALUE event_maskval;
+    rb_event_flag_t events=RUBY_EVENT_ALL;
     rb_thread_t *th;
+
+    if (2 == rb_scan_args(argc, argv, "11", &trace, &event_maskval)) {
+        events = NUM2INT(event_maskval);
+    }
+
     GetThreadPtr(obj, th);
     rb_threadptr_revmove_event_hook(th, call_trace_func);
 
     if (NIL_P(trace)) {
 	return Qnil;
     }
-    thread_add_trace_func(th, trace);
+    thread_add_trace_func(th, trace, events);
     return trace;
 }
 
@@ -4005,6 +4097,8 @@
 	return "class";
       case RUBY_EVENT_END:
 	return "end";
+      case RUBY_EVENT_BRKPT:
+	return "brkpt";
       case RUBY_EVENT_CALL:
 	return "call";
       case RUBY_EVENT_RETURN:
@@ -4015,6 +4109,14 @@
 	return "c-return";
       case RUBY_EVENT_RAISE:
 	return "raise";
+      case RUBY_EVENT_INSN:
+        return "vm-insn";
+      case RUBY_EVENT_SWITCH:
+        return "switch";
+      case RUBY_EVENT_COVERAGE:
+        return "coverage";
+      case RUBY_EVENT_VM:
+        return "vm";
       default:
 	return "unknown";
     }
@@ -4036,6 +4138,10 @@
     struct call_trace_func_args *p = (struct call_trace_func_args *)args;
     const char *srcfile = rb_sourcefile();
     VALUE eventname = rb_str_new2(get_event_name(p->event));
+    
+    if (p->event == RUBY_EVENT_INSN) 
+        return Qnil;
+    
     VALUE filename = srcfile ? rb_str_new2(srcfile) : Qnil;
     VALUE argv[6];
     int line = rb_sourceline();
@@ -4043,11 +4148,17 @@
     VALUE klass = 0;
 
     if (p->event == RUBY_EVENT_C_CALL ||
-	p->event == RUBY_EVENT_C_RETURN) {
+	p->event == RUBY_EVENT_C_RETURN ||
+	p->event == RUBY_EVENT_INSN) {
 	id = p->id;
 	klass = p->klass;
-    }
-    else {
+    } else if (p->event == RUBY_EVENT_RAISE) {
+        /* rb_thread_method_and_id() wants a place to store a klass
+	    value which subsequently we will not use.  */
+        VALUE junk_klass; 
+        rb_thread_method_id_and_class(GET_THREAD(), &id, &junk_klass);
+        klass = p->klass;
+    } else {
 	rb_thread_method_id_and_class(GET_THREAD(), &id, &klass);
     }
     if (id == ID_ALLOCATOR)
@@ -4234,9 +4346,11 @@
     rb_eThreadError = rb_define_class("ThreadError", rb_eStandardError);
 
     /* trace */
-    rb_define_global_function("set_trace_func", set_trace_func, 1);
-    rb_define_method(rb_cThread, "set_trace_func", thread_set_trace_func_m, 1);
-    rb_define_method(rb_cThread, "add_trace_func", thread_add_trace_func_m, 1);
+    rb_define_global_function("add_trace_func", add_trace_func, -1);
+    rb_define_global_function("set_trace_func", set_trace_func, -1);
+    rb_define_global_function("clear_trace_func", rb_clear_trace_func, 0);
+    rb_define_method(rb_cThread, "set_trace_func", thread_set_trace_func_m, -1);
+    rb_define_method(rb_cThread, "add_trace_func", thread_add_trace_func_m, -1);
 
     /* init thread core */
     {
Index: common.mk
===================================================================
--- common.mk	(revision 28647)
+++ common.mk	(working copy)
@@ -30,6 +30,7 @@
 
 COMMONOBJS    = array.$(OBJEXT) \
 		bignum.$(OBJEXT) \
+		brkpt.$(OBJEXT) \
 		class.$(OBJEXT) \
 		compar.$(OBJEXT) \
 		complex.$(OBJEXT) \
Index: eval.c
===================================================================
--- eval.c	(revision 28647)
+++ eval.c	(working copy)
@@ -34,7 +34,7 @@
 
 /* initialize ruby */
 
-void rb_clear_trace_func(void);
+VALUE rb_clear_trace_func(void);
 void rb_thread_stop_timer_thread(void);
 
 void rb_call_inits(void);
@@ -69,7 +69,7 @@
     GET_VM()->running = 1;
 }
 
-extern void rb_clear_trace_func(void);
+extern VALUE rb_clear_trace_func(void);
 
 void *
 ruby_options(int argc, char **argv)
@@ -440,7 +440,12 @@
     rb_trap_restore_mask();
 
     if (tag != TAG_FATAL) {
-	EXEC_EVENT_HOOK(th, RUBY_EVENT_RAISE, th->cfp->self, 0, 0);
+        /* In a RAISE event, we store as the "class" parameter the
+           the optional message parameter which is likely to be of more
+           use. Given a binding, a trace hook can get the class via 
+           eval('self.class', binding)
+	 */
+        EXEC_EVENT_HOOK(th, RUBY_EVENT_RAISE, th->cfp->self, 0, mesg);
     }
 }
 
Index: vm_exec.h
===================================================================
--- vm_exec.h	(revision 28647)
+++ vm_exec.h	(working copy)
@@ -18,6 +18,40 @@
 typedef rb_num_t GENTRY;
 typedef rb_iseq_t *ISEQ;
 
+#include "insns_info.inc"
+
+#if 0
+
+#define TRACE_INSN_SET_EXTRA_INFO(insn, var) do { var = Qnil; } while (0)
+
+#else
+
+#define TRACE_INSN_SET_EXTRA_INFO(insn, var) do { \
+  var = rb_ary_new2(insn_len(BIN(insn)) - 1); \
+  int trace_i__ = 0; \
+  while (trace_i__ < insn_len(BIN(insn)) - 1) { \
+    VALUE trace_push_val__ = Qnil; \
+    switch (insn_op_type(BIN(insn), trace_i__)) { \
+      case TS_VALUE: trace_push_val__ = GET_OPERAND(trace_i__ + 1); break; \
+      case TS_NUM: trace_push_val__ = INT2NUM(GET_OPERAND(trace_i__ + 1)); break; \
+      case TS_LINDEX: trace_push_val__ = INT2NUM((lindex_t) (GET_LFP() - GET_OPERAND(trace_i__ + 1))); break; \
+      case TS_DINDEX: trace_push_val__ = INT2NUM((dindex_t) (GET_DFP() - GET_OPERAND(trace_i__ + 1))); break; \
+      case TS_ID: trace_push_val__ = ID2SYM(GET_OPERAND(trace_i__ + 1)); break; \
+    } \
+    if (!SPECIAL_CONST_P(trace_push_val__)) \
+      trace_push_val__ = rb_type(trace_push_val__) == T_STRING ? \
+        rb_str_new_cstr(RSTRING_PTR(trace_push_val__)) : Qnil; \
+    rb_ary_push(var, trace_push_val__); \
+    trace_i__++; \
+  } \
+} while (0)
+
+#endif
+
+#define TRACE_INSN(insn) do { \
+  EXEC_EVENT_HOOK(th, RUBY_EVENT_INSN, GET_SELF(), 0, 0); \
+} while (0)
+
 #ifdef  COLLECT_USAGE_ANALYSIS
 #define USAGE_ANALYSIS_INSN(insn)           vm_analysis_insn(insn)
 #define USAGE_ANALYSIS_OPERAND(insn, n, op) vm_analysis_operand(insn, n, (VALUE)op)
@@ -28,12 +62,17 @@
 #define USAGE_ANALYSIS_REGISTER(reg, s)		/* none */
 #endif
 
-#ifdef __GCC__
+/* Rocky: VM-assisted breakpoint handling. */
+#define TEST_AND_HANDLE_BREAKPOINT(cfp, pc)				\
+    if (UNLIKELY(cfp->iseq &&						\
+		 cfp->iseq->breakpoints &&				\
+		 cfp->iseq->breakpoints[pc - cfp->iseq->iseq_encoded])) \
+	EXEC_EVENT_HOOK(th, RUBY_EVENT_BRKPT, cfp->self,		\
+			0, 0)
+
 /* TODO: machine dependent prefetch instruction */
-#define PREFETCH(pc)
-#else
-#define PREFETCH(pc)
-#endif
+#define PREFETCH(pc)							\
+    TEST_AND_HANDLE_BREAKPOINT(GET_CFP(), pc)
 
 #if VMDEBUG > 0
 #define debugs printf
Index: vm.c
===================================================================
--- vm.c	(revision 28647)
+++ vm.c	(working copy)
@@ -691,6 +691,7 @@
     if (RUBY_VM_NORMAL_ISEQ_P(iseq) && iseq->insn_info_size > 0) {
 	rb_num_t i;
 	size_t pos = cfp->pc - cfp->iseq->iseq_encoded;
+	line_no = iseq->insn_info_table[0].line_no;
 
 	if (iseq->insn_info_table[0].position == pos) goto found;
 	for (i = 1; i < iseq->insn_info_size; i++) {
@@ -1164,8 +1165,20 @@
 
 	while (th->cfp->pc == 0 || th->cfp->iseq == 0) {
 	    if (UNLIKELY(VM_FRAME_TYPE(th->cfp) == VM_FRAME_MAGIC_CFUNC)) {
-		const rb_method_entry_t *me = th->cfp->me;
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, me->called_id, me->klass);
+		/* rocky: The below tests and assignments are not
+		   quite right.  The problem I am having is when a
+		   there is an exception in hook code raised from a C
+		   return event. This causes the below EXEC_EVENT_HOOK to
+		   loop indefinitely. The below has the bad effect of
+		   not reseting exec_event_tracing sometimes.
+		 */
+		if (0 == th->tracing && 0 == th->exec_event_tracing) {
+		    const rb_method_entry_t *me = th->cfp->me;
+		    th->exec_event_tracing = 1;
+		    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, 
+				    me->called_id, me->klass);
+		    th->exec_event_tracing = 0;
+		}
 	    }
 	    th->cfp = RUBY_VM_PREVIOUS_CONTROL_FRAME(th->cfp);
 	}
@@ -1333,7 +1346,7 @@
 
 	    switch (VM_FRAME_TYPE(th->cfp)) {
 	      case VM_FRAME_MAGIC_METHOD:
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
+		EXEC_EVENT_RETURN_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
 		break;
 	      case VM_FRAME_MAGIC_CLASS:
 		EXEC_EVENT_HOOK(th, RUBY_EVENT_END, th->cfp->self, 0, 0);
Index: vm_insnhelper.c
===================================================================
--- vm_insnhelper.c	(revision 28647)
+++ vm_insnhelper.c	(working copy)
@@ -26,9 +26,12 @@
 	      const VALUE *pc, VALUE *sp, VALUE *lfp,
 	      int local_size)
 {
+    short int tracing = 0;
     rb_control_frame_t * const cfp = th->cfp - 1;
     int i;
 
+    if (type != VM_FRAME_MAGIC_TOP) tracing = th->cfp->tracing;
+
     if ((void *)(sp + local_size) >= (void *)cfp) {
 	rb_exc_raise(sysstack_error);
     }
@@ -60,6 +63,7 @@
     cfp->dfp = sp;
     cfp->proc = 0;
     cfp->me = 0;
+    cfp->tracing = tracing;
 
 #define COLLECT_PROFILE 0
 #if COLLECT_PROFILE
@@ -391,11 +395,15 @@
     const rb_method_definition_t *def = me->def;
     rb_control_frame_t *cfp;
 
-    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, me->called_id, me->klass);
-
     cfp = vm_push_frame(th, 0, VM_FRAME_MAGIC_CFUNC,
 			recv, (VALUE) blockptr, 0, reg_cfp->sp, 0, 1);
+    /* Store actual argument count. Note that cfunc.argc contains the
+       prototype value.
+    */
+    me->def->body.cfunc.actual_argc = num;
     cfp->me = me;
+    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_CALL, recv, me->called_id, me->klass);
+
     reg_cfp->sp -= num + 1;
 
     val = call_cfunc(def->body.cfunc.func, recv, (int)def->body.cfunc.argc, num, reg_cfp->sp + 1);
@@ -404,10 +412,21 @@
 	rb_bug("cfp consistency error - send");
     }
 
+    if (0 == th->tracing) {
+	rb_event_flag_t wait_event__ = th->event_flags;			
+	if (UNLIKELY(wait_event__)) {
+	    reg_cfp->sp += (num + 1);
+	    PUSH(val);
+	    rb_threadptr_exec_event_hooks(th, RUBY_EVENT_C_RETURN, recv, 
+					  me->called_id, me->klass);
+	    val = reg_cfp->sp[-1];    /* Allow for hook to change value */
+	    reg_cfp->sp -= (num + 2); /* +1 for above push */
+	}
+    } else if (th->tracing < 0)
+	th->tracing++;
+
     vm_pop_frame(th);
 
-    EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, recv, me->called_id, me->klass);
-
     return val;
 }
 
@@ -477,6 +496,13 @@
 		      iseq->iseq_encoded + opt_pc, sp, 0, 0);
 
 	cfp->sp = rsp - 1 /* recv */;
+	if (LIKELY(0 == th->tracing)) {
+	    EXEC_EVENT_HOOK(th, RUBY_EVENT_INSN, cfp->self, 0, 0);
+	    if (UNLIKELY(cfp->iseq &&
+			 cfp->iseq->breakpoints &&
+			 cfp->iseq->breakpoints[opt_pc]))
+		EXEC_EVENT_HOOK(th, RUBY_EVENT_BRKPT, cfp->self, 0, 0);
+	}
     }
     else {
 	VALUE *p_rsp;
Index: tool/instruction.rb
===================================================================
--- tool/instruction.rb	(revision 28647)
+++ tool/instruction.rb	(working copy)
@@ -854,6 +854,17 @@
       commit "INSN_ENTRY(#{insn.name}){"
       make_header_prepare_stack insn
       commit "{"
+      # rocky: for reasons that I don't understand, calling the
+      # instruction trace hook in a "leave" instruction causes a
+      # SEGV via an illegal access csuch as via vm.c line 1144: 
+      #    ep = ... cfp->iseq ...  
+      # 
+      # Since we can handle this event via RUBY_EVENT_END I don't
+      # think there is any loss in functionality.
+      # Not sure if "send" should be included.
+      unless %w(leave send).member?(insn.name)
+        commit "  TRACE_INSN(#{insn.name});"
+      end
       make_header_stack_val  insn
       make_header_default_operands insn
       make_header_operands   insn
Index: test/ruby/test_settracefunc.rb
===================================================================
--- test/ruby/test_settracefunc.rb	(revision 28647)
+++ test/ruby/test_settracefunc.rb	(working copy)
@@ -23,8 +23,6 @@
      4: x = 1 + 1
      5: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :+, Fixnum],
@@ -50,8 +48,6 @@
      7: x = add(1, 1)
      8: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -88,10 +84,8 @@
      6:   end
      7: end
      8: x = Foo.new.bar
-     9: set_trace_func(nil)
+     9: clear_trace_func()
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :inherited, Class],
@@ -124,7 +118,7 @@
                  events.shift)
     assert_equal(["line", 9, __method__, self.class],
                  events.shift)
-    assert_equal(["c-call", 9, :set_trace_func, Kernel],
+    assert_equal(["c-call", 9, :clear_trace_func, Kernel],
                  events.shift)
     assert_equal([], events)
   end
@@ -132,7 +126,7 @@
   def test_return # [ruby-dev:38701]
     events = []
     eval <<-EOF.gsub(/^.*?: /, "")
-     1: set_trace_func(Proc.new { |event, file, lineno, mid, binding, klass|
+     1: add_trace_func(Proc.new { |event, file, lineno, mid, binding, klass|
      2:   events << [event, lineno, mid, klass]
      3: })
      4: def foo(a)
@@ -143,8 +137,6 @@
      9: foo(false)
     10: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -187,8 +179,6 @@
      8: foo
      9: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["c-call", 4, :method_added, Module],
@@ -220,12 +210,10 @@
      3: })
      4: begin
      5:   raise TypeError, "error"
-     6: rescue TypeError
+     6: rescue TypeError => $e
      7: end
      8: set_trace_func(nil)
     EOF
-    assert_equal(["c-return", 3, :set_trace_func, Kernel],
-                 events.shift)
     assert_equal(["line", 4, __method__, self.class],
                  events.shift)
     assert_equal(["line", 5, __method__, self.class],
@@ -248,7 +236,7 @@
                  events.shift)
     assert_equal(["c-return", 5, :set_backtrace, Exception],
                  events.shift)
-    assert_equal(["raise", 5, :test_raise, TestSetTraceFunc],
+    assert_equal(["raise", 5, :test_raise, $e], 
                  events.shift)
     assert_equal(["c-return", 5, :raise, Kernel],
                  events.shift)
@@ -263,6 +251,15 @@
     assert_equal([], events)
   end
 
+  def chunk(list, char)
+    sep = char * 30 + "\n"
+    sep + list.map{|e| e.join(' ')}.join("\n") + "\n"
+  end
+
+  def showit(actual, expected)
+    chunk(actual, '-') + chunk(expected, '=')
+  end
+
   def test_break # [ruby-core:27606] [Bug #2610]
     events = []
     eval <<-EOF.gsub(/^.*?: /, "")
@@ -273,17 +270,15 @@
      8: set_trace_func(nil)
     EOF
 
-    [["c-return", 3, :set_trace_func, Kernel],
-     ["line", 4, __method__, self.class],
-     ["c-call", 4, :any?, Enumerable],
-     ["c-call", 4, :each, Array],
-     ["line", 4, __method__, self.class],
-     ["c-return", 4, :each, Array],
-     ["c-return", 4, :any?, Enumerable],
-     ["line", 5, __method__, self.class],
-     ["c-call", 5, :set_trace_func, Kernel]].each{|e|
-      assert_equal(e, events.shift)
-    }
+    expected = [["line", 4, __method__, self.class],
+                ["c-call", 4, :any?, Enumerable],
+                ["c-call", 4, :each, Array],
+                ["line", 4, __method__, self.class],
+                ["c-return", 4, :any?, Enumerable],
+                ["line", 5, __method__, self.class],
+                ["c-call", 5, :set_trace_func, Kernel]]
+    events.each_with_index{|e, i|
+      assert_equal(e, events[i], showit(events, expected))}
   end
 
   def test_invalid_proc
@@ -320,10 +315,11 @@
     end
     th.join
 
-    [["c-return", 1, :set_trace_func, Thread, :set],
-     ["line", 2, __method__, self.class, :set],
-     ["c-call", 2, :add_trace_func, Thread, :set]].each do |e|
-      assert_equal(e, events[:set].shift)
+    expected = [["c-return", 1, :set_trace_func, Thread, :set],
+                ["line", 2, __method__, self.class, :set],
+                ["c-call", 2, :add_trace_func, Thread, :set]]
+    expected.each do |e|
+      assert_equal(e, events[:set].shift, showit(events, expected))
     end
 
     [["c-return", 2, :add_trace_func, Thread],
@@ -354,4 +350,25 @@
     assert_equal([], events[:set])
     assert_equal([], events[:add])
   end
+
+  def test_trace_proc_that_raises_exception_recovery
+    $first_time = true
+    $traced = []
+    s = Proc.new {|event|
+      if $first_time
+        $first_time = false
+        raise RuntimeError
+      end
+      $traced << event
+    }
+    begin
+      set_trace_func(s)
+      assert_equal(false, 'hook should have raised error')
+    rescue RuntimeError
+      x = 1
+      set_trace_func(nil)
+      assert_equal(false, $traced.empty?, $traced)
+    end
+  end
+
 end
Index: template/insns_info.inc.tmpl
===================================================================
--- template/insns_info.inc.tmpl	(revision 28647)
+++ template/insns_info.inc.tmpl	(working copy)
@@ -42,38 +42,6 @@
 }
 #endif
 
-/* some utilities */
-
-static int
-insn_len(VALUE insn)
-{
-  return insn_len_info[(int)insn];
-}
-
-static const char *
-insn_name(VALUE insn)
-{
-  return insn_name_info[(int)insn];
-}
-
-static const char *
-insn_op_types(VALUE insn)
-{
-  return insn_operand_info[(int)insn];
-}
-
-static int
-insn_op_type(VALUE insn, long pos)
-{
-  int len = insn_len(insn) - 1;
-  if(pos < len){
-    return insn_operand_info[(int)insn][pos];
-  }
-  else{
-    return 0;
-  }
-}
-
 #ifdef USE_INSN_RET_NUM
 static int
 insn_ret_num(VALUE insn)
Index: brkpt.c
--- brkpt.c	(revision 28642)
+++ brkpt.c	(working copy)
@@ -0,0 +1,232 @@
+/**********************************************************************
+  brkpt.c - VM-assisted Breakpoint support 
+
+**********************************************************************/
+
+#include "ruby/ruby.h"
+
+#include "vm_core.h"
+#include "iseq.h"
+
+VALUE rb_cISeq;
+
+/* 
+ *  call-seq:
+ *  RubyVM::InstructionSequence#brkpt_alloc -> bool
+ *
+ *  Allocates a breakpoint byte vector of zeros for each 
+ *  instruction in the instruction sequence. True is returned if 
+ *  a vector was allocated, false if there already was one allocated,
+ *  and nil if there was some problem.
+ */
+
+VALUE
+iseq_brkpt_alloc(VALUE iseqval)
+{
+    rb_iseq_t *iseq;
+    if (Qnil == iseqval) return Qnil;
+    else {
+	GetISeqPtr(iseqval, iseq);
+	if (iseq->breakpoints) {
+	    return Qfalse;
+	}
+	iseq->breakpoints = calloc( iseq->iseq_size, sizeof(unsigned char));
+	return Qtrue;
+    }
+}
+
+/* 
+ *  Document-method: RubyVM::InstructionSequence::brkpt_dealloc -> bool
+ *
+ *  call-seq:
+ *     RubyVM::InstructionSequence#dealloc -> bool
+ *
+ *  Deallocates a breakpoint byte vector of zeros for each 
+ *  instruction in the instruction sequence. True is returned if 
+ *  a vector was allocated, false if there already was one allocated,
+ *  and nil if there was some problem.
+ */
+VALUE
+iseq_brkpt_dealloc(VALUE iseqval)
+{
+    rb_iseq_t *iseq;
+    if (Qnil == iseqval) return Qnil;
+    else {
+	GetISeqPtr(iseqval, iseq);
+	if (!iseq->breakpoints) {
+	    return Qfalse;
+	}
+	free(iseq->breakpoints);
+	iseq->breakpoints = NULL;
+	return Qtrue;
+    }
+}
+
+/* 
+ *  Checks that offsetval is in range and converts it to a positive
+ *  integer. An exception is raised if offsetval is invalid.
+ */
+static long unsigned int
+iseq_get_offset_internal(rb_iseq_t *iseq, VALUE offsetval)
+{
+    if (FIXNUM_P(offsetval)) {
+	long int offset = FIX2INT(offsetval);
+	unsigned long int uoffset;
+	unsigned long int size = iseq->iseq_size;
+
+	uoffset = (offset < 0) ? 
+	    (unsigned long int) size + offset :
+	    (unsigned long int) offset;
+	
+	/* FIXME: check that offset is at a valid instruction offset */
+	if (uoffset >= size) {
+	    rb_raise(rb_eTypeError, 
+		     "instruction sequence offset %lu should be in the range -%lu .. %lu",
+		     uoffset, size, size-1);
+	}
+	return uoffset;
+    } else {
+	rb_raise(rb_eTypeError, "type mismatch: %s given, Fixnum expected", 
+		 rb_class2name(CLASS_OF(offsetval)));
+	return 0; /* NOT REACHED */
+    }
+    
+}
+
+/* 
+ *  Document-method: RubyVM::InstructionSequence::brkpt_get(offset)
+ *
+ *  call-seq:
+ *     RubyVM::InstructionSequence#brkpt_get(offset) -> bool
+ *
+ *  Get a value of breakpoint of byte vector at +offset+.
+ *
+ *  True is returned if there is a breakpoint previously set, false
+ *  if not, and nil if there was some problem. Negative values of
+ *  <i>offset</i> count from the end of the instruction sequence.
+ */
+VALUE
+iseq_brkpt_get(VALUE iseqval, VALUE offsetval)
+{
+    if (Qnil != iseqval) {
+	rb_iseq_t *iseq;
+	unsigned long int uoffset;
+	
+	GetISeqPtr(iseqval, iseq);
+	if (!iseq->breakpoints) return Qfalse;
+
+	uoffset = iseq_get_offset_internal(iseq, offsetval);
+	      
+	/* FIXME: check that offset is at a valid instruction offset */
+	return (0 != iseq->breakpoints[uoffset]) ? Qtrue : Qfalse;
+    }
+    return Qnil;
+}
+
+static VALUE
+iseq_brkpt_set_unset(VALUE iseqval, VALUE offsetval, char val)
+{
+    if (Qnil != iseqval) {
+	rb_iseq_t *iseq;
+	unsigned long int uoffset;
+
+	GetISeqPtr(iseqval, iseq);
+	if (!iseq->breakpoints) {
+	    if (val) {
+		/* Set breakpoint requested */
+		VALUE alloc_ret = iseq_brkpt_alloc(iseqval);
+		if (!iseq->breakpoints) return alloc_ret;
+	    } else 
+		/* Unset breakpoint requested. */
+		return Qtrue;
+	}
+	uoffset = iseq_get_offset_internal(iseq, offsetval);
+
+	/* FIXME: check that offset is at a valid instruction offset */
+	iseq->breakpoints[uoffset] = val;
+	return Qtrue;
+    }
+    return Qnil;
+}
+
+/* 
+ *  Document-method: RubyVM::InstructionSequence::brkpt_set(offset) -> bool
+ *
+ *  call-seq:
+ *     RubyVM::InstructionSequence#brkpt_set(offset) -> bool
+ *
+ *  Set a breakpoint of byte vector at +offset+.
+ *
+ * +true+ is returned if the breakpoint is now set. An IndexError can or a
+ * TypeError can be raised if values are invalid.  Negative values of
+ * +offset+ count from the end of the instruction sequence.
+ */
+VALUE
+iseq_brkpt_set(VALUE iseqval, VALUE offsetval)
+{
+    return iseq_brkpt_set_unset(iseqval, offsetval, '\001');
+}
+
+/* 
+ *  Document-method: RubyVM::InstructionSequence::brkpt_unset
+ *
+ *  call-seq:
+ *     RubyVM::InstructionSequence#brkpt_unset(offset) -> bool
+ *
+ *  Unsets breakpoint of byte vector at +offset+.
+ * 
+ *  True is returned if the breakpoint is now unset. An IndexError can or
+ *  a TypeError can be raised if values are invalid.  However if the
+ *  instruction sequence does not have any breakpoints allocated, we
+ *  will not check whether the offset is valid in any way.
+ * 
+ *  Negative values of <i>offset</i> count from the end of the
+ *  instruction sequence. 
+ */
+VALUE
+iseq_brkpt_unset(VALUE iseqval, VALUE offsetval)
+{
+    return iseq_brkpt_set_unset(iseqval, offsetval, '\000');
+}
+
+/* 
+ *  Document-method: RubyVM::InstructionSequence::brkpts
+ *
+ *  call-seq:
+ *     RubyVM::InstructionSequence#brkpts -> Array
+ *
+ *  Returns a list of breakpoints in effect for this instruction sequence.
+ *  If no breakpoints have been allocated nil is returned. If breakpoints
+ *  were allocated but none are set then the empty array is returned.
+ */
+VALUE
+iseq_brkpts(VALUE iseqval)
+{
+    rb_iseq_t *iseq;
+    if (Qnil == iseqval) return Qnil;
+    else {
+	GetISeqPtr(iseqval, iseq);
+	if (iseq->breakpoints) {
+	    unsigned int offset;
+	    VALUE ary = rb_ary_new();
+	    for (offset = 0; offset < iseq->iseq_size; offset++) {
+		if (iseq->breakpoints[offset])
+		    rb_ary_push(ary, INT2FIX(offset));
+	    }
+	    return ary;
+	} else {
+	    return Qnil;
+	}
+    }
+}
+
+void
+Init_Brkpt(void)
+{
+    rb_define_method(rb_cISeq, "brkpt_alloc",      iseq_brkpt_alloc, 0);
+    rb_define_method(rb_cISeq, "brkpt_dealloc",    iseq_brkpt_dealloc, 0);
+    rb_define_method(rb_cISeq, "brkpt_get",        iseq_brkpt_get, 1);
+    rb_define_method(rb_cISeq, "brkpt_set",        iseq_brkpt_set, 1);
+    rb_define_method(rb_cISeq, "brkpt_unset",      iseq_brkpt_unset, 1);
+    rb_define_method(rb_cISeq, "brkpts",           iseq_brkpts, 0);
+}
Index: test/ruby/test_brkpt.rb
--- test/ruby/test_brkpt.rb	(revision 28642)
+++ test/ruby/test_brkpt.rb	(working copy)
@@ -0,0 +1,60 @@
+require 'test/unit'
+
+class TestISeqBrkpt < Test::Unit::TestCase
+
+  def setup
+    @original_compile_option = RubyVM::InstructionSequence.compile_option
+    RubyVM::InstructionSequence.compile_option = {
+      :trace_instruction => false,
+      :specialized_instruction => false
+    }
+  end
+
+  def teardown
+    set_trace_func(nil)
+    RubyVM::InstructionSequence.compile_option = @original_compile_option
+  end
+
+  def test_iseq_brkpt
+    iseq = RubyVM::InstructionSequence.compile('x=1; y=2')
+    assert iseq
+    assert_equal(nil, iseq.brkpts)
+    assert_equal(true, iseq.brkpt_alloc)
+    assert_equal([], iseq.brkpts)
+    assert_equal(false, iseq.brkpt_alloc)
+    
+    assert_equal(true, iseq.brkpt_set(0))
+    assert_equal(1,    iseq.brkpts.size)
+    assert_equal(true, iseq.brkpt_get(0), 'Offset 0 should be set')
+    assert_equal(true, iseq.brkpt_unset(0),'Offset 0 should be unset')
+    assert_equal(false, iseq.brkpt_get(0), 'Offset 0 should be unset now')
+    assert_equal(true, iseq.brkpt_unset(0), 
+                 'Offset 0 should be unset again')
+    assert_raises TypeError do iseq.brkpt_get(100) end
+    assert_equal(true, iseq.brkpt_dealloc)
+    assert_equal(false, iseq.brkpt_dealloc)
+    assert_equal(true, iseq.brkpt_unset(0),
+                 'Offset 0 should be unset even when deallocated')
+
+    assert_raises TypeError do iseq.brkpt_set('a') end
+
+    iseq.brkpt_set(2)    
+    iseq.brkpt_set(4)    
+    events = []
+    eval <<-EOF.gsub(/^.*?: /, "")
+     1: set_trace_func(Proc.new { |event, file, lineno, mid, binding, klass|
+     2:   events << [event, lineno, mid, klass]
+     3: })
+     4: iseq.eval
+     5: set_trace_func(nil)
+    EOF
+    # puts iseq.disassemble
+    brkpt_events = events.select{|item| item[0] == 'brkpt'}
+    assert_equal(2, brkpt_events.size, 
+                 "Expecting to see 2 brkpts in #{events}.inspect")
+    assert_equal(true, iseq.brkpt_dealloc)
+  end
+end
+
+# We want to double-check we didn't mess up any pointers somewhere.
+at_exit { GC.start  }
Index: test/ruby/test_disam.rb
===================================================================
--- test/ruby/test_disasm.rb	(revision 28642)
+++ test/ruby/test_disasm.rb	(working copy)
@@ -0,0 +1,17 @@
+# Some simple tests of RubyVM::InstructionSequence#disasm, and
+# #disasm_nochildren
+require 'test/unit'
+
+class TestDisasmClass < Test::Unit::TestCase
+
+  def test_basic
+    assert_equal(RubyVM::InstructionSequence.compile('1+2').disassemble,
+                 RubyVM::InstructionSequence.compile('1+2').disasm)
+
+    p='def five; 5 end; five'
+    s1=RubyVM::InstructionSequence.compile(p).disasm
+    assert_equal String, s1.class, 'disasm output should be a string'
+    s2=RubyVM::InstructionSequence.compile(p).disasm_nochildren
+    assert_equal true, s1.size > s2.size
+  end
+end
Index: test/ruby/test_iseq.rb
===================================================================
--- test/ruby/test_iseq.rb	(revision 28642)
+++ test/ruby/test_iseq.rb	(working copy)
@@ -0,0 +1,1 @@
+# See that setting ISEQS__ and SCRIPT_ISEQS__ saves 
+# RubyVM::Instruction_sequenses
+require 'test/unit'
+
+class TestIseqAccess < Test::Unit::TestCase
+  def test_basic
+    Kernel.const_set(:SCRIPT_ISEQS__, {})
+    Kernel.const_set(:ISEQS__, {})
+    sizes=[]
+    [ISEQS__, SCRIPT_ISEQS__].each do |iseq_hash|
+      sizes << iseq_hash.size
+    end
+    # defining five should trigger five instruction sequence additions
+    # to ISEQS__ and SCRIPT_ISEQS__
+    # 
+    eval 'def five; 5 end'
+    assert_equal sizes[0], sizes[1]
+    [SCRIPT_ISEQS__, ISEQS__].each do |iseq_hash|
+      assert_equal true, iseq_hash.size > sizes.pop
+      assert_equal Hash, iseq_hash.class
+      a = iseq_hash.first
+      assert_equal Array, a.class
+      assert_equal RubyVM::InstructionSequence, iseq_hash.values[0][0].class
+    end
+    Kernel.const_set(:SCRIPT_ISEQS__, nil)
+    Kernel.const_set(:ISEQS__, nil)
+  end
+end
Index: test/ruby/test_tracefunc_adds.rb
--- test/ruby/test_tracefunc_adds.rb	(revision 28642)
+++ test/ruby/test_tracefunc_adds.rb	(working copy)
@@ -0,0 +1,131 @@
+require 'test/unit'
+
+# tests set_trace_func with event bitmasks, clear_trace_func, 
+# Newer changes
+class TestSetTraceFuncAdds < Test::Unit::TestCase
+
+  # Some of the below setup is similar to what is in lib/trace_mod.rb of 
+  # rb-trace
+  @@NO_EVENT_MASK        = 0x0000
+  @@LINE_EVENT_MASK      = 0x0001
+  @@CLASS_EVENT_MASK     = 0x0002
+  @@END_EVENT_MASK       = 0x0004
+  @@CALL_EVENT_MASK      = 0x0008
+  @@RETURN_EVENT_MASK    = 0x0010
+  @@C_CALL_EVENT_MASK    = 0x0020
+  @@C_RETURN_EVENT_MASK  = 0x0040
+  @@RAISE_EVENT_MASK     = 0x0080
+  @@ALL_EVENTS_MASK      = 0x00ff
+  
+  @@EVENT2MASK = {
+    'line'     => @@LINE_EVENT_MASK,
+    'call'     => @@CALL_EVENT_MASK,
+    'return'   => @@RETURN_EVENT_MASK,
+    'c-call'   => @@C_CALL_EVENT_MASK,
+    'c-return' => @@C_RETURN_EVENT_MASK,
+    'c-raise'  => @@RAISE_EVENT_MASK
+  }
+
+  # Convert +events+ into a Fixnum bitmask used internally by Ruby.
+  # Parameter +events+ should be Enumerable and each element should
+  # either be a Fixnum mask value or something that can be converted
+  # to a symbol. If the latter, the case is not important as we'll
+  # downcase the string representation.
+  def events2bitmask(event_list)
+    bitmask = @@NO_EVENT_MASK
+    event_list.each do |event|
+      bitmask |= @@EVENT2MASK[event]
+    end
+    return bitmask
+  end
+
+  def setup
+    @original_compile_option = RubyVM::InstructionSequence.compile_option
+    RubyVM::InstructionSequence.compile_option = {
+      :trace_instruction => true,
+      :specialized_instruction => false
+    }
+    @proc_template = 'Proc.new { |event, file, lineno, mid, binding, klass|
+      %s << [event, lineno, mid, klass]}'
+  end
+
+  def teardown
+    clear_trace_func
+    RubyVM::InstructionSequence.compile_option = @original_compile_option
+  end
+
+
+  def test_eventmask
+    returned_tuples = 
+      [['line', 5, :test_eventmask, self.class],
+       ['class', 5, nil, nil],
+       ['end', 5, nil, nil],
+       ['line', 6, :test_eventmask, self.class],
+       ['call', 1, :five, self.class],
+       ['line', 1, :five, self.class],
+       ['return', 1, :five, self.class],
+       ['c-call', 6, :any?, Enumerable],
+       ['c-call', 6, :each, Array],
+       ['line', 6, :test_eventmask, self.class],
+       ['c-return', 6, :each, Array],
+       ['c-return', 6, :any?, Enumerable],
+       ['line', 7, :test_eventmask, self.class],
+       ['c-call', 7, :clear_trace_func, Kernel]]
+
+    [[], nil, 
+     %w(line),
+     %w(call line),
+     %w(c-call c-return line),
+    ].each do |event_list|
+      tuples = []
+      event_mask = if event_list
+                     events2bitmask(event_list)
+                   else
+                     @@ALL_EVENTS_MASK
+                   end
+      cmd = <<-EOF.gsub(/^.*?: /, '')
+        1: def five; 5 end
+        2: p1 = #{@proc_template}
+        3: set_trace_func(p1, #{event_mask})
+        4: class Foo; end
+        5: [1,2,five].any? {|n| n}
+        6: clear_trace_func
+      EOF
+      eval(cmd % 'tuples')
+      expected = if event_list
+                   returned_tuples.select{|x| !([x[0]] & event_list).empty?}
+                 else
+                   returned_tuples
+                 end
+      assert_equal(expected, tuples, 
+                   "Error filtering #{event_list}")
+     # p tuples
+    end
+  end
+
+  def test_chained_hook
+    tuples1 = []
+    tuples2 = []
+    cmd = <<-EOF.gsub(/^.*?: /, '')
+        1: def five; 5 end
+        2: p1 = #{@proc_template}
+        3: p2 = #{@proc_template}
+        4: add_trace_func(p1, @@LINE_EVENT_MASK)
+        5: add_trace_func(p2, @@CALL_EVENT_MASK)
+        6: class Foo; end
+        7: [1,2,five].any? {|n| n}
+      EOF
+    eval(cmd % %w(tuples1 tuples2))
+    clear_trace_func
+    assert_equal([
+                  ["line", 7, :test_chained_hook, self.class], 
+                  ["line", 8, :test_chained_hook, self.class], 
+                  ["line", 9, :test_chained_hook, self.class], 
+                  ["line", 1, :five, self.class], 
+                  ["line", 9, :test_chained_hook, self.class], 
+                 ], tuples1[0..-2],
+                 'line filtering')
+    assert_equal([["call", 1, :five, self.class]], tuples2, 
+                 'call filtering')
+  end
+end
Index: test/ruby/test_tracefunc_raise.rb
===================================================================
--- test/ruby/test_tracefunc_raise.rb	(revision 28647)
+++ test/ruby/test_tracefunc_raise.rb	(working copy)
@@ -0,0 +1,26 @@
+require 'test/unit'
+
+# tests that we a trace hook has access to the runtime exception Object
+# when it is called through a raise event
+
+class TestTracefuncRaise < Test::Unit::TestCase
+
+  def test_basic
+    tuples = []
+    p = Proc.new { 
+      |event, file, lineno, mid, binding, klass|
+      tuples << klass
+    }
+    msg = 'this is a message'
+    set_trace_func(p, 0x0080)
+    begin ; x = 1/0; rescue; end
+    begin ; raise RuntimeError, msg; rescue; end
+    clear_trace_func
+    assert_equal(2, tuples.size, 
+                 "Wrong number of tuples captured #{tuples.inspect}")
+    assert_equal msg, tuples[1].message
+    assert_equal([ZeroDivisionError, RuntimeError], tuples.map{|t| t.class},
+                 "Mismatched tuples classes in #{tuples.inspect}")
+    
+  end
+end
