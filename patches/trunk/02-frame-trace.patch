This patch adds adds the ability to set tracing on or off per frame.
Subsequent frames created which are called a frame with tracing set
off keeps tracing off by default.  (Infrequently one may want to
override this default behavior such as when wants to debug a
debugger.)  When frame returns, the trace bit is taken from the value
set from the previous frame's trace bit.

There is already a such a tracing bit that is similar which is set per
thread, but I don't think this is as useful.  When a trace hook is
called, if the hook yields to the debugged program (in the same
thread), I think the desired intent would be that tracing to turn
tracing back on if that is what it was before entering the hook.

This patch is helps make a debugger "step out" (or in gdb "finish"
command) fast.

Finally, sometimes one wants to do some setup before running a trace
hook, or write some code which simulates calling the hook as though it
were triggered by the runtime, even though it isn't. An example of
this is an immediate call to a debugger from the source code to be
debugged. This is in contrast to waiting for the next event to trigger
a call to a debugger. 

In ruby-debug situation one writes "debugger(:immediate => true)" and
this is used as a workaround for getting into the debugger in a method
at a point when there are no subsequent "line" events in that
method. Although in the next debugger this won't be needed, it still
is a nice thing to have. From the programmer's standpoint such an
immediate stop mechanism more straightforward and predictable.

In such a situation, the setup code ("debugger" above) may also call
other methods before entering the hook and so we want an easy way to
make sure those routines don't get traced just as the setup routine
isn't traced.

One might make a case for removing the trace bit in the thread
strucuture and having the frame bit subsume that. To be conservative
and compatible, I haven't done that.

Index: vm_core.h
===================================================================
--- vm_core.h	(revision 28642)
+++ vm_core.h	(working copy)
@@ -330,6 +330,9 @@
     rb_iseq_t *block_iseq;	/* cfp[8] / block[3] */
     VALUE proc;			/* cfp[9] / block[4] */
     const rb_method_entry_t *me;/* cfp[10] */
+    short int tracing;          /* Bits to control per-frame event tracing. 
+				   See VM_FRAME_TRACE_xxx defines.
+				 */
 } rb_control_frame_t;
 
 typedef struct rb_block_struct {
@@ -568,6 +572,10 @@
 
 #define VM_FRAME_TYPE(cfp) ((cfp)->flag & VM_FRAME_MAGIC_MASK)
 
+#define VM_FRAME_TRACE_RETURN 0x01  /* Call trace hook on return. */
+#define VM_FRAME_TRACE_OFF    0x02  /* Turn of event hook tracing in this frame
+				       and any frames created from this one. */
+
 /* other frame flag */
 #define VM_FRAME_FLAG_PASSED 0x0100
 
@@ -695,13 +700,29 @@
 void
 rb_threadptr_exec_event_hooks(rb_thread_t *th, rb_event_flag_t flag, VALUE self, ID id, VALUE klass);
 
-#define EXEC_EVENT_HOOK(th, flag, self, id, klass) do { \
-    rb_event_flag_t wait_event__ = th->event_flags; \
-    if (UNLIKELY(wait_event__)) { \
-	if (wait_event__ & (flag | RUBY_EVENT_VM)) { \
-	    rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
-	} \
-    } \
-} while (0)
+#define EXEC_EVENT_HOOK(th, flag, self, id, klass)			\
+  if (LIKELY(0 == th->tracing)) {					\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+	    }								\
+	}								\
+    }
+
+/* Customized version of EXEC_EVENT_HOOK for RUBY_EVENT_RETURN events */
+#define EXEC_EVENT_RETURN_HOOK(th, flag, self, id, klass)		\
+    if (LIKELY(0 == th->tracing &&					\
+	       (!(th->cfp->tracing & VM_FRAME_TRACE_OFF)		\
+		|| (th->cfp->tracing & VM_FRAME_TRACE_RETURN)))) {	\
+	rb_event_flag_t wait_event__ = th->event_flags;			\
+	if (UNLIKELY(wait_event__)) {					\
+	    if (wait_event__ & (flag | RUBY_EVENT_VM)) {		\
+	        th->tracing = 1;					\
+		rb_threadptr_exec_event_hooks(th, flag, self, id, klass); \
+		th->tracing = 0;					\
+	    }								\
+	}								\
+    }
 
 #endif /* RUBY_VM_CORE_H */
Index: thread.c
===================================================================
--- thread.c	(revision 28783)
+++ thread.c	(working copy)
@@ -3797,10 +3788,12 @@
     const rb_event_flag_t wait_event = th->event_flags;
 
     if (self == rb_mRubyVMFrozenCore) return;
-    if (wait_event & flag) {
-	exec_event_hooks(th->event_hooks, flag, self, id, klass);
+    if (wait_event & flag && th->tracing <= 0) {
+	if (!RUBY_VM_CONTROL_FRAME_STACK_OVERFLOW_P(th, th->cfp)
+	      && !(th->cfp->tracing & VM_FRAME_TRACE_OFF))
+	    exec_event_hooks(th->event_hooks, flag, self, id, klass);
     }
-    if (wait_event & RUBY_EVENT_VM) {
+    if (wait_event & RUBY_EVENT_VM && th->tracing <= 0) {
 	if (th->vm->event_hooks == NULL) {
 	    th->event_flags &= (~RUBY_EVENT_VM);
 	}
--- vm.c	(revision 27742)
+++ vm.c	(working copy)
@@ -1166,7 +1166,8 @@
 	while (th->cfp->pc == 0 || th->cfp->iseq == 0) {
 	    if (UNLIKELY(VM_FRAME_TYPE(th->cfp) == VM_FRAME_MAGIC_CFUNC)) {
 		const rb_method_entry_t *me = th->cfp->me;
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, me->called_id, me->klass);
+		EXEC_EVENT_RETURN_HOOK(th, RUBY_EVENT_C_RETURN, th->cfp->self, 
+					   me->called_id, me->klass);
 	    }
 	    th->cfp = RUBY_VM_PREVIOUS_CONTROL_FRAME(th->cfp);
 	}
@@ -1334,7 +1346,7 @@
 
 	    switch (VM_FRAME_TYPE(th->cfp)) {
 	      case VM_FRAME_MAGIC_METHOD:
-		EXEC_EVENT_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
+		EXEC_EVENT_RETURN_HOOK(th, RUBY_EVENT_RETURN, th->cfp->self, 0, 0);
 		break;
 	      case VM_FRAME_MAGIC_CLASS:
 		EXEC_EVENT_HOOK(th, RUBY_EVENT_END, th->cfp->self, 0, 0);
Index: vm_insnhelper.c
Index: vm_insnhelper.c
===================================================================
--- vm_insnhelper.c	(revision 28783)
+++ vm_insnhelper.c	(working copy)
@@ -26,9 +26,12 @@
 	      const VALUE *pc, VALUE *sp, VALUE *lfp,
 	      int local_size)
 {
+    short int tracing = 0;
     rb_control_frame_t * const cfp = th->cfp - 1;
     int i;
 
+    if (type != VM_FRAME_MAGIC_TOP) tracing = th->cfp->tracing;
+
     if ((void *)(sp + local_size) >= (void *)cfp) {
 	rb_exc_raise(sysstack_error);
     }
@@ -60,6 +63,7 @@
     cfp->dfp = sp;
     cfp->proc = 0;
     cfp->me = 0;
+    cfp->tracing = tracing;
 
 #define COLLECT_PROFILE 0
 #if COLLECT_PROFILE
